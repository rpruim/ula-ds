<!DOCTYPE html>
<!--********************************************-->
<!--*       Generated from PreTeXt source      *-->
<!--*                                          *-->
<!--*         https://pretextbook.org          *-->
<!--*                                          *-->
<!--********************************************-->
<html lang="en-US" dir="ltr">
<head xmlns:og="http://ogp.me/ns#" xmlns:book="https://ogp.me/ns/book#">
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<title>Singular Value Decompositions</title>
<meta name="Keywords" content="Authored in PreTeXt">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta property="og:type" content="book">
<meta property="book:title" content="Understanding Linear Algebra">
<meta property="book:author" content=" Randall Pruim ">
<script src="https://sagecell.sagemath.org/static/embedded_sagecell.js"></script><script>
var runestoneMathReady = new Promise((resolve) => window.rsMathReady = resolve);
window.MathJax = {
  "tex": {
    "inlineMath": [
      [
        "\\(",
        "\\)"
      ]
    ],
    "tags": "none",
    "tagSide": "right",
    "tagIndent": ".8em",
    "packages": {
      "[+]": [
        "base",
        "extpfeil",
        "ams",
        "amscd",
        "color",
        "newcommand",
        "knowl"
      ]
    }
  },
  "options": {
    "ignoreHtmlClass": "tex2jax_ignore|ignore-math",
    "processHtmlClass": "process-math",
    "renderActions": {
      "findScript": [
        10,
        function (doc) {
            document.querySelectorAll('script[type^="math/tex"]').forEach(function(node) {
                var display = !!node.type.match(/; *mode=display/);
                var math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
                var text = document.createTextNode('');
                node.parentNode.replaceChild(text, node);
                math.start = {node: text, delim: '', n: 0};
                math.end = {node: text, delim: '', n: 0};
                doc.math.push(math);
            });
        },
        ""
      ]
    }
  },
  "chtml": {
    "scale": 0.98,
    "mtextInheritFont": true
  },
  "loader": {
    "load": [
      "input/asciimath",
      "[tex]/extpfeil",
      "[tex]/amscd",
      "[tex]/color",
      "[tex]/newcommand",
      "[pretext]/mathjaxknowl3.js"
    ],
    "paths": {
      "pretext": "https://pretextbook.org/js/lib"
    }
  },
  "startup": {
    pageReady() {
      return MathJax.startup.defaultPageReady().then(function () {
      console.log("in ready function");
      rsMathReady();
      }
    )}
  }
};
</script><script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"></script><script>// Make *any* pre with class 'sagecell-python' an executable Sage cell
// Their results will be linked, only within language type
sagecell.makeSagecell({
  "inputLocation": "pre.sagecell-python",
  "linked": true,
  "linkKey": "linked-python",
  "autoeval": false,
  "languages": [
    "python"
  ],
  "evalButtonText": "Evaluate (Python)"
});
</script><script async="" src="https://cse.google.com/cse.js?cx=015103900096539427448:ngwuia10qci"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/lunr.js/2.3.9/lunr.min.js" integrity="sha512-4xUl/d6D6THrAnXAwGajXkoWaeMNwEKK4iNfq5DotEbLPAfk6FSxSP3ydNxqDgCw1c/0Z1Jg6L8h2j+++9BZmg==" crossorigin="anonymous" referrerpolicy="no-referrer"></script><script src="lunr-pretext-search-index.js" async=""></script><script src="https://pretextbook.org/js/0.3/pretext_search.js"></script><link href="https://pretextbook.org/css/0.7/pretext_search.css" rel="stylesheet" type="text/css">
<script>js_version = 0.3</script><script src="https://pretextbook.org/js/lib/jquery.min.js"></script><script src="https://pretextbook.org/js/lib/jquery.sticky.js"></script><script src="https://pretextbook.org/js/lib/jquery.espy.min.js"></script><script src="https://pretextbook.org/js/0.3/pretext.js"></script><script>miniversion=0.1</script><script src="https://pretextbook.org/js/0.3/pretext_add_on.js?x=1"></script><script src="https://pretextbook.org/js/0.3/user_preferences.js"></script><script src="https://pretextbook.org/js/lib/knowl.js"></script><!--knowl.js code controls Sage Cells within knowls--><script>sagecellEvalName='Evaluate (Sage)';
</script><link rel="preconnect" href="https://fonts.googleapis.com">
<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin="">
<link href="https://fonts.googleapis.com/css2?family=Inconsolata:wght@400;700&amp;family=Noto+Serif:ital,wght@0,400;0,700;1,400;1,700&amp;family=Tinos:ital,wght@0,400;0,700;1,400;1,700&amp;display=swap" rel="stylesheet">
<link href="https://fonts.cdnfonts.com/css/dejavu-serif" rel="stylesheet">
<link href="https://fonts.googleapis.com/css2?family=Roboto+Serif:opsz,wdth,wght@8..144,50..150,100..900&amp;display=swap" rel="stylesheet">
<link href="https://fonts.googleapis.com/css2?family=Open+Sans:wdth,wght@75..100,300..800&amp;display=swap" rel="stylesheet">
<link href="https://pretextbook.org/css/0.7/pretext.css" rel="stylesheet" type="text/css">
<link href="https://pretextbook.org/css/0.7/pretext_add_on.css" rel="stylesheet" type="text/css">
<link href="https://pretextbook.org/css/0.7/shell_default.css" rel="stylesheet" type="text/css">
<link href="https://pretextbook.org/css/0.7/banner_default.css" rel="stylesheet" type="text/css">
<link href="https://pretextbook.org/css/0.7/navbar_default.css" rel="stylesheet" type="text/css">
<link href="https://pretextbook.org/css/0.7/toc_default.css" rel="stylesheet" type="text/css">
<link href="https://pretextbook.org/css/0.7/knowls_default.css" rel="stylesheet" type="text/css">
<link href="https://pretextbook.org/css/0.7/style_default.css" rel="stylesheet" type="text/css">
<link href="https://pretextbook.org/css/0.7/colors_blue_grey.css" rel="stylesheet" type="text/css">
<link href="https://pretextbook.org/css/0.7/setcolors.css" rel="stylesheet" type="text/css">
</head>
<body class="pretext book ignore-math">
<a class="assistive" href="#ptx-content">Skip to main content</a><header id="ptx-masthead" class="ptx-masthead"><div class="ptx-banner">
<a id="logo-link" class="logo-link" href=""></a><div class="title-container">
<h1 class="heading"><a href="ula.html"><span class="title">Understanding Linear Algebra:</span> <span class="subtitle">Data Science Edition</span></a></h1>
<p class="byline">Randall Pruim</p>
</div>
<div id="searchresultsplaceholder" class="searchresultsplaceholder" style="display: none">
<button id="closesearchresults" class="closesearchresults" onclick="document.getElementById('searchresultsplaceholder').style.display = 'none'; return false;">x</button><h2>Search Results: <span id="searchterms" class="searchterms"></span>
</h2>
<div id="searchempty" class="searchempty"><span>No results.</span></div>
<ol id="searchresults" class="searchresults"></ol>
</div>
</div></header><nav id="ptx-navbar" class="ptx-navbar navbar"><button class="toc-toggle button" aria-label="Show or hide table of contents"><span class="icon">‚ò∞</span><span class="name">Contents</span></button><a class="index-button button" href="index-1.html" title="Index"><span class="name">Index</span></a><button id="user-preferences-button" class="user-preferences-button button" title="Modify user preferences"><span id="avatarbutton" class="avatarbutton name">You!</span><div id="preferences_menu_holder" class="preferences_menu_holder hidden"><ol id="preferences_menu" class="preferences_menu" style="font-family: 'Roboto Serif', serif;">
<li data-env="avatar" tabindex="-1">Choose avatar<div class="wrap_to_submenu"><span class="to_submenu">‚ñª</span></div>
<ol class="hidden avatar">
<li data-val="You!" tabindex="-1">
<span id="theYou!" class="avatarcheck">‚úîÔ∏è</span>You!</li>
<li data-val="üò∫" tabindex="-1">
<span id="theüò∫" class="avatarcheck"></span>üò∫</li>
<li data-val="üë§" tabindex="-1">
<span id="theüë§" class="avatarcheck"></span>üë§</li>
<li data-val="üëΩ" tabindex="-1">
<span id="theüëΩ" class="avatarcheck"></span>üëΩ</li>
<li data-val="üê∂" tabindex="-1">
<span id="theüê∂" class="avatarcheck"></span>üê∂</li>
<li data-val="üêº" tabindex="-1">
<span id="theüêº" class="avatarcheck"></span>üêº</li>
<li data-val="üåà" tabindex="-1">
<span id="theüåà" class="avatarcheck"></span>üåà</li>
</ol>
</li>
<li data-env="fontfamily" tabindex="-1">Font family<div class="wrap_to_submenu"><span class="to_submenu">‚ñª</span></div>
<ol class="hidden fontfamily">
<li data-val="face" data-change="OS" tabindex="-1" style="font-family: 'Open Sans'">
<span id="theOS" class="ffcheck">‚úîÔ∏è</span><span class="name">Open Sans</span><span class="sample">AaBbCc 123 PreTeXt</span>
</li>
<li data-val="face" data-change="RS" tabindex="-1" style="font-family: 'Roboto Serif'">
<span id="theRS" class="ffcheck"></span><span class="name">Roboto Serif</span><span class="sample">AaBbCc 123 PreTeXt</span>
</li>
</ol>
</li>
<li data-env="font" tabindex="-1">Adjust font<div class="wrap_to_submenu"><span class="to_submenu">‚ñª</span></div>
<ol class="hidden fonts">
<li>Size</li>
<li><span id="thesize">12</span></li>
<li data-val="size" data-change="-1" tabindex="-1" style="font-size: 80%">Smaller</li>
<li data-val="size" data-change="1" tabindex="-1" style="font-size: 110%">Larger</li>
<li>Width</li>
<li><span id="thewdth">100</span></li>
<li data-val="wdth" data-change="-5" tabindex="-1" style="font-variation-settings: 'wdth' 60">narrower</li>
<li data-val="wdth" data-change="5" tabindex="-1" style="font-variation-settings: 'wdth' 150">wider</li>
<li>Weight</li>
<li><span id="thewght">400</span></li>
<li data-val="wght" data-change="-50" tabindex="-1" style="font-weight: 200">thinner</li>
<li data-val="wght" data-change="50" tabindex="-1" style="font-weight: 700">heavier</li>
<li>Letter spacing</li>
<li>
<span id="thelspace">0</span><span class="byunits">/200</span>
</li>
<li data-val="lspace" data-change="-1" tabindex="-1">closer</li>
<li data-val="lspace" data-change="1" tabindex="-1">f a r t h e r</li>
<li>Word spacing</li>
<li>
<span id="thewspace">0</span><span class="byunits">/50</span>
</li>
<li data-val="wspace" data-change="-1" tabindex="-1">smaller‚ÄÖgap‚ÄÉ</li>
<li data-val="wspace" data-change="1" tabindex="-1">larger‚ÄÉgap</li>
<li>Line Spacing</li>
<li>
<span id="theheight">135</span><span class="byunits">/100</span>
</li>
<li data-val="height" data-change="-5" tabindex="-1" style="line-height: 1">closer<br>together</li>
<li data-val="height" data-change="5" tabindex="-1" style="line-height: 1.75">further<br>apart</li>
</ol>
</li>
<li data-env="atmosphere" tabindex="-1">Light/dark mode<div class="wrap_to_submenu"><span class="to_submenu">‚ñª</span></div>
<ol class="hidden atmosphere">
<li data-val="default" tabindex="-1">
<span id="thedefault" class="atmospherecheck">‚úîÔ∏è</span>default</li>
<li data-val="pastel" tabindex="-1">
<span id="thepastel" class="atmospherecheck"></span>pastel</li>
<li data-val="darktwilight" tabindex="-1">
<span id="thedarktwilight" class="atmospherecheck"></span>twilight</li>
<li data-val="dark" tabindex="-1">
<span id="thedark" class="atmospherecheck"></span>dark</li>
<li data-val="darkmidnight" tabindex="-1">
<span id="thedarkmidnight" class="atmospherecheck"></span>midnight</li>
</ol>
</li>
<li data-env="ruler" tabindex="-1">Reading ruler<div class="wrap_to_submenu"><span class="to_submenu">‚ñª</span></div>
<ol class="hidden ruler">
<li data-val="none" tabindex="-1">
<span id="thenone" class="rulercheck">‚úîÔ∏è</span>none</li>
<li data-val="underline" tabindex="-1">
<span id="theunderline" class="rulercheck"></span>underline</li>
<li data-val="lunderline" tabindex="-1">
<span id="thelunderline" class="rulercheck"></span>L-underline</li>
<li data-val="greybar" tabindex="-1">
<span id="thegreybar" class="rulercheck"></span>grey bar</li>
<li data-val="lightbox" tabindex="-1">
<span id="thelightbox" class="rulercheck"></span>light box</li>
<li data-val="sunrise" tabindex="-1">
<span id="thesunrise" class="rulercheck"></span>sunrise</li>
<li data-val="sunriseunderline" tabindex="-1">
<span id="thesunriseunderline" class="rulercheck"></span>sunrise underline</li>
<li class="moveQ">Motion by:</li>
<li data-val="mouse" tabindex="-1">
<span id="themouse" class="motioncheck">‚úîÔ∏è</span>follow the mouse</li>
<li data-val="arrow" tabindex="-1">
<span id="thearrow" class="motioncheck"></span>up/down arrows - not yet</li>
<li data-val="eye" tabindex="-1">
<span id="theeye" class="motioncheck"></span>eye tracking - not yet</li>
</ol>
</li>
</ol></div></button><span class="treebuttons"><a class="previous-button button" href="sec-pca.html" title="Previous"><span class="icon">&lt;</span><span class="name">Prev</span></a><a class="up-button button" href="chap7.html" title="Up"><span class="icon">^</span><span class="name">Up</span></a><a class="next-button button" href="sec-svd-uses.html" title="Next"><span class="name">Next</span><span class="icon">&gt;</span></a></span><div class="searchwrapper" role="search"><div class="gcse-search"></div></div>
<div class="searchbox"><div class="searchwidget">
<input id="ptxsearch" class="ptxsearch" type="text" name="terms" placeholder="Search" onchange="doSearch()"><button id="searchbutton" class="searchbutton" type="button" onclick="doSearch()">üîç</button>
</div></div></nav><div id="latex-macros" class="hidden-content process-math" style="display:none"><span class="process-math">\(\newcommand{\avec}{{\boldsymbol a}}
\newcommand{\bvec}{{\boldsymbol b}}
\newcommand{\cvec}{{\boldsymbol c}}
\newcommand{\dvec}{{\boldsymbol d}}
\newcommand{\dtil}{\widetilde{\boldsymbol d}}
\newcommand{\evec}{{\boldsymbol e}}
\newcommand{\fvec}{{\boldsymbol f}}
\newcommand{\mvec}{{\boldsymbol m}}
\newcommand{\nvec}{{\boldsymbol n}}
\newcommand{\pvec}{{\boldsymbol p}}
\newcommand{\qvec}{{\boldsymbol q}}
\newcommand{\rvec}{{\boldsymbol r}}
\newcommand{\svec}{{\boldsymbol s}}
\newcommand{\tvec}{{\boldsymbol t}}
\newcommand{\uvec}{{\boldsymbol u}}
\newcommand{\vvec}{{\boldsymbol v}}
\newcommand{\wvec}{{\boldsymbol w}}
\newcommand{\xvec}{{\boldsymbol x}}
\newcommand{\yvec}{{\boldsymbol y}}
\newcommand{\zvec}{{\boldsymbol z}}
\newcommand{\betavec}{{\boldsymbol \beta}}
\newcommand{\E}{\operatorname{E}}
\newcommand{\zerovec}{{\boldsymbol 0}}
\newcommand{\onevec}{{\boldsymbol 1}}
\newcommand{\real}{{\mathbb R}}
\newcommand{\twovec}[2]{\left[\begin{array}{r}#1 \\ #2
\end{array}\right]}
\newcommand{\ctwovec}[2]{\left[\begin{array}{c}#1 \\ #2
\end{array}\right]}
\newcommand{\threevec}[3]{\left[\begin{array}{r}#1 \\ #2 \\ #3
\end{array}\right]}
\newcommand{\cthreevec}[3]{\left[\begin{array}{c}#1 \\ #2 \\ #3
\end{array}\right]}
\newcommand{\fourvec}[4]{\left[\begin{array}{r}#1 \\ #2 \\ #3 \\ #4
\end{array}\right]}
\newcommand{\cfourvec}[4]{\left[\begin{array}{c}#1 \\ #2 \\ #3 \\ #4
\end{array}\right]}
\newcommand{\fivevec}[5]{\left[\begin{array}{r}#1 \\ #2 \\ #3 \\
#4 \\ #5 \\ \end{array}\right]}
\newcommand{\cfivevec}[5]{\left[\begin{array}{c}#1 \\ #2 \\ #3 \\
#4 \\ #5 \\ \end{array}\right]}
\newcommand{\mattwo}[4]{\left[\begin{array}{rr}#1 \amp #2 \\ #3 \amp #4 \\ \end{array}\right]}
\newcommand{\laspan}[1]{\text{Span}\{#1\}}
\newcommand{\bcal}{{\cal B}}
\newcommand{\ccal}{{\cal C}}
\newcommand{\scal}{{\cal S}}
\newcommand{\wcal}{{\cal W}}
\newcommand{\ecal}{{\cal E}}
\newcommand{\coords}[2]{\left\{#1\right\}_{#2}}
\newcommand{\gray}[1]{\color{gray}{#1}}
\newcommand{\lgray}[1]{\color{lightgray}{#1}}
\newcommand{\rank}{\operatorname{rank}}
\newcommand{\row}{\text{Row}}
\newcommand{\col}{\text{Col}}
\renewcommand{\row}{\text{Row}}
\newcommand{\nul}{\text{Nul}}
\newcommand{\var}{\text{Var}}
\newcommand{\cov}{\text{Cov}}
\newcommand{\corr}{\text{corr}}
\newcommand{\len}[1]{\left|#1\right|}
\newcommand{\bbar}{\overline{\bvec}}
\newcommand{\bhat}{\widehat{\bvec}}
\newcommand{\bperp}{\bvec^\perp}
\newcommand{\atilde}{\tilde{\avec}}
\newcommand{\btilde}{\tilde{\bvec}}
\newcommand{\vhat}{\widehat{\vvec}}
\newcommand{\uhat}{\widehat{\uvec}}
\newcommand{\what}{\widehat{\wvec}}
\newcommand{\xhat}{\widehat{\xvec}}
\newcommand{\xmean}{\overline{\xvec}}
\newcommand{\xbar}{\overline{\xvec}}
\newcommand{\xtilde}{\tilde{\xvec}}
\newcommand{\Xtilde}{\tilde{X}}
\newcommand{\yhat}{\widehat{\yvec}}
\newcommand{\ymean}{\overline{\yvec}}
\newcommand{\ybar}{\overline{\yvec}}
\newcommand{\ytilde}{\tilde{\yvec}}
\newcommand{\yperp}{\yvec^\perp}
\newcommand{\betahat}{\widehat{\betavec}}
\newcommand{\Sighat}{\widehat{\Sigma}}
\newcommand{\by}{\times}
\newcommand{\transpose}{\top}
\newcommand{\proj}[2]{\operatorname{proj}\left(#1 \to #2\right)}
\newcommand{\projsub}[2]{\operatorname{proj}_{#2}(#1)}
\newcommand{\lt}{&lt;}
\newcommand{\gt}{&gt;}
\newcommand{\amp}{&amp;}
\definecolor{fillinmathshade}{gray}{0.9}
\newcommand{\fillinmath}[1]{\mathchoice{\colorbox{fillinmathshade}{$\displaystyle     \phantom{\,#1\,}$}}{\colorbox{fillinmathshade}{$\textstyle        \phantom{\,#1\,}$}}{\colorbox{fillinmathshade}{$\scriptstyle      \phantom{\,#1\,}$}}{\colorbox{fillinmathshade}{$\scriptscriptstyle\phantom{\,#1\,}$}}}
\)</span></div>
<div class="ptx-page">
<div id="ptx-sidebar" class="ptx-sidebar"><nav id="ptx-toc" class="ptx-toc depth2"><ul class="structural">
<li>
<div class="toc-item"><a href="frontmatter.html" class="internal"><span class="title">Front Matter</span></a></div>
<ul class="structural">
<li><div class="toc-item"><a href="colophon-1.html" class="internal"><span class="title">Colophon</span></a></div></li>
<li><div class="toc-item"><a href="preface-1.html" class="internal"><span class="title">Our goals -- Preface to David Austin‚Äôs original edition</span></a></div></li>
<li><div class="toc-item"><a href="preface-2.html" class="internal"><span class="title">What‚Äôs different in the data science edition?</span></a></div></li>
</ul>
</li>
<li>
<div class="toc-item"><a href="chap1.html" class="internal"><span class="codenumber">1</span> <span class="title">Scalars, Vectors and Matrices</span></a></div>
<ul class="structural">
<li>
<div class="toc-item"><a href="sec-vectors.html" class="internal"><span class="codenumber">1.1</span> <span class="title">Vectors</span></a></div>
<ul class="structural">
<li><div class="toc-item"><a href="sec-vectors.html#subsection-1" class="internal"><span class="codenumber">1.1.1</span> <span class="title">Three ways to think about vectors</span></a></div></li>
<li>
<div class="toc-item"><a href="sec-vectors.html#subsection-2" class="internal"><span class="codenumber">1.1.2</span> <span class="title">Vector operations: scalar multiplication and vector addition.</span></a></div>
<ul class="structural">
<li><div class="toc-item"><a href="sec-vectors.html#subsubsec-scalar-multiplication" class="internal"><span class="codenumber">1.1.2.1</span> <span class="title">Scalar Multiplication</span></a></div></li>
<li><div class="toc-item"><a href="sec-vectors.html#subsubsec-vector-addition" class="internal"><span class="codenumber">1.1.2.2</span> <span class="title">Vector addition</span></a></div></li>
<li><div class="toc-item"><a href="sec-vectors.html#subsubsec-vector-properties" class="internal"><span class="codenumber">1.1.2.3</span> <span class="title">Mathematical properties of vector operations</span></a></div></li>
</ul>
</li>
<li><div class="toc-item"><a href="sec-vectors.html#subsection-3" class="internal"><span class="codenumber">1.1.3</span> <span class="title">The (Euclidean) length of a vector</span></a></div></li>
<li><div class="toc-item"><a href="sec-vectors.html#subsection-4" class="internal"><span class="codenumber">1.1.4</span> <span class="title">Summary</span></a></div></li>
</ul>
</li>
<li>
<div class="toc-item"><a href="sec-vectors-in-python.html" class="internal"><span class="codenumber">1.2</span> <span class="title">Vectors in Python</span></a></div>
<ul class="structural">
<li><div class="toc-item"><a href="sec-vectors-in-python.html#subsec-intro-to-python" class="internal"><span class="codenumber">1.2.1</span> <span class="title">Introduction to Python</span></a></div></li>
<li><div class="toc-item"><a href="sec-vectors-in-python.html#subsec-numpy-vectors" class="internal"><span class="codenumber">1.2.2</span> <span class="title"><code class="code-inline tex2jax_ignore">numpy</code> vectors</span></a></div></li>
<li><div class="toc-item"><a href="sec-vectors-in-python.html#subsec-vector-length-numpy" class="internal"><span class="codenumber">1.2.3</span> <span class="title">Vector length</span></a></div></li>
<li><div class="toc-item"><a href="sec-vectors-in-python.html#subsection-8" class="internal"><span class="codenumber">1.2.4</span> <span class="title">Plotting vectors</span></a></div></li>
</ul>
</li>
<li>
<div class="toc-item"><a href="sec-linear-combos-of-vectors.html" class="internal"><span class="codenumber">1.3</span> <span class="title">Linear combinations of vectors</span></a></div>
<ul class="structural">
<li><div class="toc-item"><a href="sec-linear-combos-of-vectors.html#subsection-9" class="internal"><span class="codenumber">1.3.1</span> <span class="title">Summary</span></a></div></li>
<li><div class="toc-item"><a href="sec-linear-combos-of-vectors.html#exercises-1" class="internal"><span class="codenumber">1.3.2</span> <span class="title">Exercises</span></a></div></li>
</ul>
</li>
<li>
<div class="toc-item"><a href="sec-matrices.html" class="internal"><span class="codenumber">1.4</span> <span class="title">Matrices</span></a></div>
<ul class="structural">
<li><div class="toc-item"><a href="sec-matrices.html#subsec-matrices-and-their-uses" class="internal"><span class="codenumber">1.4.1</span> <span class="title">Matrices and their uses</span></a></div></li>
<li><div class="toc-item"><a href="sec-matrices.html#subsection-11" class="internal"><span class="codenumber">1.4.2</span> <span class="title">Scalar multiplication and addition of matrices</span></a></div></li>
<li><div class="toc-item"><a href="sec-matrices.html#subsection-12" class="internal"><span class="codenumber">1.4.3</span> <span class="title">Matrix-vector multiplication and linear combinations</span></a></div></li>
<li><div class="toc-item"><a href="sec-matrices.html#subsection-13" class="internal"><span class="codenumber">1.4.4</span> <span class="title">Matrix-vector multiplication and linear systems</span></a></div></li>
<li><div class="toc-item"><a href="sec-matrices.html#sec-matrices-in-python" class="internal"><span class="codenumber">1.4.5</span> <span class="title">Matrices in Python</span></a></div></li>
<li><div class="toc-item"><a href="sec-matrices.html#subsection-15" class="internal"><span class="codenumber">1.4.6</span> <span class="title">Matrix-matrix products</span></a></div></li>
<li><div class="toc-item"><a href="sec-matrices.html#subsec-special-matrices" class="internal"><span class="codenumber">1.4.7</span> <span class="title">Some special types of matrices</span></a></div></li>
<li><div class="toc-item"><a href="sec-matrices.html#subsection-17" class="internal"><span class="codenumber">1.4.8</span> <span class="title">Summary</span></a></div></li>
<li><div class="toc-item"><a href="sec-matrices.html#exercises-2" class="internal"><span class="codenumber">1.4.9</span> <span class="title">Exercises</span></a></div></li>
</ul>
</li>
<li>
<div class="toc-item"><a href="sec-tensors.html" class="internal"><span class="codenumber">1.5</span> <span class="title">Tensors</span></a></div>
<ul class="structural">
<li><div class="toc-item"><a href="sec-tensors.html#subsec-numpy-tensors" class="internal"><span class="codenumber">1.5.1</span> <span class="title">Tensors in NumPy</span></a></div></li>
<li><div class="toc-item"><a href="sec-tensors.html#subsec-axes" class="internal"><span class="codenumber">1.5.2</span> <span class="title">Aggregation and Axes</span></a></div></li>
<li><div class="toc-item"><a href="sec-tensors.html#subsec-ndarray-append" class="internal"><span class="codenumber">1.5.3</span> <span class="title">Expanding an array</span></a></div></li>
<li><div class="toc-item"><a href="sec-tensors.html#subsec-broadcasting" class="internal"><span class="codenumber">1.5.4</span> <span class="title">Broadcasting</span></a></div></li>
<li><div class="toc-item"><a href="sec-tensors.html#exercises-1-5" class="internal"><span class="codenumber">1.5.5</span> <span class="title">Exercises</span></a></div></li>
</ul>
</li>
</ul>
</li>
<li>
<div class="toc-item"><a href="chap2.html" class="internal"><span class="codenumber">2</span> <span class="title">Systems of equations: Solving <span class="process-math">\(A \xvec = \bvec\)</span></span></a></div>
<ul class="structural">
<li>
<div class="toc-item"><a href="sec-expect.html" class="internal"><span class="codenumber">2.1</span> <span class="title">What can we expect</span></a></div>
<ul class="structural">
<li><div class="toc-item"><a href="sec-expect.html#subsection-22" class="internal"><span class="codenumber">2.1.1</span> <span class="title">Some simple examples</span></a></div></li>
<li><div class="toc-item"><a href="sec-expect.html#subsection-23" class="internal"><span class="codenumber">2.1.2</span> <span class="title">Systems of linear equations</span></a></div></li>
<li><div class="toc-item"><a href="sec-expect.html#subsection-24" class="internal"><span class="codenumber">2.1.3</span> <span class="title">Summary</span></a></div></li>
<li><div class="toc-item"><a href="sec-expect.html#exercises-4" class="internal"><span class="codenumber">2.1.4</span> <span class="title">Exercises</span></a></div></li>
</ul>
</li>
<li>
<div class="toc-item"><a href="sec-finding-solutions.html" class="internal"><span class="codenumber">2.2</span> <span class="title">Finding solutions to linear systems</span></a></div>
<ul class="structural">
<li><div class="toc-item"><a href="sec-finding-solutions.html#subsection-25" class="internal"><span class="codenumber">2.2.1</span> <span class="title">Gaussian elimination</span></a></div></li>
<li><div class="toc-item"><a href="sec-finding-solutions.html#subsection-26" class="internal"><span class="codenumber">2.2.2</span> <span class="title">Augmented matrices</span></a></div></li>
<li><div class="toc-item"><a href="sec-finding-solutions.html#subsection-27" class="internal"><span class="codenumber">2.2.3</span> <span class="title">Reduced row echelon form</span></a></div></li>
<li><div class="toc-item"><a href="sec-finding-solutions.html#subsec-solving-matrix-equations" class="internal"><span class="codenumber">2.2.4</span> <span class="title">Solving matrix equations</span></a></div></li>
<li><div class="toc-item"><a href="sec-finding-solutions.html#subsection-29" class="internal"><span class="codenumber">2.2.5</span> <span class="title">Summary</span></a></div></li>
<li><div class="toc-item"><a href="sec-finding-solutions.html#exercises-5" class="internal"><span class="codenumber">2.2.6</span> <span class="title">Exercises</span></a></div></li>
</ul>
</li>
<li>
<div class="toc-item"><a href="sec-python-introduction.html" class="internal"><span class="codenumber">2.3</span> <span class="title">Computational Linear Algebra</span></a></div>
<ul class="structural">
<li><div class="toc-item"><a href="sec-python-introduction.html#subsection-30" class="internal"><span class="codenumber">2.3.1</span> <span class="title">Reduced row echelon form in Python</span></a></div></li>
<li><div class="toc-item"><a href="sec-python-introduction.html#subsec-linalg-solve" class="internal"><span class="codenumber">2.3.2</span> <span class="title">np.linalg.solve()</span></a></div></li>
<li><div class="toc-item"><a href="sec-python-introduction.html#subsec-compute-effort" class="internal"><span class="codenumber">2.3.3</span> <span class="title">Computational effort</span></a></div></li>
<li><div class="toc-item"><a href="sec-python-introduction.html#subsection-33" class="internal"><span class="codenumber">2.3.4</span> <span class="title">Summary</span></a></div></li>
<li><div class="toc-item"><a href="sec-python-introduction.html#exercises-6" class="internal"><span class="codenumber">2.3.5</span> <span class="title">Exercises</span></a></div></li>
</ul>
</li>
<li>
<div class="toc-item"><a href="sec-pivots.html" class="internal"><span class="codenumber">2.4</span> <span class="title">Pivots and their relationship to solution spaces</span></a></div>
<ul class="structural">
<li><div class="toc-item"><a href="sec-pivots.html#subsection-34" class="internal"><span class="codenumber">2.4.1</span> <span class="title">The existence of solutions</span></a></div></li>
<li><div class="toc-item"><a href="sec-pivots.html#subsection-35" class="internal"><span class="codenumber">2.4.2</span> <span class="title">The uniqueness of solutions</span></a></div></li>
<li><div class="toc-item"><a href="sec-pivots.html#subsection-36" class="internal"><span class="codenumber">2.4.3</span> <span class="title">Summary</span></a></div></li>
<li><div class="toc-item"><a href="sec-pivots.html#exercises-7" class="internal"><span class="codenumber">2.4.4</span> <span class="title">Exercises</span></a></div></li>
</ul>
</li>
</ul>
</li>
<li>
<div class="toc-item"><a href="chap3.html" class="internal"><span class="codenumber">3</span> <span class="title">Linear combinations and transformations</span></a></div>
<ul class="structural">
<li>
<div class="toc-item"><a href="sec-span.html" class="internal"><span class="codenumber">3.1</span> <span class="title">The span of a set of vectors</span></a></div>
<ul class="structural">
<li><div class="toc-item"><a href="sec-span.html#subsection-37" class="internal"><span class="codenumber">3.1.1</span> <span class="title">The span of a set of vectors</span></a></div></li>
<li><div class="toc-item"><a href="sec-span.html#subsection-38" class="internal"><span class="codenumber">3.1.2</span> <span class="title">Pivot positions and span</span></a></div></li>
<li><div class="toc-item"><a href="sec-span.html#subsec-span-and-linear-models" class="internal"><span class="codenumber">3.1.3</span> <span class="title">Span and linear models</span></a></div></li>
<li><div class="toc-item"><a href="sec-span.html#subsection-40" class="internal"><span class="codenumber">3.1.4</span> <span class="title">Summary</span></a></div></li>
<li><div class="toc-item"><a href="sec-span.html#exercises-8" class="internal"><span class="codenumber">3.1.5</span> <span class="title">Exercises</span></a></div></li>
</ul>
</li>
<li>
<div class="toc-item"><a href="sec-linear-dep.html" class="internal"><span class="codenumber">3.2</span> <span class="title">Linear independence</span></a></div>
<ul class="structural">
<li><div class="toc-item"><a href="sec-linear-dep.html#subsection-41" class="internal"><span class="codenumber">3.2.1</span> <span class="title">Linear dependence</span></a></div></li>
<li><div class="toc-item"><a href="sec-linear-dep.html#subsection-42" class="internal"><span class="codenumber">3.2.2</span> <span class="title">How to recognize linear dependence</span></a></div></li>
<li><div class="toc-item"><a href="sec-linear-dep.html#subsection-43" class="internal"><span class="codenumber">3.2.3</span> <span class="title">Homogeneous equations</span></a></div></li>
<li><div class="toc-item"><a href="sec-linear-dep.html#subsection-44" class="internal"><span class="codenumber">3.2.4</span> <span class="title">Summary</span></a></div></li>
<li><div class="toc-item"><a href="sec-linear-dep.html#exercises-9" class="internal"><span class="codenumber">3.2.5</span> <span class="title">Exercises</span></a></div></li>
</ul>
</li>
<li>
<div class="toc-item"><a href="sec-linear-trans.html" class="internal"><span class="codenumber">3.3</span> <span class="title">Matrix transformations</span></a></div>
<ul class="structural">
<li><div class="toc-item"><a href="sec-linear-trans.html#subsec-matrix-trans" class="internal"><span class="codenumber">3.3.1</span> <span class="title">Matrix transformations</span></a></div></li>
<li><div class="toc-item"><a href="sec-linear-trans.html#subsec-linear-trans" class="internal"><span class="codenumber">3.3.2</span> <span class="title">Linear transformations</span></a></div></li>
<li><div class="toc-item"><a href="sec-linear-trans.html#subsection-47" class="internal"><span class="codenumber">3.3.3</span> <span class="title">Composing matrix transformations</span></a></div></li>
<li><div class="toc-item"><a href="sec-linear-trans.html#subsec-dynamical-systems" class="internal"><span class="codenumber">3.3.4</span> <span class="title">Discrete Dynamical Systems</span></a></div></li>
<li><div class="toc-item"><a href="sec-linear-trans.html#subsection-49" class="internal"><span class="codenumber">3.3.5</span> <span class="title">Summary</span></a></div></li>
<li><div class="toc-item"><a href="sec-linear-trans.html#exercises-10" class="internal"><span class="codenumber">3.3.6</span> <span class="title">Exercises</span></a></div></li>
</ul>
</li>
<li>
<div class="toc-item"><a href="sec-transforms-geom.html" class="internal"><span class="codenumber">3.4</span> <span class="title">The geometry of matrix transformations</span></a></div>
<ul class="structural">
<li><div class="toc-item"><a href="sec-transforms-geom.html#subsection-50" class="internal"><span class="codenumber">3.4.1</span> <span class="title">The geometry of <span class="process-math">\(2\by2\)</span> matrix transformations</span></a></div></li>
<li><div class="toc-item"><a href="sec-transforms-geom.html#subsection-51" class="internal"><span class="codenumber">3.4.2</span> <span class="title">Matrix transformations and computer animation</span></a></div></li>
<li><div class="toc-item"><a href="sec-transforms-geom.html#subsection-52" class="internal"><span class="codenumber">3.4.3</span> <span class="title">Summary</span></a></div></li>
<li><div class="toc-item"><a href="sec-transforms-geom.html#exercises-11" class="internal"><span class="codenumber">3.4.4</span> <span class="title">Exercises</span></a></div></li>
</ul>
</li>
</ul>
</li>
<li>
<div class="toc-item"><a href="chap4.html" class="internal"><span class="codenumber">4</span> <span class="title">Invertibility, bases, and coordinate systems</span></a></div>
<ul class="structural">
<li>
<div class="toc-item"><a href="sec-matrix-inverse.html" class="internal"><span class="codenumber">4.1</span> <span class="title">Invertibility</span></a></div>
<ul class="structural">
<li><div class="toc-item"><a href="sec-matrix-inverse.html#subsection-53" class="internal"><span class="codenumber">4.1.1</span> <span class="title">Invertible matrices</span></a></div></li>
<li><div class="toc-item"><a href="sec-matrix-inverse.html#subsection-54" class="internal"><span class="codenumber">4.1.2</span> <span class="title">Solving equations with an inverse</span></a></div></li>
<li><div class="toc-item"><a href="sec-matrix-inverse.html#subsec-finding-inverses" class="internal"><span class="codenumber">4.1.3</span> <span class="title">Finding inverses</span></a></div></li>
<li><div class="toc-item"><a href="sec-matrix-inverse.html#subsection-56" class="internal"><span class="codenumber">4.1.4</span> <span class="title">Summary</span></a></div></li>
<li><div class="toc-item"><a href="sec-matrix-inverse.html#exercises-12" class="internal"><span class="codenumber">4.1.5</span> <span class="title">Exercises</span></a></div></li>
</ul>
</li>
<li>
<div class="toc-item"><a href="subsec-triangular-invertible.html" class="internal"><span class="codenumber">4.2</span> <span class="title">Triangular matrices and Gaussian elimination</span></a></div>
<ul class="structural">
<li><div class="toc-item"><a href="subsec-triangular-invertible.html#subsec-triangular-matrices" class="internal"><span class="codenumber">4.2.1</span> <span class="title">Triangular matrices</span></a></div></li>
<li><div class="toc-item"><a href="subsec-triangular-invertible.html#subsec-elementary-matrices" class="internal"><span class="codenumber">4.2.2</span> <span class="title">Elementary matrices</span></a></div></li>
<li><div class="toc-item"><a href="subsec-triangular-invertible.html#subsection-59" class="internal"><span class="codenumber">4.2.3</span> <span class="title">Summary</span></a></div></li>
<li><div class="toc-item"><a href="subsec-triangular-invertible.html#exercises-13" class="internal"><span class="codenumber">4.2.4</span> <span class="title">Exercises</span></a></div></li>
</ul>
</li>
<li>
<div class="toc-item"><a href="sec-bases.html" class="internal"><span class="codenumber">4.3</span> <span class="title">Bases and coordinate systems</span></a></div>
<ul class="structural">
<li><div class="toc-item"><a href="sec-bases.html#subsection-60" class="internal"><span class="codenumber">4.3.1</span> <span class="title">Bases</span></a></div></li>
<li><div class="toc-item"><a href="sec-bases.html#subsection-61" class="internal"><span class="codenumber">4.3.2</span> <span class="title">Coordinate systems</span></a></div></li>
<li><div class="toc-item"><a href="sec-bases.html#subsection-62" class="internal"><span class="codenumber">4.3.3</span> <span class="title">Examples of bases</span></a></div></li>
<li><div class="toc-item"><a href="sec-bases.html#subsection-63" class="internal"><span class="codenumber">4.3.4</span> <span class="title">Summary</span></a></div></li>
<li><div class="toc-item"><a href="sec-bases.html#exercises-14" class="internal"><span class="codenumber">4.3.5</span> <span class="title">Exercises</span></a></div></li>
</ul>
</li>
<li>
<div class="toc-item"><a href="sec-jpeg.html" class="internal"><span class="codenumber">4.4</span> <span class="title">Image compression</span></a></div>
<ul class="structural">
<li><div class="toc-item"><a href="sec-jpeg.html#subsection-64" class="internal"><span class="codenumber">4.4.1</span> <span class="title">Color models</span></a></div></li>
<li><div class="toc-item"><a href="sec-jpeg.html#subsection-65" class="internal"><span class="codenumber">4.4.2</span> <span class="title">The JPEG compression algorithm</span></a></div></li>
<li><div class="toc-item"><a href="sec-jpeg.html#subsection-66" class="internal"><span class="codenumber">4.4.3</span> <span class="title">Summary</span></a></div></li>
<li><div class="toc-item"><a href="sec-jpeg.html#exercises-15" class="internal"><span class="codenumber">4.4.4</span> <span class="title">Exercises</span></a></div></li>
</ul>
</li>
<li>
<div class="toc-item"><a href="sec-determinants.html" class="internal"><span class="codenumber">4.5</span> <span class="title">Determinants</span></a></div>
<ul class="structural">
<li><div class="toc-item"><a href="sec-determinants.html#subsection-67" class="internal"><span class="codenumber">4.5.1</span> <span class="title">Determinants of <span class="process-math">\(2\by2\)</span> matrices</span></a></div></li>
<li>
<div class="toc-item"><a href="sec-determinants.html#subsec-determinants-larger-matrices" class="internal"><span class="codenumber">4.5.2</span> <span class="title">Determinants of larger matrices</span></a></div>
<ul class="structural">
<li><div class="toc-item"><a href="sec-determinants.html#subsubsection-4" class="internal"><span class="codenumber">4.5.2.1</span> <span class="title">Determinants of elementary matrices</span></a></div></li>
<li><div class="toc-item"><a href="sec-determinants.html#subsubsec-rref-to-determinants" class="internal"><span class="codenumber">4.5.2.2</span> <span class="title">Using RREF to compute determinants</span></a></div></li>
<li><div class="toc-item"><a href="sec-determinants.html#subsubsection-6" class="internal"><span class="codenumber">4.5.2.3</span> <span class="title">Cofactor expansions</span></a></div></li>
</ul>
</li>
<li><div class="toc-item"><a href="sec-determinants.html#subsection-69" class="internal"><span class="codenumber">4.5.3</span> <span class="title">Summary</span></a></div></li>
<li><div class="toc-item"><a href="sec-determinants.html#exercises-16" class="internal"><span class="codenumber">4.5.4</span> <span class="title">Exercises</span></a></div></li>
</ul>
</li>
<li>
<div class="toc-item"><a href="sec-subspaces.html" class="internal"><span class="codenumber">4.6</span> <span class="title">Subspaces</span></a></div>
<ul class="structural">
<li><div class="toc-item"><a href="sec-subspaces.html#subsection-70" class="internal"><span class="codenumber">4.6.1</span> <span class="title">Subspaces</span></a></div></li>
<li><div class="toc-item"><a href="sec-subspaces.html#subsection-71" class="internal"><span class="codenumber">4.6.2</span> <span class="title">The column space of <span class="process-math">\(A\)</span></span></a></div></li>
<li><div class="toc-item"><a href="sec-subspaces.html#subsection-72" class="internal"><span class="codenumber">4.6.3</span> <span class="title">The null space of <span class="process-math">\(A\)</span></span></a></div></li>
<li><div class="toc-item"><a href="sec-subspaces.html#subsection-73" class="internal"><span class="codenumber">4.6.4</span> <span class="title">Summary</span></a></div></li>
<li><div class="toc-item"><a href="sec-subspaces.html#exercises-17" class="internal"><span class="codenumber">4.6.5</span> <span class="title">Exercises</span></a></div></li>
</ul>
</li>
<li>
<div class="toc-item"><a href="sec-gaussian-revisited.html" class="internal"><span class="codenumber">4.7</span> <span class="title">Partial pivoting and LU factorizations</span></a></div>
<ul class="structural">
<li><div class="toc-item"><a href="sec-gaussian-revisited.html#subsec-partial-pivot" class="internal"><span class="codenumber">4.7.1</span> <span class="title">Partial pivoting</span></a></div></li>
<li><div class="toc-item"><a href="sec-gaussian-revisited.html#subsection-75" class="internal"><span class="codenumber">4.7.2</span> <span class="title"><span class="process-math">\(LU\)</span> factorizations</span></a></div></li>
<li><div class="toc-item"><a href="sec-gaussian-revisited.html#subsection-76" class="internal"><span class="codenumber">4.7.3</span> <span class="title">Summary</span></a></div></li>
<li><div class="toc-item"><a href="sec-gaussian-revisited.html#exercises-18" class="internal"><span class="codenumber">4.7.4</span> <span class="title">Exercises</span></a></div></li>
</ul>
</li>
</ul>
</li>
<li>
<div class="toc-item"><a href="chap5.html" class="internal"><span class="codenumber">5</span> <span class="title">Eigenvalues and eigenvectors</span></a></div>
<ul class="structural">
<li>
<div class="toc-item"><a href="sec-eigen-intro.html" class="internal"><span class="codenumber">5.1</span> <span class="title">An introduction to eigenvalues and eigenvectors</span></a></div>
<ul class="structural">
<li><div class="toc-item"><a href="sec-eigen-intro.html#subsection-77" class="internal"><span class="codenumber">5.1.1</span> <span class="title">A few examples</span></a></div></li>
<li><div class="toc-item"><a href="sec-eigen-intro.html#subsec-eigen-use" class="internal"><span class="codenumber">5.1.2</span> <span class="title">The usefulness of eigenvalues and eigenvectors</span></a></div></li>
<li><div class="toc-item"><a href="sec-eigen-intro.html#subsection-79" class="internal"><span class="codenumber">5.1.3</span> <span class="title">Summary</span></a></div></li>
<li><div class="toc-item"><a href="sec-eigen-intro.html#exercises-19" class="internal"><span class="codenumber">5.1.4</span> <span class="title">Exercises</span></a></div></li>
</ul>
</li>
<li>
<div class="toc-item"><a href="sec-eigen-find.html" class="internal"><span class="codenumber">5.2</span> <span class="title">Finding eigenvalues and eigenvectors</span></a></div>
<ul class="structural">
<li><div class="toc-item"><a href="sec-eigen-find.html#subsection-80" class="internal"><span class="codenumber">5.2.1</span> <span class="title">The characteristic polynomial</span></a></div></li>
<li><div class="toc-item"><a href="sec-eigen-find.html#subsection-81" class="internal"><span class="codenumber">5.2.2</span> <span class="title">Finding eigenvectors</span></a></div></li>
<li><div class="toc-item"><a href="sec-eigen-find.html#subsection-82" class="internal"><span class="codenumber">5.2.3</span> <span class="title">The characteristic polynomial and the dimension of eigenspaces</span></a></div></li>
<li><div class="toc-item"><a href="sec-eigen-find.html#subsection-83" class="internal"><span class="codenumber">5.2.4</span> <span class="title">Using Python to find eigenvalues and eigenvectors</span></a></div></li>
<li><div class="toc-item"><a href="sec-eigen-find.html#subsection-84" class="internal"><span class="codenumber">5.2.5</span> <span class="title">Summary</span></a></div></li>
<li><div class="toc-item"><a href="sec-eigen-find.html#exercises-20" class="internal"><span class="codenumber">5.2.6</span> <span class="title">Exercises</span></a></div></li>
</ul>
</li>
<li>
<div class="toc-item"><a href="sec-eigen-diag.html" class="internal"><span class="codenumber">5.3</span> <span class="title">Diagonalization, similarity, and powers of a matrix</span></a></div>
<ul class="structural">
<li><div class="toc-item"><a href="sec-eigen-diag.html#subsection-85" class="internal"><span class="codenumber">5.3.1</span> <span class="title">Diagonalization of matrices</span></a></div></li>
<li><div class="toc-item"><a href="sec-eigen-diag.html#subsection-86" class="internal"><span class="codenumber">5.3.2</span> <span class="title">Powers of a diagonalizable matrix</span></a></div></li>
<li><div class="toc-item"><a href="sec-eigen-diag.html#subsection-87" class="internal"><span class="codenumber">5.3.3</span> <span class="title">Similarity and complex eigenvalues</span></a></div></li>
<li><div class="toc-item"><a href="sec-eigen-diag.html#subsection-88" class="internal"><span class="codenumber">5.3.4</span> <span class="title">Summary</span></a></div></li>
<li><div class="toc-item"><a href="sec-eigen-diag.html#exercises-21" class="internal"><span class="codenumber">5.3.5</span> <span class="title">Exercises</span></a></div></li>
</ul>
</li>
<li>
<div class="toc-item"><a href="sec-dynamical.html" class="internal"><span class="codenumber">5.4</span> <span class="title">Dynamical systems</span></a></div>
<ul class="structural">
<li><div class="toc-item"><a href="sec-dynamical.html#subsection-89" class="internal"><span class="codenumber">5.4.1</span> <span class="title">A first example</span></a></div></li>
<li><div class="toc-item"><a href="sec-dynamical.html#subsection-90" class="internal"><span class="codenumber">5.4.2</span> <span class="title">Classifying dynamical systems</span></a></div></li>
<li><div class="toc-item"><a href="sec-dynamical.html#subsection-91" class="internal"><span class="codenumber">5.4.3</span> <span class="title">A <span class="process-math">\(3\by3\)</span> system</span></a></div></li>
<li><div class="toc-item"><a href="sec-dynamical.html#subsection-92" class="internal"><span class="codenumber">5.4.4</span> <span class="title">Summary</span></a></div></li>
<li><div class="toc-item"><a href="sec-dynamical.html#exercises-22" class="internal"><span class="codenumber">5.4.5</span> <span class="title">Exercises</span></a></div></li>
</ul>
</li>
<li>
<div class="toc-item"><a href="sec-stochastic.html" class="internal"><span class="codenumber">5.5</span> <span class="title">Markov chains and Google‚Äôs PageRank algorithm</span></a></div>
<ul class="structural">
<li><div class="toc-item"><a href="sec-stochastic.html#subsection-93" class="internal"><span class="codenumber">5.5.1</span> <span class="title">A first example</span></a></div></li>
<li><div class="toc-item"><a href="sec-stochastic.html#subsection-94" class="internal"><span class="codenumber">5.5.2</span> <span class="title">Markov chains</span></a></div></li>
<li><div class="toc-item"><a href="sec-stochastic.html#subsec-google" class="internal"><span class="codenumber">5.5.3</span> <span class="title">Google‚Äôs PageRank algorithm</span></a></div></li>
<li><div class="toc-item"><a href="sec-stochastic.html#subsection-96" class="internal"><span class="codenumber">5.5.4</span> <span class="title">Summary</span></a></div></li>
<li><div class="toc-item"><a href="sec-stochastic.html#exercises-23" class="internal"><span class="codenumber">5.5.5</span> <span class="title">Exercises</span></a></div></li>
</ul>
</li>
<li>
<div class="toc-item"><a href="sec-power-method.html" class="internal"><span class="codenumber">5.6</span> <span class="title">Finding eigenvectors numerically</span></a></div>
<ul class="structural">
<li><div class="toc-item"><a href="sec-power-method.html#subsection-97" class="internal"><span class="codenumber">5.6.1</span> <span class="title">The power method</span></a></div></li>
<li><div class="toc-item"><a href="sec-power-method.html#subsection-98" class="internal"><span class="codenumber">5.6.2</span> <span class="title">Finding other eigenvalues</span></a></div></li>
<li><div class="toc-item"><a href="sec-power-method.html#subsection-99" class="internal"><span class="codenumber">5.6.3</span> <span class="title">Summary</span></a></div></li>
<li><div class="toc-item"><a href="sec-power-method.html#exercises-24" class="internal"><span class="codenumber">5.6.4</span> <span class="title">Exercises</span></a></div></li>
</ul>
</li>
</ul>
</li>
<li>
<div class="toc-item"><a href="chap6.html" class="internal"><span class="codenumber">6</span> <span class="title">Orthogonality and Least Squares</span></a></div>
<ul class="structural">
<li>
<div class="toc-item"><a href="sec-dot-product.html" class="internal"><span class="codenumber">6.1</span> <span class="title">The dot product</span></a></div>
<ul class="structural">
<li><div class="toc-item"><a href="sec-dot-product.html#sec-projections-and-dot-products" class="internal"><span class="codenumber">6.1.1</span> <span class="title">Projections and dot products</span></a></div></li>
<li><div class="toc-item"><a href="sec-dot-product.html#subsec-computing-dot-products" class="internal"><span class="codenumber">6.1.2</span> <span class="title">Computing dot products</span></a></div></li>
<li><div class="toc-item"><a href="sec-dot-product.html#subsection-102" class="internal"><span class="codenumber">6.1.3</span> <span class="title"><span class="process-math">\(k\)</span>-means clustering</span></a></div></li>
<li><div class="toc-item"><a href="sec-dot-product.html#subsection-103" class="internal"><span class="codenumber">6.1.4</span> <span class="title">Summary</span></a></div></li>
<li><div class="toc-item"><a href="sec-dot-product.html#exercises-25" class="internal"><span class="codenumber">6.1.5</span> <span class="title">Exercises</span></a></div></li>
</ul>
</li>
<li>
<div class="toc-item"><a href="sec-transpose.html" class="internal"><span class="codenumber">6.2</span> <span class="title">Orthogonal complements and the matrix transpose</span></a></div>
<ul class="structural">
<li><div class="toc-item"><a href="sec-transpose.html#subsection-104" class="internal"><span class="codenumber">6.2.1</span> <span class="title">Orthogonal complements</span></a></div></li>
<li><div class="toc-item"><a href="sec-transpose.html#subsection-105" class="internal"><span class="codenumber">6.2.2</span> <span class="title">The matrix transpose</span></a></div></li>
<li><div class="toc-item"><a href="sec-transpose.html#subsection-106" class="internal"><span class="codenumber">6.2.3</span> <span class="title">Properties of the matrix transpose</span></a></div></li>
<li><div class="toc-item"><a href="sec-transpose.html#subsection-107" class="internal"><span class="codenumber">6.2.4</span> <span class="title">Summary</span></a></div></li>
<li><div class="toc-item"><a href="sec-transpose.html#exercises-26" class="internal"><span class="codenumber">6.2.5</span> <span class="title">Exercises</span></a></div></li>
</ul>
</li>
<li>
<div class="toc-item"><a href="sec-orthogonal-bases.html" class="internal"><span class="codenumber">6.3</span> <span class="title">Orthogonal bases and projections</span></a></div>
<ul class="structural">
<li><div class="toc-item"><a href="sec-orthogonal-bases.html#subsection-108" class="internal"><span class="codenumber">6.3.1</span> <span class="title">Orthogonal sets</span></a></div></li>
<li><div class="toc-item"><a href="sec-orthogonal-bases.html#subsection-109" class="internal"><span class="codenumber">6.3.2</span> <span class="title">Orthogonal projections</span></a></div></li>
<li><div class="toc-item"><a href="sec-orthogonal-bases.html#subsection-110" class="internal"><span class="codenumber">6.3.3</span> <span class="title">Summary</span></a></div></li>
<li><div class="toc-item"><a href="sec-orthogonal-bases.html#exercises-27" class="internal"><span class="codenumber">6.3.4</span> <span class="title">Exercises</span></a></div></li>
</ul>
</li>
<li>
<div class="toc-item"><a href="sec-gram-schmidt.html" class="internal"><span class="codenumber">6.4</span> <span class="title">Finding orthogonal bases</span></a></div>
<ul class="structural">
<li><div class="toc-item"><a href="sec-gram-schmidt.html#subsection-111" class="internal"><span class="codenumber">6.4.1</span> <span class="title">Gram-Schmidt orthogonalization</span></a></div></li>
<li><div class="toc-item"><a href="sec-gram-schmidt.html#subsection-112" class="internal"><span class="codenumber">6.4.2</span> <span class="title"><span class="process-math">\(QR\)</span> factorizations</span></a></div></li>
<li><div class="toc-item"><a href="sec-gram-schmidt.html#subsection-113" class="internal"><span class="codenumber">6.4.3</span> <span class="title">Summary</span></a></div></li>
<li><div class="toc-item"><a href="sec-gram-schmidt.html#exercises-28" class="internal"><span class="codenumber">6.4.4</span> <span class="title">Exercises</span></a></div></li>
</ul>
</li>
<li>
<div class="toc-item"><a href="sec-least-squares.html" class="internal"><span class="codenumber">6.5</span> <span class="title">Least squares methods</span></a></div>
<ul class="structural">
<li><div class="toc-item"><a href="sec-least-squares.html#subsection-114" class="internal"><span class="codenumber">6.5.1</span> <span class="title">A first example</span></a></div></li>
<li><div class="toc-item"><a href="sec-least-squares.html#subsec-linear-model-framework" class="internal"><span class="codenumber">6.5.2</span> <span class="title">The linear model framework</span></a></div></li>
<li><div class="toc-item"><a href="sec-least-squares.html#subsection-116" class="internal"><span class="codenumber">6.5.3</span> <span class="title">Solving least squares problems</span></a></div></li>
<li><div class="toc-item"><a href="sec-least-squares.html#subsection-117" class="internal"><span class="codenumber">6.5.4</span> <span class="title">Using <span class="process-math">\(QR\)</span> factorizations</span></a></div></li>
<li><div class="toc-item"><a href="sec-least-squares.html#subsection-118" class="internal"><span class="codenumber">6.5.5</span> <span class="title">Polynomial Regression</span></a></div></li>
<li><div class="toc-item"><a href="sec-least-squares.html#subsec-skl-lm" class="internal"><span class="codenumber">6.5.6</span> <span class="title">Fitting linear models with standard tools</span></a></div></li>
<li><div class="toc-item"><a href="sec-least-squares.html#subsection-120" class="internal"><span class="codenumber">6.5.7</span> <span class="title">Summary</span></a></div></li>
<li><div class="toc-item"><a href="sec-least-squares.html#exercises-29" class="internal"><span class="codenumber">6.5.8</span> <span class="title">Exercises</span></a></div></li>
</ul>
</li>
</ul>
</li>
<li>
<div class="toc-item"><a href="chap7.html" class="internal"><span class="codenumber">7</span> <span class="title">The Spectral Theorem and singular value decompositions</span></a></div>
<ul class="structural">
<li>
<div class="toc-item"><a href="sec-variance-covariance.html" class="internal"><span class="codenumber">7.1</span> <span class="title">Sample statistics as linear algebra</span></a></div>
<ul class="structural">
<li><div class="toc-item"><a href="sec-variance-covariance.html#subsec-sample-mean" class="internal"><span class="codenumber">7.1.1</span> <span class="title">Sample mean</span></a></div></li>
<li><div class="toc-item"><a href="sec-variance-covariance.html#subsec-variance-covariance" class="internal"><span class="codenumber">7.1.2</span> <span class="title">Sample variance and covariance</span></a></div></li>
<li><div class="toc-item"><a href="sec-variance-covariance.html#subsection-123" class="internal"><span class="codenumber">7.1.3</span> <span class="title">Summary</span></a></div></li>
<li><div class="toc-item"><a href="sec-variance-covariance.html#exercises-30" class="internal"><span class="codenumber">7.1.4</span> <span class="title">Exercises</span></a></div></li>
</ul>
</li>
<li>
<div class="toc-item"><a href="sec-symmetric-matrices.html" class="internal"><span class="codenumber">7.2</span> <span class="title">Symmetric matrices</span></a></div>
<ul class="structural">
<li><div class="toc-item"><a href="sec-symmetric-matrices.html#subsection-124" class="internal"><span class="codenumber">7.2.1</span> <span class="title">Symmetric matrices and orthogonal diagonalization</span></a></div></li>
<li><div class="toc-item"><a href="sec-symmetric-matrices.html#subsection-125" class="internal"><span class="codenumber">7.2.2</span> <span class="title">Summary</span></a></div></li>
<li><div class="toc-item"><a href="sec-symmetric-matrices.html#exercises-31" class="internal"><span class="codenumber">7.2.3</span> <span class="title">Exercises</span></a></div></li>
</ul>
</li>
<li>
<div class="toc-item"><a href="sec-quadratic-forms.html" class="internal"><span class="codenumber">7.3</span> <span class="title">Quadratic forms</span></a></div>
<ul class="structural">
<li><div class="toc-item"><a href="sec-quadratic-forms.html#subsection-126" class="internal"><span class="codenumber">7.3.1</span> <span class="title">Quadratic forms</span></a></div></li>
<li><div class="toc-item"><a href="sec-quadratic-forms.html#subsection-127" class="internal"><span class="codenumber">7.3.2</span> <span class="title">Definite symmetric matrices</span></a></div></li>
<li><div class="toc-item"><a href="sec-quadratic-forms.html#subsection-128" class="internal"><span class="codenumber">7.3.3</span> <span class="title">Summary</span></a></div></li>
<li><div class="toc-item"><a href="sec-quadratic-forms.html#exercises-32" class="internal"><span class="codenumber">7.3.4</span> <span class="title">Exercises</span></a></div></li>
</ul>
</li>
<li>
<div class="toc-item"><a href="sec-pca.html" class="internal"><span class="codenumber">7.4</span> <span class="title">Principal Component Analysis</span></a></div>
<ul class="structural">
<li><div class="toc-item"><a href="sec-pca.html#subsection-129" class="internal"><span class="codenumber">7.4.1</span> <span class="title">Themes of Principal Component Analysis</span></a></div></li>
<li><div class="toc-item"><a href="sec-pca.html#subsection-130" class="internal"><span class="codenumber">7.4.2</span> <span class="title">Using Principal Component Analysis</span></a></div></li>
<li><div class="toc-item"><a href="sec-pca.html#subsection-131" class="internal"><span class="codenumber">7.4.3</span> <span class="title">Summary</span></a></div></li>
<li><div class="toc-item"><a href="sec-pca.html#exercises-33" class="internal"><span class="codenumber">7.4.4</span> <span class="title">Exercises</span></a></div></li>
</ul>
</li>
<li class="active">
<div class="toc-item"><a href="sec-svd-intro.html" class="internal"><span class="codenumber">7.5</span> <span class="title">Singular Value Decompositions</span></a></div>
<ul class="structural">
<li><div class="toc-item"><a href="sec-svd-intro.html#subsection-132" class="internal"><span class="codenumber">7.5.1</span> <span class="title">Finding singular value decompositions</span></a></div></li>
<li><div class="toc-item"><a href="sec-svd-intro.html#subsection-133" class="internal"><span class="codenumber">7.5.2</span> <span class="title">The structure of singular value decompositions</span></a></div></li>
<li><div class="toc-item"><a href="sec-svd-intro.html#subsection-134" class="internal"><span class="codenumber">7.5.3</span> <span class="title">Reduced singular value decompositions</span></a></div></li>
<li><div class="toc-item"><a href="sec-svd-intro.html#subsection-135" class="internal"><span class="codenumber">7.5.4</span> <span class="title">Summary</span></a></div></li>
<li><div class="toc-item"><a href="sec-svd-intro.html#exercises-34" class="internal"><span class="codenumber">7.5.5</span> <span class="title">Exercises</span></a></div></li>
</ul>
</li>
<li>
<div class="toc-item"><a href="sec-svd-uses.html" class="internal"><span class="codenumber">7.6</span> <span class="title">Using Singular Value Decompositions</span></a></div>
<ul class="structural">
<li><div class="toc-item"><a href="sec-svd-uses.html#subsection-136" class="internal"><span class="codenumber">7.6.1</span> <span class="title">Least squares problems</span></a></div></li>
<li><div class="toc-item"><a href="sec-svd-uses.html#subsection-137" class="internal"><span class="codenumber">7.6.2</span> <span class="title">Rank <span class="process-math">\(k\)</span> approximations</span></a></div></li>
<li><div class="toc-item"><a href="sec-svd-uses.html#subsection-138" class="internal"><span class="codenumber">7.6.3</span> <span class="title">Principal component analysis</span></a></div></li>
<li><div class="toc-item"><a href="sec-svd-uses.html#subsection-139" class="internal"><span class="codenumber">7.6.4</span> <span class="title">Image compressing and denoising</span></a></div></li>
<li><div class="toc-item"><a href="sec-svd-uses.html#subsection-140" class="internal"><span class="codenumber">7.6.5</span> <span class="title">Analyzing Supreme Court cases</span></a></div></li>
<li><div class="toc-item"><a href="sec-svd-uses.html#subsection-141" class="internal"><span class="codenumber">7.6.6</span> <span class="title">Summary</span></a></div></li>
<li><div class="toc-item"><a href="sec-svd-uses.html#exercises-35" class="internal"><span class="codenumber">7.6.7</span> <span class="title">Exercises</span></a></div></li>
</ul>
</li>
</ul>
</li>
<li>
<div class="toc-item"><a href="backmatter.html" class="internal"><span class="title">Back Matter</span></a></div>
<ul class="structural">
<li><div class="toc-item"><a href="app-notation.html" class="internal"><span class="codenumber">A</span> <span class="title">Notation</span></a></div></li>
<li>
<div class="toc-item"><a href="app-python-reference.html" class="internal"><span class="codenumber">B</span> <span class="title">Python Reference</span></a></div>
<ul class="structural">
<li><div class="toc-item"><a href="subsection-142.html" class="internal"><span class="codenumber">B.1</span> <span class="title">Accessing Python</span></a></div></li>
<li><div class="toc-item"><a href="subsection-143.html" class="internal"><span class="codenumber">B.2</span> <span class="title">Packages and libraries for data science</span></a></div></li>
<li><div class="toc-item"><a href="subsec-frequently-used-python.html" class="internal"><span class="codenumber">B.3</span> <span class="title">Frequently used Python commands</span></a></div></li>
</ul>
</li>
<li><div class="toc-item"><a href="index-1.html" class="internal"><span class="title">Index</span></a></div></li>
<li><div class="toc-item"><a href="colophon-2.html" class="internal"><span class="title">Colophon</span></a></div></li>
</ul>
</li>
</ul></nav></div>
<main class="ptx-main"><div id="ptx-content" class="ptx-content"><section class="section" id="sec-svd-intro"><h2 class="heading hide-type">
<span class="type">Section</span><span class="space"> </span><span class="codenumber">7.5</span><span class="space"> </span><span class="title">Singular Value Decompositions</span>
</h2>
<section class="introduction" id="introduction-45"><div class="para" id="p-8292">The Spectral Theorem has motivated the past few sections.  In particular, we applied the fact that symmetric matrices can be orthogonally diagonalized to simplify quadratic forms, which enabled us to use principal component analysis to reduce the dimension of a dataset.</div> <div class="para logical" id="p-8293">
<div class="para">But what can we do with matrices that are not symmetric or even square?  For instance, the following matrices are not diagonalizable, much less orthogonally so:</div>
<div class="displaymath process-math">
\begin{equation*}
\begin{bmatrix}
2 \amp 1 \\
0 \amp 2
\end{bmatrix},
\hspace{24pt}
\begin{bmatrix}
1 \amp 1 \amp 0 \\
-1 \amp 0 \amp 1
\end{bmatrix}.
\end{equation*}
</div>
<div class="para">In this section, we will develop a description of matrices called the <dfn class="terminology">singular value decomposition</dfn> that is, in many ways, analogous to an orthogonal diagonalization. For example, we have seen that any symmetric matrix can be written in the form <span class="process-math">\(QDQ^{\transpose}\)</span> where <span class="process-math">\(Q\)</span> is an orthogonal matrix and <span class="process-math">\(D\)</span> is diagonal.  A singular value decomposition will have the form <span class="process-math">\(U\Sigma V^{\transpose}\)</span> where <span class="process-math">\(U\)</span> and <span class="process-math">\(V\)</span> are orthogonal and <span class="process-math">\(\Sigma\)</span> is diagonal.  Most notably, we will see that <em class="emphasis">every</em> matrix has a singular value decomposition whether it‚Äôs symmetric or not.</div>
</div> <article class="exploration project-like" id="exploration-28"><h3 class="heading">
<span class="type">Preview Activity</span><span class="space"> </span><span class="codenumber">7.5.1</span><span class="period">.</span>
</h3>
<div class="para logical" id="p-8294">
<div class="para">Let‚Äôs review orthogonal diagonalizations and quadratic forms as our understanding of singular value decompositions will rely on them.</div>
<ol class="lower-alpha">
<li id="li-5579"><div class="para" id="p-8295">Suppose that <span class="process-math">\(A\)</span> is any matrix.  Explain why the matrix <span class="process-math">\(G = A^{\transpose}A\)</span> is symmetric.</div></li>
<li id="li-5580"><div class="para" id="p-8296">Suppose that <span class="process-math">\(A = \begin{bmatrix}
1 \amp 2 \\
-2 \amp -1 \\
\end{bmatrix}\text{.}\)</span>  Find the matrix <span class="process-math">\(G=A^{\transpose}A\)</span> and write out the quadratic form <span class="process-math">\(q_G\left(\twovec{x_1}{x_2}\right)\)</span> as a function of <span class="process-math">\(x_1\)</span> and <span class="process-math">\(x_2\text{.}\)</span>
</div></li>
<li id="li-5581">
<div class="para" id="p-8297">What is the maximum value of <span class="process-math">\(q_G(\xvec)\)</span> and in which direction does it occur?</div>
<pre class="ptx-sagecell sagecell-python" id="sage-301"><script type="text/x-sage">
</script></pre>
</li>
<li id="li-5582"><div class="para" id="p-8298">What is the minimum value of <span class="process-math">\(q_G(\xvec)\)</span> and in which direction does it occur?</div></li>
<li id="li-5583"><div class="para" id="p-8299">What is the geometric relationship between the directions in which the maximum and minimum values occur?</div></li>
</ol>
</div>
<div class="solutions">
<a href="" data-knowl="" class="id-ref solution-knowl original" data-refid="hk-solution-411" id="solution-411"><span class="type">Solution</span><span class="period">.</span></a><div class="hidden-content tex2jax_ignore" id="hk-solution-411"><div class="solution solution-like"><div class="para logical" id="p-8300"><ol class="lower-alpha">
<li id="li-5584"><div class="para" id="p-8301"><span class="process-math">\(G^{\transpose}=(A^{\transpose}A)^{\transpose} = A^{\transpose}(A^{\transpose})^{\transpose} = A^{\transpose}A=G\text{.}\)</span></div></li>
<li id="li-5585"><div class="para" id="p-8302">
<span class="process-math">\(G=\begin{bmatrix}
5 \amp 4 \\
4 \amp 5 \\
\end{bmatrix}\)</span> leads to the quadratic form <span class="process-math">\(q_G = 5x_1^2 +
8x_1x_2 + 5x_2^2\text{.}\)</span>
</div></li>
<li id="li-5586"><div class="para" id="p-8303">The maximum value of <span class="process-math">\(q_G\)</span> equals the largest eigenvalue of <span class="process-math">\(G\text{,}\)</span> which is <span class="process-math">\(\lambda_1=9\text{.}\)</span>  This maximum value occurs in the direction of the associated eigenvector <span class="process-math">\(\uvec_1 =
\twovec{\frac{1}{\sqrt{2}}}{\frac{1}{\sqrt{2}}}\text{.}\)</span>
</div></li>
<li id="li-5587"><div class="para" id="p-8304">The minimum value of <span class="process-math">\(q_G\)</span> equals the smallest eigenvalue of <span class="process-math">\(G\text{,}\)</span> which is <span class="process-math">\(\lambda_2=1\text{.}\)</span>  This minimum value occurs in the direction of the associated eigenvector <span class="process-math">\(\uvec_2 =
\twovec{\frac{1}{\sqrt{2}}}{-\frac{1}{\sqrt{2}}}\text{.}\)</span>
</div></li>
<li id="li-5588"><div class="para" id="p-8305">These two directions are orthogonal to each other.</div></li>
</ol></div></div></div>
</div></article></section><section class="subsection" id="subsection-132"><h3 class="heading hide-type">
<span class="type">Subsection</span><span class="space"> </span><span class="codenumber">7.5.1</span><span class="space"> </span><span class="title">Finding singular value decompositions</span>
</h3>
<div class="para" id="p-8306">We will begin by explaining what a singular value decomposition is and how we can find one for a given matrix <span class="process-math">\(A\text{.}\)</span>
</div>
<div class="para" id="p-8307">Recall how the orthogonal diagonalization of a symmetric matrix is formed: if <span class="process-math">\(A\)</span> is symmetric, we write <span class="process-math">\(A = QDQ^{\transpose}\)</span> where the diagonal entries of <span class="process-math">\(D\)</span> are the eigenvalues of <span class="process-math">\(A\)</span> and the columns of <span class="process-math">\(Q\)</span> are the associated eigenvectors.  Moreover, the eigenvalues are related to the maximum and minimum values of the associated quadratic form <span class="process-math">\(q_A(\uvec)\)</span> among all unit vectors.</div>
<div class="para logical" id="p-8308">
<div class="para">A general matrix, particularly a matrix that is not square, may not have eigenvalues and eigenvectors, but we can discover analogous features, called <dfn class="terminology">singular values</dfn> and <dfn class="terminology">singular vectors</dfn>, by studying a function somewhat similar to a quadratic form.  More specifically, any matrix <span class="process-math">\(A\)</span> defines a function</div>
<div class="displaymath process-math">
\begin{equation*}
l_A(\xvec) = |A\xvec|,
\end{equation*}
</div>
<div class="para">which measures the length of <span class="process-math">\(A\xvec\text{.}\)</span> For example, the diagonal matrix <span class="process-math">\(D=\begin{bmatrix}
3 \amp 0 \\
0 \amp -2 \\
\end{bmatrix}\)</span> gives the function <span class="process-math">\(l_D(\xvec) = \sqrt{9x_1^2 + 4x_2^2}\text{.}\)</span> The presence of the square root means that this function is not a quadratic form.  We can, however, define the singular values and vectors by looking for the maximum and minimum of this function <span class="process-math">\(l_A(\uvec)\)</span> among all unit vectors <span class="process-math">\(\uvec\text{.}\)</span>
</div>
</div>
<div class="para logical" id="p-8309">
<div class="para">While <span class="process-math">\(l_A(\xvec)\)</span> is not itself a quadratic form, it becomes one if we square it:</div>
<div class="displaymath process-math">
\begin{equation*}
\left(l_A(\xvec)\right)^2 = |A\xvec|^2 = (A\xvec)\cdot(A\xvec)
= \xvec\cdot(A^{\transpose}A\xvec)=q_{A^{\transpose}A}(\xvec)\text{.}
\end{equation*}
</div>
<div class="para"> We call <span class="process-math">\(G=A^{\transpose}A\text{,}\)</span> the <dfn class="terminology">Gram matrix</dfn> associated to <span class="process-math">\(A\)</span> and note that</div>
<div class="displaymath process-math">
\begin{equation*}
l_A(\xvec) = \sqrt{q_G(\xvec)}\text{.}
\end{equation*}
</div>
<div class="para">This is important in the next activity, which introduces singular values and singular vectors.</div>
</div>
<article class="activity project-like" id="activity-107"><h4 class="heading">
<span class="type">Activity</span><span class="space"> </span><span class="codenumber">7.5.2</span><span class="period">.</span>
</h4>
<div class="para" id="p-8310">The following interactive figure will help us explore singular values and vectors geometrically before we begin a more algebraic approach.</div> <figure class="figure figure-like" id="js-svd"><iframe id="interactive-svd" width="600" height="400" src="interactive-svd-if.html"></iframe><div class="instructions">
<a href="" data-knowl="" class="id-ref instructions-knowl original" data-refid="hk-instructions-14" id="instructions-14"><h5 class="heading"><span class="type">Instructions<span class="period">.</span></span></h5></a><div class="hidden-content tex2jax_ignore" id="hk-instructions-14"><div class="solution-like"><div class="para" id="p-8312">You may choose a <span class="process-math">\(2\by2\)</span> matrix <span class="process-math">\(A=\begin{bmatrix}
a \amp b \\
c \amp d \\
\end{bmatrix}\)</span> using the four sliders at the top of the diagram.  On the left, you may vary the red unit vector <span class="process-math">\(\xvec\)</span> by clicking in the head of the vector.</div></div></div>
</div>
<figcaption><span class="type">Figure</span><span class="space"> </span><span class="codenumber">7.5.1<span class="period">.</span></span><span class="space"> </span>Singular values, right singular vectors and left singular vectors</figcaption></figure> <div class="para" id="p-8313">Select the matrix <span class="process-math">\(A=\begin{bmatrix}
1 \amp 2 \\
-2 \amp - 1 \\
\end{bmatrix}\text{.}\)</span> As we vary the vector <span class="process-math">\(\xvec\text{,}\)</span> we see the vector <span class="process-math">\(A\xvec\)</span> on the right in gray while the height of the blue bar to the right tells us <span class="process-math">\(l_A(\xvec) =
|A\xvec|\text{.}\)</span>
</div> <div class="para logical" id="p-8314"><ol class="lower-alpha">
<li id="li-5589">
<div class="para" id="p-8315">The first <dfn class="terminology">singular value</dfn> <span class="process-math">\(\sigma_1\)</span> is the maximum value of <span class="process-math">\(l_A(\xvec)\)</span> and an associated <dfn class="terminology">right singular vector</dfn> <span class="process-math">\(\vvec_1\)</span> is a unit vector describing a direction in which this maximum occurs.</div>
<div class="para" id="p-8316">Use the diagram to find the first singular value <span class="process-math">\(\sigma_1\)</span> and an associated right singular vector <span class="process-math">\(\vvec_1\text{.}\)</span>
</div>
</li>
<li id="li-5590">
<div class="para" id="p-8317">The second singular value <span class="process-math">\(\sigma_2\)</span> is the minimum value of <span class="process-math">\(l_A(\xvec)\)</span> and an associated right singular vector <span class="process-math">\(\vvec_2\)</span> is a unit vector describing a direction in which this minimum occurs.</div>
<div class="para" id="p-8318">Use the diagram to find the second singular value <span class="process-math">\(\sigma_2\)</span> and an associated right singular vector <span class="process-math">\(\vvec_2\text{.}\)</span>
</div>
</li>
<li id="li-5591">
<div class="para" id="p-8319">Here‚Äôs how we can find the right singular values and vectors without using the diagram.  Remember that <span class="process-math">\(l_A(\xvec) = \sqrt{q_G(\xvec)}\)</span> where <span class="process-math">\(G=A^{\transpose}A\)</span> is the Gram matrix associated to <span class="process-math">\(A\text{.}\)</span>  Since <span class="process-math">\(G\)</span> is symmetric, it is orthogonally diagonalizable.  Find <span class="process-math">\(G\)</span> and an orthogonal diagonalization of it.</div>
<pre class="ptx-sagecell sagecell-python" id="sage-302"><script type="text/x-sage">
</script></pre>
<div class="para" id="p-8320">What is the maximum value of the quadratic form <span class="process-math">\(q_G(\xvec)\)</span> among all unit vectors and in which direction does it occur?  What is the minimum value of <span class="process-math">\(q_G(\xvec)\)</span> and in which direction does it occur?</div>
</li>
<li id="li-5592"><div class="para" id="p-8321">Because <span class="process-math">\(l_A(\xvec) = \sqrt{q_G(\xvec)}\text{,}\)</span> the first singular value <span class="process-math">\(\sigma_1\)</span> will be the square root of the maximum value of <span class="process-math">\(q_G(\xvec)\)</span> and <span class="process-math">\(\sigma_2\)</span> the square root of the minimum. Verify that the singular values that you found from the diagram are the square roots of the maximum and minimum values of <span class="process-math">\(q_G(\xvec)\text{.}\)</span>
</div></li>
<li id="li-5593"><div class="para" id="p-8322">Verify that the right singular vectors <span class="process-math">\(\vvec_1\)</span> and <span class="process-math">\(\vvec_2\)</span> that you found from the diagram are the directions in which the maximum and minimum values occur.</div></li>
<li id="li-5594">
<div class="para" id="p-8323">Finally, we introduce the <dfn class="terminology">left singular vectors</dfn> <span class="process-math">\(\uvec_1\)</span> and <span class="process-math">\(\uvec_2\)</span> by requiring that <span class="process-math">\(A\vvec_1 = \sigma_1\uvec_1\)</span> and <span class="process-math">\(A\vvec_2=\sigma_2\uvec_2\text{.}\)</span>  Find the two left singular vectors.</div>
<pre class="ptx-sagecell sagecell-python" id="sage-303"><script type="text/x-sage">
</script></pre>
</li>
<li id="li-5595"><div class="para logical" id="p-8324">
<div class="para">Form the matrices</div>
<div class="displaymath process-math">
\begin{equation*}
U = \begin{bmatrix}\uvec_1 \amp \uvec_2
\end{bmatrix}, \hspace{24pt}
\Sigma = \begin{bmatrix}
\sigma_1 \amp 0 \\
0 \amp \sigma_2 \\
\end{bmatrix}, \hspace{24pt}
V = \begin{bmatrix}\vvec_1 \amp \vvec_2
\end{bmatrix}
\end{equation*}
</div>
<div class="para">and explain why <span class="process-math">\(AV = U\Sigma\text{.}\)</span>
</div>
</div></li>
<li id="li-5596"><div class="para" id="p-8325">Finally, explain why <span class="process-math">\(A=U\Sigma V^{\transpose}\)</span> and verify that this relationship holds for this specific example.</div></li>
</ol></div>
<div class="solutions">
<a href="" data-knowl="" class="id-ref answer-knowl original" data-refid="hk-answer-324" id="answer-324"><span class="type">Answer</span><span class="period">.</span></a><div class="hidden-content tex2jax_ignore" id="hk-answer-324"><div class="answer solution-like"><div class="para logical" id="p-8326"><ol class="lower-alpha">
<li id="li-5597"><div class="para" id="p-8327">
<span class="process-math">\(\sigma_1=3\text{,}\)</span> <span class="process-math">\(\vvec_1 =
\twovec{1/\sqrt{2}}{1/\sqrt{2}}\)</span>
</div></li>
<li id="li-5598"><div class="para" id="p-8328">
<span class="process-math">\(\sigma_2=1\text{,}\)</span> <span class="process-math">\(\vvec_1 =
\twovec{1/\sqrt{2}}{-1/\sqrt{2}}\)</span>
</div></li>
<li id="li-5599"><div class="para" id="p-8329">The maximum value of <span class="process-math">\(q_G(\xvec)\)</span> is <span class="process-math">\(9\text{,}\)</span> which occurs in the direction <span class="process-math">\(\twovec{1/\sqrt{2}}{1/\sqrt{2}}\text{.}\)</span>  The minimum value of <span class="process-math">\(q_G(\xvec)\)</span> is <span class="process-math">\(1\text{,}\)</span> which occurs in the direction <span class="process-math">\(\twovec{1/\sqrt{2}}{-1/\sqrt{2}}\text{.}\)</span>
</div></li>
<li id="li-5600"><div class="para" id="p-8330">
<span class="process-math">\(\sigma_1 = \sqrt{9} = 3\)</span> and <span class="process-math">\(\sigma_2 = \sqrt{1}
= 1\)</span>
</div></li>
<li id="li-5601"><div class="para" id="p-8331">
<span class="process-math">\(\vvec_1\)</span> agrees with the direction in which <span class="process-math">\(q_G(\xvec)\)</span> has its maximum value.  The corresponding fact is true for <span class="process-math">\(\vvec_2\text{.}\)</span>
</div></li>
<li id="li-5602"><div class="para" id="p-8332">
<span class="process-math">\(\uvec_1=\twovec{1/\sqrt{2}}{-1/\sqrt{2}}\)</span> and <span class="process-math">\(\uvec_2 = \twovec{-1/\sqrt{2}}{-1/\sqrt{2}}\)</span>
</div></li>
<li id="li-5603"><div class="para" id="p-8333"><span class="process-math">\(AV = \begin{bmatrix} A\vvec_1 \amp A\vvec_2
\end{bmatrix} = \begin{bmatrix} \sigma_1\uvec_1 \amp
\sigma_2\uvec_2 \end{bmatrix} = U\Sigma\text{.}\)</span></div></li>
<li id="li-5604"><div class="para" id="p-8334">Since <span class="process-math">\(V\)</span> is an orthogonal matrix, we have <span class="process-math">\(A = AVV^{\transpose} = U\Sigma V^{\transpose}\text{.}\)</span>
</div></li>
</ol></div></div></div>
<a href="" data-knowl="" class="id-ref solution-knowl original" data-refid="hk-solution-412" id="solution-412"><span class="type">Solution</span><span class="period">.</span></a><div class="hidden-content tex2jax_ignore" id="hk-solution-412"><div class="solution solution-like"><div class="para logical" id="p-8335"><ol class="lower-alpha">
<li id="li-5605"><div class="para" id="p-8336">The maximum value of <span class="process-math">\(l_A(\xvec)\)</span> is <span class="process-math">\(\sigma_1=3\text{,}\)</span> which occurs at <span class="process-math">\(\vvec_1 =
\twovec{1/\sqrt{2}}{1/\sqrt{2}}\text{.}\)</span>
</div></li>
<li id="li-5606"><div class="para" id="p-8337">The minimum value of <span class="process-math">\(l_A(\xvec)\)</span> is <span class="process-math">\(\sigma_2=1\text{,}\)</span> which occurs at <span class="process-math">\(\vvec_1 =
\twovec{1/\sqrt{2}}{-1/\sqrt{2}}\text{.}\)</span>
</div></li>
<li id="li-5607"><div class="para logical" id="p-8338">
<div class="para">
<span class="process-math">\(G = \begin{bmatrix}
5 \amp 4 \\
4 \amp 5 \\
\end{bmatrix} = QDQ^{\transpose}\)</span> where</div>
<div class="displaymath process-math">
\begin{equation*}
D = \begin{bmatrix}
9 \amp 0 \\
0 \amp 1 \\
\end{bmatrix},\hspace{24pt}
Q = \begin{bmatrix}
1/\sqrt{2} \amp 1/\sqrt{2} \\
1/\sqrt{2} \amp -1/\sqrt{2} \\
\end{bmatrix}\text{.}
\end{equation*}
</div>
<div class="para">The maximum value of <span class="process-math">\(q_G(\xvec)\)</span> is therefore <span class="process-math">\(\lambda_1=9\text{,}\)</span> which occurs in the direction <span class="process-math">\(\twovec{1/\sqrt{2}}{1/\sqrt{2}}\text{.}\)</span>  The minimum value of <span class="process-math">\(q_G(\xvec)\)</span> is <span class="process-math">\(\lambda_2=1\text{,}\)</span> which occurs in the direction <span class="process-math">\(\twovec{1/\sqrt{2}}{-1/\sqrt{2}}\text{.}\)</span>
</div>
</div></li>
<li id="li-5608"><div class="para" id="p-8339">We see that <span class="process-math">\(\sigma_1 = \sqrt{\lambda_1} = \sqrt{9}
= 3\)</span> and <span class="process-math">\(\sigma_2 = \sqrt{\lambda_2} = \sqrt{1}
= 1\text{.}\)</span>
</div></li>
<li id="li-5609"><div class="para" id="p-8340">We also see that <span class="process-math">\(\vvec_1\text{,}\)</span> the first right singular vector, agrees with the direction in which <span class="process-math">\(q_G(\xvec)\)</span> has its maximum value.  The corresponding fact is true for <span class="process-math">\(\vvec_2\text{.}\)</span>
</div></li>
<li id="li-5610"><div class="para" id="p-8341">We find that <span class="process-math">\(\uvec_1=\twovec{1/\sqrt{2}}{-1/\sqrt{2}}\)</span> and <span class="process-math">\(\uvec_2 = \twovec{-1/\sqrt{2}}{-1/\sqrt{2}}\text{.}\)</span>
</div></li>
<li id="li-5611"><div class="para" id="p-8342"><span class="process-math">\(AV = \begin{bmatrix} A\vvec_1 \amp A\vvec_2
\end{bmatrix} = \begin{bmatrix} \sigma_1\uvec_1 \amp
\sigma_2\uvec_2 \end{bmatrix} = U\Sigma\text{.}\)</span></div></li>
<li id="li-5612"><div class="para" id="p-8343">Since <span class="process-math">\(V\)</span> is an orthogonal matrix, we have <span class="process-math">\(A = AVV^{\transpose} = U\Sigma V^{\transpose}\text{.}\)</span>
</div></li>
</ol></div></div></div>
</div></article><div class="para" id="p-8344">As this activity shows, the singular values of <span class="process-math">\(A\)</span> are the maximum and minimum values of <span class="process-math">\(l_A(\xvec)=|A\xvec|\)</span> among all unit vectors and the right singular vectors <span class="process-math">\(\vvec_1\)</span> and <span class="process-math">\(\vvec_2\)</span> are the directions in which they occur.  The key to finding the singular values and vectors is to utilize the Gram matrix <span class="process-math">\(G\)</span> and its associated quadratic form <span class="process-math">\(q_G(\xvec)\text{.}\)</span>  We will illustrate with some more examples.</div>
<article class="example example-like" id="example-91"><h4 class="heading">
<span class="type">Example</span><span class="space"> </span><span class="codenumber">7.5.2</span><span class="period">.</span>
</h4>
<div class="para" id="p-8345">We will find a singular value decomposition of the matrix <span class="process-math">\(A=\begin{bmatrix}
1 \amp 2 \\
-1 \amp 2
\end{bmatrix}
\text{.}\)</span>  Notice that this matrix is not symmetric so it cannot be orthogonally diagonalized.</div> <div class="para logical" id="p-8346">
<div class="para">We begin by constructing the Gram matrix <span class="process-math">\(G = A^{\transpose}A =
\begin{bmatrix} 
2 \amp 0 \\
0 \amp 8 \\
\end{bmatrix}\text{.}\)</span>  Since <span class="process-math">\(G\)</span> is symmetric, it can be orthogonally diagonalized with</div>
<div class="displaymath process-math">
\begin{equation*}
D = \begin{bmatrix}
8 \amp 0 \\
0 \amp 2 \\
\end{bmatrix},\hspace{24pt}
Q = \begin{bmatrix}
0 \amp 1 \\
1 \amp 0 \\
\end{bmatrix}\text{.}
\end{equation*}
</div>
</div> <div class="para" id="p-8347">We now know that the maximum value of the quadratic form <span class="process-math">\(q_G(\xvec)\)</span> is 8, which occurs in the direction <span class="process-math">\(\twovec01\text{.}\)</span>  Since <span class="process-math">\(l_A(\xvec) =
\sqrt{q_G(\xvec)}\text{,}\)</span> this tells us that the maximum value of <span class="process-math">\(l_A(\xvec)\text{,}\)</span> the first singular value, is <span class="process-math">\(\sigma_1=\sqrt{8}\)</span> and that this occurs in the direction of the first right singular vector <span class="process-math">\(\vvec_1=\twovec01\text{.}\)</span>
</div> <div class="para" id="p-8348">In the same way, we also know that the second singular value <span class="process-math">\(\sigma_2=\sqrt{2}\)</span> with associated right singular vector <span class="process-math">\(\vvec_2=\twovec10\text{.}\)</span>
</div> <div class="para" id="p-8349">The first left singular vector <span class="process-math">\(\uvec_1\)</span> is defined by <span class="process-math">\(A\vvec_1 = \twovec22 = \sigma_1\uvec_1\text{.}\)</span>  Because <span class="process-math">\(\sigma_1 = \sqrt{8}\text{,}\)</span> we have <span class="process-math">\(\uvec_1
= \twovec{1/\sqrt{2}}{1/\sqrt{2}}\text{.}\)</span>  Notice that <span class="process-math">\(\uvec_1\)</span> is a unit vector because <span class="process-math">\(\sigma_1 =
|A\vvec_1|\text{.}\)</span>
</div> <div class="para" id="p-8350">In the same way, the second left singular vector is defined by <span class="process-math">\(A\vvec_2 = \twovec1{-1} = \sigma_2\uvec_2\text{,}\)</span> which gives us <span class="process-math">\(\uvec_2 = \twovec{1/\sqrt{2}}{-1/\sqrt{2}}\text{.}\)</span>
</div> <div class="para logical" id="p-8351">
<div class="para">We then construct</div>
<div class="displaymath process-math" id="md-56">
\begin{align*}
U \amp {}={} \begin{bmatrix}
\uvec_1 \amp \uvec_2 \end{bmatrix} =
\begin{bmatrix}
1/\sqrt{2} \amp 1/\sqrt{2} \\
1/\sqrt{2} \amp -1/\sqrt{2} \\
\end{bmatrix}\\
\Sigma \amp {}={} \begin{bmatrix}
\sigma_1 \amp 0 \\
0 \amp \sigma_2 \\
\end{bmatrix} = 
\begin{bmatrix} 
\sqrt{8} \amp 0 \\
0 \amp \sqrt{2} \\
\end{bmatrix}\\
V \amp {}={} \begin{bmatrix}
\vvec_1 \amp \vvec_2 \end{bmatrix} =
\begin{bmatrix}
0 \amp 1 \\
1 \amp 0 \\
\end{bmatrix}
\end{align*}
</div>
</div> <div class="para logical" id="p-8352">
<div class="para">We now have <span class="process-math">\(AV=U\Sigma\)</span> because</div>
<div class="displaymath process-math">
\begin{equation*}
AV = \begin{bmatrix}
A\vvec_1 \amp A\vvec_2
\end{bmatrix}
= \begin{bmatrix}
\sigma_1\uvec_1 \amp \sigma_2\uvec_2
\end{bmatrix}
= \Sigma U\text{.}
\end{equation*}
</div>
<div class="para">Because the right singular vectors, the columns of <span class="process-math">\(V\text{,}\)</span> are eigenvectors of the symmetric matrix <span class="process-math">\(G\text{,}\)</span> they form an orthonormal basis, which means that <span class="process-math">\(V\)</span> is orthogonal.  Therefore, we have <span class="process-math">\((AV)V^{\transpose} = A = U\Sigma
V^{\transpose}\text{.}\)</span>  This gives the singular value decomposition</div>
<div class="displaymath process-math">
\begin{equation*}
A = \begin{bmatrix}
1 \amp 2 \\
-1 \amp 2 \\
\end{bmatrix} =
\begin{bmatrix}
1/\sqrt{2} \amp 1/\sqrt{2} \\
1/\sqrt{2} \amp -1/\sqrt{2} \\
\end{bmatrix}
\begin{bmatrix}
\sqrt{8} \amp 0 \\
0 \amp \sqrt{2} \\
\end{bmatrix}
\begin{bmatrix}
0 \amp 1 \\
1 \amp 0 \\
\end{bmatrix}^{\transpose}
= U\Sigma V^{\transpose}\text{.}
\end{equation*}
</div>
</div></article><article class="assemblage assemblage-like" id="assemblage-svd"><h4 class="heading"><span class="title">Computing the SVD.</span></h4>
<div class="para logical" id="p-8353">
<div class="para">We find a singular value decomposition of a matrix <span class="process-math">\(A\)</span> in the following way:</div>
<ul class="disc">
<li id="li-5613"><div class="para" id="p-8354">Construct the Gram matrix <span class="process-math">\(G=A^{\transpose}A\)</span> and find an orthogonal diagonalization to obtain eigenvalues <span class="process-math">\(\lambda_i\)</span> and an orthonormal basis of eigenvectors.</div></li>
<li id="li-5614"><div class="para" id="p-8355">The singular values of <span class="process-math">\(A\)</span> are the square roots of eigenvalues <span class="process-math">\(\lambda_i\)</span> of <span class="process-math">\(G\text{;}\)</span> that is, <span class="process-math">\(\sigma_i = \sqrt{\lambda_i}\text{.}\)</span>  By convention, the singular values are listed in decreasing order: <span class="process-math">\(\sigma_1 \geq \sigma_2 \geq \ldots
\text{.}\)</span>  The right singular vectors <span class="process-math">\(\vvec_i\)</span> are the associated eigenvectors of <span class="process-math">\(G\text{.}\)</span>
</div></li>
<li id="li-5615">
<div class="para logical" id="p-8356">
<div class="para">The left singular vectors <span class="process-math">\(\uvec_i\)</span> are found by solving <span class="process-math">\(A\vvec_i = \sigma_i\uvec_i\text{.}\)</span>  That is,</div>
<div class="displaymath process-math">
\begin{equation*}
\uvec_i = \frac{A\vvec_i}{\sigma_i}\text{.}
\end{equation*}
</div>
<div class="para">Because <span class="process-math">\(\sigma_i=|A\vvec_i|\text{,}\)</span> we know that <span class="process-math">\(\uvec_i\)</span> will be a unit vector.</div>
</div>
<div class="para logical" id="p-8357">
<div class="para">In fact, the left singular vectors will also form an orthonormal basis.  To see this, suppose that the associcated singular values are nonzero.  We then have:</div>
<div class="displaymath process-math" id="md-57">
\begin{align*}
\sigma_i\sigma_j(\uvec_i\cdot\uvec_j) \amp {}={}
(\sigma_i\uvec_i)\cdot(\sigma_j\uvec_j) =
(A\vvec_i)\cdot(A\vvec_j)\\
\amp {}={}
\vvec_i\cdot(A^{\transpose}A\vvec_j) \\
\amp {}={}
\vvec_i\cdot(G\vvec_j) =
\lambda_j\vvec_i\cdot\vvec_j = 0
\end{align*}
</div>
<div class="para">since the right singular vectors are orthogonal.</div>
</div>
</li>
</ul>
</div></article><article class="example example-like" id="example-92"><h4 class="heading">
<span class="type">Example</span><span class="space"> </span><span class="codenumber">7.5.3</span><span class="period">.</span>
</h4>
<div class="para logical" id="p-8358">
<div class="para">Let‚Äôs find a singular value decomposition for the symmetric matrix <span class="process-math">\(A=\begin{bmatrix}
1 \amp 2 \\
2 \amp 1
\end{bmatrix}\text{.}\)</span> The associated Gram matrix is</div>
<div class="displaymath process-math">
\begin{equation*}
G = A^{\transpose}A = \begin{bmatrix}
5 \amp 4 \\
4 \amp 5 \\
\end{bmatrix}\text{,}
\end{equation*}
</div>
<div class="para">which has an orthogonal diagonalization with</div>
<div class="displaymath process-math">
\begin{equation*}
D = \begin{bmatrix}
9 \amp 0 \\
0 \amp 1 \\
\end{bmatrix},\hspace{24pt}
Q = \begin{bmatrix}
1/\sqrt{2} \amp 1/\sqrt{2} \\
1/\sqrt{2} \amp -1/\sqrt{2} \\
\end{bmatrix}\text{.}
\end{equation*}
</div>
<div class="para">This gives singular values and vectors</div>
<div class="displaymath process-math" id="md-58">
\begin{align*}
\sigma_1 = 3, \hspace{24pt}\amp \vvec_1 =
\twovec{1/\sqrt{2}}{1/\sqrt{2}}, 
\amp \uvec_1 = \twovec{1/\sqrt{2}}{1/\sqrt{2}}\\
\sigma_2 = 1, \hspace{24pt}\amp \vvec_2 =
\twovec{1/\sqrt{2}}{-1/\sqrt{2}}, 
\amp \uvec_2 = \twovec{-1/\sqrt{2}}{1/\sqrt{2}}
\end{align*}
</div>
<div class="para">and the singular value decomposition <span class="process-math">\(A=U\Sigma V^{\transpose}\)</span> where</div>
<div class="displaymath process-math">
\begin{equation*}
U = \begin{bmatrix}
1/\sqrt{2} \amp -1/\sqrt{2} \\
1/\sqrt{2} \amp 1/\sqrt{2}
\end{bmatrix},\hspace{24pt}
\Sigma = \begin{bmatrix}
3 \amp 0 \\
0 \amp 1
\end{bmatrix},\hspace{24pt}
V = \begin{bmatrix}
1/\sqrt{2} \amp 1/\sqrt{2} \\
1/\sqrt{2} \amp -1/\sqrt{2}
\end{bmatrix}.
\end{equation*}
</div>
</div> <div class="para" id="p-8359">This example is special because <span class="process-math">\(A\)</span> is symmetric.  With a little thought, it‚Äôs possible to relate this singular value decomposition to an orthogonal diagonalization of <span class="process-math">\(A\)</span> using the fact that <span class="process-math">\(G=A^{\transpose}A = A^2\text{.}\)</span>
</div></article><article class="activity project-like" id="activity-108"><h4 class="heading">
<span class="type">Activity</span><span class="space"> </span><span class="codenumber">7.5.3</span><span class="period">.</span>
</h4>
<div class="para logical" id="p-8360">
<div class="para">In this activity, we will construct the singular value decomposition of <span class="process-math">\(A=\begin{bmatrix} 1 \amp 0 \amp -1 \\
1 \amp 1 \amp 1
\end{bmatrix}\text{.}\)</span> Notice that this matrix is not square so there are no eigenvalues and eigenvectors associated to it.</div>
<ol class="lower-alpha">
<li id="li-5616">
<div class="para" id="p-8361">Construct the Gram matrix <span class="process-math">\(G=A^{\transpose}A\)</span> and find an orthogonal diagonalization of it.</div>
<pre class="ptx-sagecell sagecell-python" id="sage-304"><script type="text/x-sage">
</script></pre>
</li>
<li id="li-5617"><div class="para" id="p-8362">Identify the singular values of <span class="process-math">\(A\)</span> and the right singular vectors <span class="process-math">\(\vvec_1\text{,}\)</span> <span class="process-math">\(\vvec_2\text{,}\)</span> and <span class="process-math">\(\vvec_3\text{.}\)</span>  What is the dimension of these vectors?  How many nonzero singular values are there?</div></li>
<li id="li-5618"><div class="para" id="p-8363">Find the left singular vectors <span class="process-math">\(\uvec_1\)</span> and <span class="process-math">\(\uvec_2\)</span> using the fact that <span class="process-math">\(A\vvec_i =
\sigma_i\uvec_i\text{.}\)</span> What is the dimension of these vectors? What happens if you try to find a third left singular vector <span class="process-math">\(\uvec_3\)</span> in this way?</div></li>
<li id="li-5619"><div class="para" id="p-8364">As before, form the orthogonal matrices <span class="process-math">\(U\)</span> and <span class="process-math">\(V\)</span> from the left and right singular vectors. What are the shapes of <span class="process-math">\(U\)</span> and <span class="process-math">\(V\text{?}\)</span> How do these shapes relate to the number of rows and columns of <span class="process-math">\(A\text{?}\)</span>
</div></li>
<li id="li-5620">
<div class="para logical" id="p-8365">
<div class="para">Now form <span class="process-math">\(\Sigma\)</span> so that it has the same shape as <span class="process-math">\(A\text{:}\)</span>
</div>
<div class="displaymath process-math">
\begin{equation*}
\Sigma = \begin{bmatrix}
\sigma_1 \amp 0 \amp 0 \\
0 \amp \sigma_2 \amp 0
\end{bmatrix}
\end{equation*}
</div>
<div class="para">and verify that <span class="process-math">\(A = U\Sigma V^{\transpose}\text{.}\)</span>
</div>
</div>
<pre class="ptx-sagecell sagecell-python" id="sage-305"><script type="text/x-sage">
</script></pre>
</li>
<li id="li-5621"><div class="para" id="p-8366">How can you use this singular value decomposition of <span class="process-math">\(A=U\Sigma V^{\transpose}\)</span> to easily find a singular value decomposition of <span class="process-math">\(A^{\transpose}=\begin{bmatrix}
1 \amp 1 \\
0 \amp 1 \\
-1 \amp 1 \\
\end{bmatrix}\text{?}\)</span>
</div></li>
</ol>
</div>
<div class="solutions">
<a href="" data-knowl="" class="id-ref answer-knowl original" data-refid="hk-answer-325" id="answer-325"><span class="type">Answer</span><span class="period">.</span></a><div class="hidden-content tex2jax_ignore" id="hk-answer-325"><div class="answer solution-like"><div class="para logical" id="p-8367"><ol class="lower-alpha">
<li id="li-5622"><div class="para logical" id="p-8368">
<div class="para">
<span class="process-math">\(G\)</span> can be orthogonally diagaonalized with</div>
<div class="displaymath process-math">
\begin{equation*}
D = \begin{bmatrix}
3 \amp 0 \amp 0 \\
0 \amp 2 \amp 0 \\
0 \amp 0 \amp 0
\end{bmatrix},\hspace{24pt}
Q = \begin{bmatrix}
1/\sqrt{3} \amp 1/\sqrt{2} \amp 1/\sqrt{6} \\
1/\sqrt{3} \amp 0 \amp -2/\sqrt{6} \\
1/\sqrt{3} \amp -1/\sqrt{2} \amp 1/\sqrt{6} 
\end{bmatrix}.
\end{equation*}
</div>
</div></li>
<li id="li-5623"><div class="para" id="p-8369">
<span class="process-math">\(\sigma_1 = \sqrt{3}\text{,}\)</span> <span class="process-math">\(\sigma_2 = \sqrt{2}\text{,}\)</span> and <span class="process-math">\(\sigma_3 = 0\text{.}\)</span> The three right singular vectors <span class="process-math">\(\vvec_i\)</span> are the columns of <span class="process-math">\(Q\text{.}\)</span>
</div></li>
<li id="li-5624"><div class="para" id="p-8370">
<span class="process-math">\(\uvec_1 = \twovec01\)</span> and <span class="process-math">\(\uvec_2 = \twovec10\)</span>
</div></li>
<li id="li-5625"><div class="para logical" id="p-8371">
<div class="para">We have</div>
<div class="displaymath process-math">
\begin{equation*}
U = \begin{bmatrix}
0 \amp 1 \\
1 \amp 0 \\
\end{bmatrix},\hspace{24pt}
V = \begin{bmatrix}
1/\sqrt{3} \amp 1/\sqrt{2} \amp 1/\sqrt{6} \\
1/\sqrt{3} \amp 0 \amp -2/\sqrt{6} \\
1/\sqrt{3} \amp -1/\sqrt{2} \amp 1/\sqrt{6} 
\end{bmatrix}\text{.}
\end{equation*}
</div>
</div></li>
<li id="li-5626"><div class="para" id="p-8372">With <span class="process-math">\(\Sigma = \begin{bmatrix}
\sqrt{3} \amp 0 \amp 0 \\
0 \amp \sqrt{2} \amp 0
\end{bmatrix}\text{,}\)</span> we see that <span class="process-math">\(A=U\Sigma V^{\transpose}\text{.}\)</span>
</div></li>
<li id="li-5627"><div class="para" id="p-8373"><span class="process-math">\(A^{\transpose}=(U\Sigma V^{\transpose})^{\transpose}
= V\Sigma^{\transpose} U^{\transpose}\text{.}\)</span></div></li>
</ol></div></div></div>
<a href="" data-knowl="" class="id-ref solution-knowl original" data-refid="hk-solution-413" id="solution-413"><span class="type">Solution</span><span class="period">.</span></a><div class="hidden-content tex2jax_ignore" id="hk-solution-413"><div class="solution solution-like"><div class="para logical" id="p-8374"><ol class="lower-alpha">
<li id="li-5628"><div class="para logical" id="p-8375">
<div class="para">Constructing the Gram matrix of <span class="process-math">\(A\)</span> gives the <span class="process-math">\(3\by3\)</span> matrix</div>
<div class="displaymath process-math">
\begin{equation*}
G = \begin{bmatrix}
2 \amp 1 \amp 0 \\
1 \amp 1 \amp 1 \\
0 \amp 1 \amp 2
\end{bmatrix}\text{,}
\end{equation*}
</div>
<div class="para">which can be orthogonally diagaonalized with</div>
<div class="displaymath process-math">
\begin{equation*}
D = \begin{bmatrix}
3 \amp 0 \amp 0 \\
0 \amp 2 \amp 0 \\
0 \amp 0 \amp 0
\end{bmatrix},\hspace{24pt}
Q = \begin{bmatrix}
1/\sqrt{3} \amp 1/\sqrt{2} \amp 1/\sqrt{6} \\
1/\sqrt{3} \amp 0 \amp -2/\sqrt{6} \\
1/\sqrt{3} \amp -1/\sqrt{2} \amp 1/\sqrt{6} 
\end{bmatrix}.
\end{equation*}
</div>
</div></li>
<li id="li-5629"><div class="para" id="p-8376">This tells us that <span class="process-math">\(\sigma_1 = \sqrt{3}\text{,}\)</span> <span class="process-math">\(\sigma_2 = \sqrt{2}\text{,}\)</span> and <span class="process-math">\(\sigma_3 = 0\text{.}\)</span> The three right singular vectors <span class="process-math">\(\vvec_i\)</span> are the columns of <span class="process-math">\(Q\text{.}\)</span>  Since these vectors are 3-dimensional, it follows that the matrix <span class="process-math">\(A\)</span> will be <span class="process-math">\(3\by3\text{.}\)</span>
</div></li>
<li id="li-5630">
<div class="para logical" id="p-8377">
<div class="para">We have</div>
<div class="displaymath process-math" id="md-59">
\begin{align*}
A\vvec_1 \amp = \twovec{0}{\sqrt{3}} = \sqrt{3} \twovec01\\
A\vvec_2 \amp = \twovec{\sqrt{2}}0 = \sqrt{2} \twovec10
\end{align*}
</div>
<div class="para">showing that</div>
<div class="displaymath process-math">
\begin{equation*}
\uvec_1 = \twovec01, \hspace{24pt} \uvec_2 = \twovec10.
\end{equation*}
</div>
<div class="para">Notice that <span class="process-math">\(A\vvec_3 = \zerovec\)</span> so it is not possible to find a vector <span class="process-math">\(\uvec_3\)</span> in this way.</div>
</div>
<div class="para" id="p-8378">The left singular vectors are 2-dimensional so <span class="process-math">\(U\)</span> will be a <span class="process-math">\(2\by2\)</span> matrix.</div>
</li>
<li id="li-5631"><div class="para logical" id="p-8379">
<div class="para">We have</div>
<div class="displaymath process-math">
\begin{equation*}
U = \begin{bmatrix}
0 \amp 1 \\
1 \amp 0 \\
\end{bmatrix},\hspace{24pt}
V = \begin{bmatrix}
1/\sqrt{3} \amp 1/\sqrt{2} \amp 1/\sqrt{6} \\
1/\sqrt{3} \amp 0 \amp -2/\sqrt{6} \\
1/\sqrt{3} \amp -1/\sqrt{2} \amp 1/\sqrt{6} 
\end{bmatrix}\text{.}
\end{equation*}
</div>
<div class="para">The matrix <span class="process-math">\(U\)</span> is <span class="process-math">\(2\by2\)</span> since there are two rows in <span class="process-math">\(A\)</span> and <span class="process-math">\(V\)</span> is <span class="process-math">\(3\by3\)</span> since there are three columns in <span class="process-math">\(A\)</span>
</div>
</div></li>
<li id="li-5632"><div class="para" id="p-8380">With <span class="process-math">\(\Sigma = \begin{bmatrix}
\sqrt{3} \amp 0 \amp 0 \\
0 \amp \sqrt{2} \amp 0
\end{bmatrix}\text{,}\)</span> we see that <span class="process-math">\(A=U\Sigma V^{\transpose}\text{.}\)</span>
</div></li>
<li id="li-5633"><div class="para" id="p-8381">If <span class="process-math">\(A = U\Sigma V^{\transpose}\text{,}\)</span> then <span class="process-math">\(A^{\transpose}=(U\Sigma V^{\transpose})^{\transpose}
= V\Sigma^{\transpose} U^{\transpose}\text{.}\)</span>
</div></li>
</ol></div></div></div>
</div></article><article class="example example-like" id="example-svd-nonsquare"><h4 class="heading">
<span class="type">Example</span><span class="space"> </span><span class="codenumber">7.5.4</span><span class="period">.</span>
</h4>
<div class="para" id="p-8382">We will find a singular value decomposition of the matrix <span class="process-math">\(A=\begin{bmatrix}
2 \amp -2 \amp 1 \\
-4 \amp -8 \amp -8 \\
\end{bmatrix}\text{.}\)</span>
</div> <div class="para logical" id="p-8383">
<div class="para">Finding an orthogonal diagonalization of <span class="process-math">\(G=A^{\transpose}A\)</span> gives</div>
<div class="displaymath process-math">
\begin{equation*}
D=\begin{bmatrix}
144 \amp 0 \amp 0 \\
0 \amp 9 \amp 0 \\
0 \amp 0 \amp 0 \\
\end{bmatrix},\hspace{24pt}
Q=\begin{bmatrix}
1/3 \amp 2/3 \amp 2/3 \\
2/3 \amp -2/3 \amp 1/3 \\
2/3 \amp 1/3 \amp -2/3 \\
\end{bmatrix}\text{,}
\end{equation*}
</div>
<div class="para">which gives singular values <span class="process-math">\(\sigma_1=\sqrt{144}=12\text{,}\)</span> <span class="process-math">\(\sigma_2 = \sqrt{9}= 3\text{,}\)</span> and <span class="process-math">\(\sigma_3 = 0\text{.}\)</span> The right singular vectors <span class="process-math">\(\vvec_i\)</span> appear as the columns of <span class="process-math">\(Q\)</span> so that <span class="process-math">\(V = Q\text{.}\)</span>
</div>
</div> <div class="para logical" id="p-8384">
<div class="para">We now find</div>
<div class="displaymath process-math" id="md-60">
\begin{align*}
A\vvec_1 = \twovec{0}{-12} = 12\uvec_1,
\hspace{24pt}
\amp
\uvec_1 = \twovec{0}{-1}\\
A\vvec_2 = \twovec{3}{0} = 3\uvec_1,
\hspace{24pt}
\amp
\uvec_1 = \twovec10\\
A\vvec_3 = \twovec{0}{0}
\end{align*}
</div>
<div class="para">Notice that it‚Äôs not possible to find a third left singular vector since <span class="process-math">\(A\vvec_3=\zerovec\text{.}\)</span> We therefore form the matrices</div>
<div class="displaymath process-math">
\begin{equation*}
U = \begin{bmatrix}
0 \amp 1 \\
-1 \amp 0 \\
\end{bmatrix},\hspace{24pt}
\Sigma = \begin{bmatrix}
12 \amp 0 \amp 0 \\
0 \amp 3 \amp 0 \\
\end{bmatrix},\hspace{24pt}
V=\begin{bmatrix}
1/3 \amp 2/3 \amp 2/3 \\
2/3 \amp -2/3 \amp 1/3 \\
2/3 \amp 1/3 \amp -2/3 \\
\end{bmatrix}\text{,}
\end{equation*}
</div>
<div class="para">which gives the singular value decomposition <span class="process-math">\(A=U\Sigma V^{\transpose}\text{.}\)</span>
</div>
</div> <div class="para" id="p-8385">Notice that <span class="process-math">\(U\)</span> is a <span class="process-math">\(2\by2\)</span> orthogonal matrix because <span class="process-math">\(A\)</span> has two rows, and <span class="process-math">\(V\)</span> is a <span class="process-math">\(3\by3\)</span> orthogonal matrix because <span class="process-math">\(A\)</span> has three columns.</div></article><div class="para" id="p-8386">As we‚Äôll see in the next section, some additional work may be needed to construct the left singular vectors <span class="process-math">\(\uvec_j\)</span> if more of the singular values are zero, but we won‚Äôt worry about that now.  For the time being, let‚Äôs record our work in the following theorem.</div>
<article class="theorem theorem-like" id="theorem-svd"><h4 class="heading">
<span class="type">Theorem</span><span class="space"> </span><span class="codenumber">7.5.5</span><span class="period">.</span><span class="space"> </span><span class="title">The singular value decomposition.</span>
</h4>
<div class="para" id="p-8387">An <span class="process-math">\(m\by n\)</span> matrix <span class="process-math">\(A\)</span> may be written as <span class="process-math">\(A=U\Sigma V^{\transpose}\)</span> where <span class="process-math">\(U\)</span> is an orthogonal <span class="process-math">\(m\by m\)</span> matrix, <span class="process-math">\(V\)</span> is an orthogonal <span class="process-math">\(n\by n\)</span> matrix, and <span class="process-math">\(\Sigma\)</span> is an <span class="process-math">\(m\by
n\)</span> matrix whose entries are zero except for the singular values of <span class="process-math">\(A\)</span> which appear in decreasing order on the diagonal.</div></article><div class="para logical" id="p-8388">
<div class="para">Notice that a singular value decomposition of <span class="process-math">\(A\)</span> gives us a singular value decomposition of <span class="process-math">\(A^{\transpose}\text{.}\)</span>  More specifically, if <span class="process-math">\(A=U\Sigma V^{\transpose}\text{,}\)</span> then</div>
<div class="displaymath process-math">
\begin{equation*}
A^{\transpose} = (U\Sigma V^{\transpose})^{\transpose} = V\Sigma^{\transpose} U^{\transpose}.
\end{equation*}
</div>
</div>
<article class="proposition theorem-like" id="prop-svd-transpose"><h4 class="heading">
<span class="type">Proposition</span><span class="space"> </span><span class="codenumber">7.5.6</span><span class="period">.</span>
</h4>
<div class="para" id="p-8389">If <span class="process-math">\(A=U\Sigma V^{\transpose}\text{,}\)</span> then <span class="process-math">\(A^{\transpose} = V\Sigma^{\transpose} U^{\transpose}\text{.}\)</span> In other words, <span class="process-math">\(A\)</span> and <span class="process-math">\(A^{\transpose}\)</span> share the same singular values, and the left singular vectors of <span class="process-math">\(A\)</span> are the right singular vectors of <span class="process-math">\(A^{\transpose}\)</span> and vice-versa.</div></article><div class="para" id="p-8390">As we said earlier, a singular value decomposition should be thought of a generalization of an orthogonal diagonalization. For instance, the Spectral Theorem tells us that a symmetric matrix can be written as <span class="process-math">\(QDQ^{\transpose}\text{.}\)</span>  Many matrices, however, are not symmetric and so they are not orthogonally diagonalizable.  However, every matrix has a singular value decomposition <span class="process-math">\(U\Sigma V^{\transpose}\text{.}\)</span>  The price of this generalization is that we usually have two sets of singular vectors that form the orthogonal matrices <span class="process-math">\(U\)</span> and <span class="process-math">\(V\)</span> whereas a symmetric matrix has a single set of eignevectors that form the orthogonal matrix <span class="process-math">\(Q\text{.}\)</span>
</div></section><section class="subsection" id="subsection-133"><h3 class="heading hide-type">
<span class="type">Subsection</span><span class="space"> </span><span class="codenumber">7.5.2</span><span class="space"> </span><span class="title">The structure of singular value decompositions</span>
</h3>
<div class="para" id="p-8391">Now that we have an understanding of what a singular value decomposition is and how to construct it, let‚Äôs explore the ways in which a singular value decomposition reveals the underlying structure of the matrix.  As we‚Äôll see, the matrices <span class="process-math">\(U\)</span> and <span class="process-math">\(V\)</span> in a singular value decomposition provide convenient bases for some important subspaces, such as the column and null spaces of the matrix.  This observation will provide the key to some of our uses of these decompositions in the next section.</div>
<article class="activity project-like" id="activity-svd-null-col-spaces"><h4 class="heading">
<span class="type">Activity</span><span class="space"> </span><span class="codenumber">7.5.4</span><span class="period">.</span>
</h4>
<div class="para logical" id="p-8392">
<div class="para">Let‚Äôs suppose that a matrix <span class="process-math">\(A\)</span> has a singular value decomposition <span class="process-math">\(A=U\Sigma V^{\transpose}\)</span> where</div>
<div class="displaymath process-math">
\begin{equation*}
U=\begin{bmatrix}
\uvec_1 \amp \uvec_2 \amp \uvec_3 \amp \uvec_4
\end{bmatrix},\hspace{10pt}
\Sigma = \begin{bmatrix}
20 \amp 0 \amp 0 \\
0 \amp 5 \amp 0 \\
0 \amp 0 \amp 0 \\
0 \amp 0 \amp 0
\end{bmatrix},\hspace{10pt}
V=\begin{bmatrix}
\vvec_1 \amp \vvec_2 \amp \vvec_3
\end{bmatrix}.
\end{equation*}
</div>
<ol class="lower-alpha">
<li id="li-5634"><div class="para" id="p-8393">What is the shape of <span class="process-math">\(A\text{;}\)</span> that is, how many rows and columns does <span class="process-math">\(A\)</span> have?</div></li>
<li id="li-5635">
<div class="para logical" id="p-8394">
<div class="para">Suppose we write a three-dimensional vector <span class="process-math">\(\xvec\)</span> as a linear combination of right singular vectors:</div>
<div class="displaymath process-math">
\begin{equation*}
\xvec = c_1\vvec_1 + c_2\vvec_2 + c_3\vvec_3\text{.}
\end{equation*}
</div>
<div class="para">We would like to find an expression for <span class="process-math">\(A\xvec\text{.}\)</span>
</div>
</div>
<div class="para" id="p-8395">To begin, <span class="process-math">\(V^{\transpose}\xvec = \threevec{\vvec_1\cdot\xvec}
{\vvec_2\cdot\xvec}
{\vvec_3\cdot\xvec} = \threevec{c_1}{c_2}{c_3}
\text{.}\)</span>
</div>
<div class="para" id="p-8396">Now <span class="process-math">\(\Sigma V^{\transpose} \xvec = 
\begin{bmatrix}
20 \amp 0 \amp 0 \\
0 \amp 5 \amp 0 \\
0 \amp 0 \amp 0 \\
0 \amp 0 \amp 0
\end{bmatrix}\threevec{c_1}{c_2}{c_3}
= \cfourvec{20c_1}{5c_2}00\text{.}\)</span>
</div>
<div class="para" id="p-8397">And finally, <span class="process-math">\(A\xvec = U\Sigma V^{\transpose}\xvec =
\begin{bmatrix}
\uvec_1 \amp \uvec_2 \amp \uvec_3 \amp \uvec_4
\end{bmatrix}
\cfourvec{20c_1}{5c_2}00 =
20c_1\uvec_1 + 5c_2\uvec_2\text{.}\)</span>
</div>
<div class="para" id="p-8398">To summarize, we have <span class="process-math">\(A\xvec = 20c_1\uvec_1 +
5c_2\uvec_2\text{.}\)</span>
</div>
<div class="para" id="p-8399">What condition on <span class="process-math">\(c_1\text{,}\)</span> <span class="process-math">\(c_2\text{,}\)</span> and <span class="process-math">\(c_3\)</span> must be satisfied if <span class="process-math">\(\xvec\)</span> is a solution to the equation <span class="process-math">\(A\xvec=40\uvec_1 + 20\uvec_2\text{?}\)</span> Is there a unique solution or are there infinitely many?</div>
</li>
<li id="li-5636"><div class="para" id="p-8400">Remembering that <span class="process-math">\(\uvec_1\)</span> and <span class="process-math">\(\uvec_2\)</span> are linearly independent, what condition on <span class="process-math">\(c_1\text{,}\)</span> <span class="process-math">\(c_2\text{,}\)</span> and <span class="process-math">\(c_3\)</span> must be satisfied if <span class="process-math">\(A\xvec = \zerovec\text{?}\)</span>
</div></li>
<li id="li-5637"><div class="para" id="p-8401">How do the right singular vectors <span class="process-math">\(\vvec_i\)</span> provide a basis for <span class="process-math">\(\nul(A)\text{,}\)</span> the subspace of solutions to the equation <span class="process-math">\(A\xvec = \zerovec\text{?}\)</span>
</div></li>
<li id="li-5638"><div class="para logical" id="p-8402">
<div class="para">Remember that <span class="process-math">\(\bvec\)</span> is in <span class="process-math">\(\col(A)\)</span> if the equation <span class="process-math">\(A\xvec = \bvec\)</span> is consistent, which means that</div>
<div class="displaymath process-math">
\begin{equation*}
A\xvec = 20c_1\uvec_1 + 5c_2\uvec_2 = \bvec
\end{equation*}
</div>
<div class="para">for some coefficients <span class="process-math">\(c_1\)</span> and <span class="process-math">\(c_2\text{.}\)</span>  How do the left singular vectors <span class="process-math">\(\uvec_i\)</span> provide an orthonormal basis for <span class="process-math">\(\col(A)\text{?}\)</span>
</div>
</div></li>
<li id="li-5639"><div class="para" id="p-8403">Remember that <span class="process-math">\(\rank(A)\)</span> is the dimension of the column space.  What is <span class="process-math">\(\rank(A)\)</span> and how do the number of nonzero singular values determine <span class="process-math">\(\rank(A)\text{?}\)</span>
</div></li>
</ol>
</div>
<div class="solutions">
<a href="" data-knowl="" class="id-ref answer-knowl original" data-refid="hk-answer-326" id="answer-326"><span class="type">Answer</span><span class="period">.</span></a><div class="hidden-content tex2jax_ignore" id="hk-answer-326"><div class="answer solution-like"><div class="para logical" id="p-8404"><ol class="lower-alpha">
<li id="li-5640"><div class="para" id="p-8405">
<span class="process-math">\(A\)</span> is <span class="process-math">\(4\by3\)</span>
</div></li>
<li id="li-5641"><div class="para" id="p-8406">
<span class="process-math">\(c_1 = 2\text{,}\)</span> <span class="process-math">\(c_2 = 4\text{,}\)</span> and there is no condition on <span class="process-math">\(c_3\)</span>
</div></li>
<li id="li-5642"><div class="para" id="p-8407">
<span class="process-math">\(c_1 = 0\text{,}\)</span> <span class="process-math">\(c_2 = 0\text{,}\)</span> and there is no condition on <span class="process-math">\(c_3\)</span>
</div></li>
<li id="li-5643"><div class="para" id="p-8408">
<span class="process-math">\(\vvec_3\)</span> forms a basis for <span class="process-math">\(\nul(A)\text{.}\)</span>
</div></li>
<li id="li-5644"><div class="para" id="p-8409">
<span class="process-math">\(\uvec_1\)</span> and <span class="process-math">\(\uvec_2\)</span> form a basis for <span class="process-math">\(\col(A)\text{.}\)</span>
</div></li>
<li id="li-5645"><div class="para" id="p-8410">
<span class="process-math">\(\rank(A) = 2\text{,}\)</span> which is the number of nonzero singular values.</div></li>
</ol></div></div></div>
<a href="" data-knowl="" class="id-ref solution-knowl original" data-refid="hk-solution-414" id="solution-414"><span class="type">Solution</span><span class="period">.</span></a><div class="hidden-content tex2jax_ignore" id="hk-solution-414"><div class="solution solution-like"><div class="para logical" id="p-8411"><ol class="lower-alpha">
<li id="li-5646"><div class="para" id="p-8412">The shape of <span class="process-math">\(A\)</span> is the same as <span class="process-math">\(\Sigma\)</span> so <span class="process-math">\(A\)</span> is <span class="process-math">\(4\by3\text{;}\)</span>  that is, <span class="process-math">\(A\)</span> has <span class="process-math">\(4\)</span> rows and <span class="process-math">\(3\)</span> columns.</div></li>
<li id="li-5647"><div class="para" id="p-8413">We have <span class="process-math">\(A\xvec=20c_1\uvec_1  + 5c_2\uvec_2 =
40\uvec_1 + 20\uvec_2\text{.}\)</span>  This means that <span class="process-math">\(c_1 =
2\text{,}\)</span> <span class="process-math">\(c_2 = 4\text{,}\)</span> and <span class="process-math">\(c_3\)</span> could be anything.  Since there is no condition on <span class="process-math">\(c_3\text{,}\)</span> there are infinitely many solutions.</div></li>
<li id="li-5648"><div class="para" id="p-8414">We have <span class="process-math">\(A\xvec=20c_1\uvec_1  + 5c_2\uvec_2 =
\zerovec\text{,}\)</span> which says that <span class="process-math">\(c_1 =
0\text{,}\)</span> <span class="process-math">\(c_2 = 0\text{,}\)</span> and <span class="process-math">\(c_3\)</span> could be anything.</div></li>
<li id="li-5649"><div class="para" id="p-8415">Any vector <span class="process-math">\(\xvec\)</span> in <span class="process-math">\(\nul(A)\)</span> satisfies <span class="process-math">\(A\xvec = \zerovec\)</span> and must have the form <span class="process-math">\(\xvec = c_3\vvec_3\text{.}\)</span>  Therefore, <span class="process-math">\(\vvec_3\)</span> forms a basis for <span class="process-math">\(\nul(A)\text{.}\)</span>
</div></li>
<li id="li-5650"><div class="para" id="p-8416">The vector <span class="process-math">\(\bvec\)</span> is in <span class="process-math">\(\col(A)\)</span> only if <span class="process-math">\(\bvec\)</span> is a linear combination of <span class="process-math">\(\uvec_1\)</span> and <span class="process-math">\(\uvec_2\text{.}\)</span>  Therefore, <span class="process-math">\(\uvec_1\)</span> and <span class="process-math">\(\uvec_2\)</span> form a basis for <span class="process-math">\(\col(A)\text{.}\)</span>
</div></li>
<li id="li-5651"><div class="para" id="p-8417">
<span class="process-math">\(\rank(A) = 2\text{,}\)</span> which is the number of nonzero singular values.</div></li>
</ol></div></div></div>
</div></article><div class="para" id="p-8418">This activity shows how a singular value decomposition of a matrix encodes important information about its null and column spaces.  More specifically, the left and right singular vectors provide orthonormal bases for <span class="process-math">\(\nul(A)\)</span> and <span class="process-math">\(\col(A)\text{.}\)</span> This is one of the reasons that singular value decompositions are so useful.</div>
<article class="example example-like" id="example-94"><h4 class="heading">
<span class="type">Example</span><span class="space"> </span><span class="codenumber">7.5.7</span><span class="period">.</span>
</h4>
<div class="para" id="p-8419">Suppose we have a singular value decomposition <span class="process-math">\(A=U\Sigma
V^{\transpose}\)</span> where <span class="process-math">\(\Sigma = \begin{bmatrix}
\sigma_1 \amp 0 \amp 0 \amp 0 \amp 0 \\
0 \amp \sigma_2 \amp 0 \amp 0 \amp 0 \\
0 \amp 0 \amp \sigma_3 \amp 0 \amp 0 \\
0 \amp 0 \amp 0 \amp 0 \amp 0 \\
\end{bmatrix}
\text{.}\)</span>  This means that <span class="process-math">\(A\)</span> has four rows and five columns just as <span class="process-math">\(\Sigma\)</span> does.</div> <div class="para logical" id="p-8420">
<div class="para">As in <a href="" class="xref" data-knowl="./knowl/activity-svd-null-col-spaces.html" title="Activity 7.5.4">Activity¬†7.5.4</a>, if <span class="process-math">\(\xvec = c_1 \vvec_1 + c_2\vvec_2 +
\ldots + c_5\vvec_5\text{,}\)</span> we have</div>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/activity-svd-null-col-spaces.html">
\begin{equation*}
A\xvec = \sigma_1c_1\uvec_1 + \sigma_2c_2\uvec_2 +
\sigma_3c_3\uvec_3\text{.}
\end{equation*}
</div>
</div> <div class="para logical" id="p-8421">
<div class="para">If <span class="process-math">\(\bvec\)</span> is in <span class="process-math">\(\col(A)\text{,}\)</span> then <span class="process-math">\(\bvec\)</span> must have the form</div>
<div class="displaymath process-math">
\begin{equation*}
\bvec = \sigma_1c_1\uvec_1 + \sigma_2c_2\uvec_2 +
\sigma_3c_3\uvec_3\text{,}
\end{equation*}
</div>
<div class="para">which says that <span class="process-math">\(\bvec\)</span> is a linear combination of <span class="process-math">\(\uvec_1\text{,}\)</span> <span class="process-math">\(\uvec_2\text{,}\)</span> and <span class="process-math">\(\uvec_3\text{.}\)</span> These three vectors therefore form a basis for <span class="process-math">\(\col(A)\text{.}\)</span>  In fact, since they are columns in the orthogonal matrix <span class="process-math">\(U\text{,}\)</span> they form an orthonormal basis for <span class="process-math">\(\col(A)\text{.}\)</span>
</div>
</div> <div class="para" id="p-8422">Remembering that <span class="process-math">\(\rank(A)=\dim\col(A)\text{,}\)</span> we see that <span class="process-math">\(\rank(A) = 3\text{,}\)</span> which results from the three nonzero singular values.  In general, the rank <span class="process-math">\(r\)</span> of a matrix <span class="process-math">\(A\)</span> equals the number of nonzero singular values, and <span class="process-math">\(\uvec_1, \uvec_2, \ldots,\uvec_r\)</span> form an orthonormal basis for <span class="process-math">\(\col(A)\text{.}\)</span>
</div> <div class="para logical" id="p-8423">
<div class="para">Moreover, if <span class="process-math">\(\xvec = c_1 \vvec_1 + c_2\vvec_2 +
\ldots + c_5\vvec_5\)</span> satisfies <span class="process-math">\(A\xvec = \zerovec\text{,}\)</span> then</div>
<div class="displaymath process-math">
\begin{equation*}
A\xvec = \sigma_1c_1\uvec_1 + \sigma_2c_2\uvec_2 +
\sigma_3c_3\uvec_3=\zerovec\text{,}
\end{equation*}
</div>
<div class="para">which implies that <span class="process-math">\(c_1=0\text{,}\)</span> <span class="process-math">\(c_2=0\text{,}\)</span> and <span class="process-math">\(c_3=0\text{.}\)</span>  Therefore, <span class="process-math">\(\xvec =
c_4\vvec_4+c_5\vvec_5\)</span> so <span class="process-math">\(\vvec_4\)</span> and <span class="process-math">\(\vvec_5\)</span> form an orthonormal basis for <span class="process-math">\(\nul(A)\text{.}\)</span>
</div>
</div> <div class="para" id="p-8424">More generally, if <span class="process-math">\(A\)</span> is an <span class="process-math">\(m\by n\)</span> matrix and if <span class="process-math">\(\rank(A) = r\text{,}\)</span> the last <span class="process-math">\(n-r\)</span> right singular vectors form an orthonormal basis for <span class="process-math">\(\nul(A)\text{.}\)</span>
</div></article><div class="para logical" id="p-8425">
<div class="para">Generally speaking, if the rank of an <span class="process-math">\(m\by n\)</span> matrix <span class="process-math">\(A\)</span> is <span class="process-math">\(r\text{,}\)</span> then there are <span class="process-math">\(r\)</span> nonzero singular values and <span class="process-math">\(\Sigma\)</span> has the form</div>
<div class="displaymath process-math">
\begin{equation*}
\begin{bmatrix}
\sigma_1 \amp \ldots \amp 0 \amp \ldots \amp 0 \\
0 \amp \ldots \amp 0 \amp \ldots \amp 0 \\
0 \amp \ldots \amp \sigma_r \amp \ldots \amp 0 \\
0 \amp \ldots \amp 0 \amp \ldots \amp 0 \\
\vdots \amp \vdots \amp \vdots \amp \ddots \amp \vdots \\
0 \amp \ldots \amp 0 \amp \ldots \amp 0 \\
\end{bmatrix},
\end{equation*}
</div>
<div class="para">The first <span class="process-math">\(r\)</span> columns of <span class="process-math">\(U\)</span> form an orthonormal basis for <span class="process-math">\(\col(A)\text{:}\)</span>
</div>
<div class="displaymath process-math">
\begin{equation*}
U = \left[
\underbrace{\uvec_1 ~ \ldots ~ \uvec_r}_{\col(A)} \hspace{3pt}
\uvec_{r+1} ~ \ldots ~ \uvec_m
\right]
\end{equation*}
</div>
<div class="para">and the last <span class="process-math">\(n-r\)</span> columns of <span class="process-math">\(V\)</span> form an orthonormal basis for <span class="process-math">\(\nul(A)\text{:}\)</span>
</div>
<div class="displaymath process-math">
\begin{equation*}
V = \left[
\vvec_1 ~ \ldots ~ \vvec_r\hspace{3pt}
\underbrace{\vvec_{r+1} ~ \ldots ~ \vvec_n}_{\nul(A)}
\right]
\end{equation*}
</div>
</div>
<div class="para" id="p-8426">Remember that <a href="" class="xref" data-knowl="./knowl/prop-svd-transpose.html" title="Proposition 7.5.6">Proposition¬†7.5.6</a> says that <span class="process-math">\(A\)</span> and its transpose <span class="process-math">\(A^{\transpose}\)</span> share the same singular values.  Since the rank of a matrix equals its number of nonzero singular values, this means that <span class="process-math">\(\rank(A)=\rank(A^{\transpose})\text{,}\)</span> a fact that we cited back in <a href="sec-transpose.html" class="internal" title="Section 6.2: Orthogonal complements and the matrix transpose">Section¬†6.2</a>.</div>
<article class="proposition theorem-like" id="prop-rank-transpose"><h4 class="heading">
<span class="type">Proposition</span><span class="space"> </span><span class="codenumber">7.5.8</span><span class="period">.</span>
</h4>
<div class="para logical" id="p-8427">
<div class="para">For any matrix <span class="process-math">\(A\text{,}\)</span>
</div>
<div class="displaymath process-math">
\begin{equation*}
\rank(A) =
\rank(A^{\transpose})\text{.}
\end{equation*}
</div>
</div></article><div class="para logical" id="p-8428">
<div class="para">If we have a singular value decomposition of an <span class="process-math">\(m\by n\)</span> matrix <span class="process-math">\(A=U\Sigma V^{\transpose}\text{,}\)</span> <a href="" class="xref" data-knowl="./knowl/prop-svd-transpose.html" title="Proposition 7.5.6">Proposition¬†7.5.6</a> also tells us that the left singular vectors of <span class="process-math">\(A\)</span> are the right singular vectors of <span class="process-math">\(A^{\transpose}\text{.}\)</span>  Therefore, <span class="process-math">\(U\)</span> is the <span class="process-math">\(m\by m\)</span> matrix whose columns are the right singular vectors of <span class="process-math">\(A^{\transpose}\text{.}\)</span>  This means that the last <span class="process-math">\(m-r\)</span> vectors form an orthonormal basis for <span class="process-math">\(\nul(A^{\transpose})\text{.}\)</span> Therefore, the columns of <span class="process-math">\(U\)</span> provide orthonormal bases for <span class="process-math">\(\col(A)\)</span> and <span class="process-math">\(\nul(A^{\transpose})\text{:}\)</span>
</div>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/prop-svd-transpose.html">
\begin{equation*}
U = \left[
\underbrace{\uvec_1 ~ \ldots ~ \uvec_r}_{\col(A)} \hspace{3pt}
\underbrace{\uvec_{r+1} ~ \ldots ~ \uvec_m}_{\nul(A^{\transpose})}
\right]\text{.}
\end{equation*}
</div>
<div class="para">This reflects the familiar fact that <span class="process-math">\(\nul(A^{\transpose})\)</span> is the orthogonal complement of <span class="process-math">\(\col(A)\text{.}\)</span>
</div>
</div>
<div class="para logical" id="p-8429">
<div class="para">In the same way, <span class="process-math">\(V\)</span> is the <span class="process-math">\(n\by n\)</span> matrix whose columns are the left singular vectors of <span class="process-math">\(A^{\transpose}\text{,}\)</span> which means that the first <span class="process-math">\(r\)</span> vectors form an orthonormal basis for <span class="process-math">\(\col(A^{\transpose})\text{.}\)</span>  Because the columns of <span class="process-math">\(A^{\transpose}\)</span> are the rows of <span class="process-math">\(A\text{,}\)</span> this subspace is sometimes called the <dfn class="terminology">row space</dfn> of <span class="process-math">\(A\)</span> and denoted <span class="process-math">\(\row(A)\text{.}\)</span>  While we have yet to have an occasion to use <span class="process-math">\(\row(A)\text{,}\)</span> there are times when it is important to have an orthonormal basis for it, and a singular value decomposition provides just that.  To summarize, the columns of <span class="process-math">\(V\)</span> provide orthonormal bases for <span class="process-math">\(\col(A^{\transpose})\)</span> and <span class="process-math">\(\nul(A)\text{:}\)</span>
</div>
<div class="displaymath process-math">
\begin{equation*}
V = \left[
\underbrace{\vvec_1 ~ \ldots ~ \vvec_r}_{\col(A^{\transpose})}\hspace{3pt}
\underbrace{\vvec_{r+1} ~ \ldots ~ \vvec_m}_{\nul(A)}
\right]
\end{equation*}
</div>
</div>
<div class="para" id="p-8430">Considered altogether, the subspaces <span class="process-math">\(\col(A)\text{,}\)</span> <span class="process-math">\(\nul(A)\text{,}\)</span> <span class="process-math">\(\col(A^{\transpose})\text{,}\)</span> and <span class="process-math">\(\nul(A^{\transpose})\)</span> are called the <dfn class="terminology">four fundamental subspaces</dfn> associated to <span class="process-math">\(A\text{.}\)</span>  In addition to telling us the rank of a matrix, a singular value decomposition gives us orthonormal bases for all four fundamental subspaces.</div>
<article class="theorem theorem-like" id="thm-four-subspaces"><h4 class="heading">
<span class="type">Theorem</span><span class="space"> </span><span class="codenumber">7.5.9</span><span class="period">.</span>
</h4>
<div class="para logical" id="p-8431">
<div class="para">Suppose <span class="process-math">\(A\)</span> is an <span class="process-math">\(m\by n\)</span> matrix having a singular value decomposition <span class="process-math">\(A=U\Sigma V^{\transpose}\text{.}\)</span>  Then</div>
<ul class="disc">
<li id="li-5652"><div class="para" id="p-8432">
<span class="process-math">\(r=\rank(A)\)</span> is the number of nonzero singular values.</div></li>
<li id="li-5653"><div class="para" id="p-8433">The columns <span class="process-math">\(\uvec_1,\uvec_2,\ldots,\uvec_r\)</span> form an orthonormal basis for <span class="process-math">\(\col(A)\text{.}\)</span>
</div></li>
<li id="li-5654"><div class="para" id="p-8434">The columns <span class="process-math">\(\uvec_{r+1},\ldots,\uvec_m\)</span> form an orthonormal basis for <span class="process-math">\(\nul(A^{\transpose})\text{.}\)</span>
</div></li>
<li id="li-5655"><div class="para" id="p-8435">The columns <span class="process-math">\(\vvec_1,\vvec_2,\ldots,\vvec_r\)</span> form an orthonormal basis for <span class="process-math">\(\col(A^{\transpose})\text{.}\)</span>
</div></li>
<li id="li-5656"><div class="para" id="p-8436">The columns <span class="process-math">\(\vvec_{r+1},\ldots,\vvec_n\)</span> form an orthonormal basis for <span class="process-math">\(\nul(A)\text{.}\)</span>
</div></li>
</ul>
</div></article><div class="para" id="p-8437">When we previously outlined a procedure for finding a singular decomposition of an <span class="process-math">\(m\by n\)</span> matrix <span class="process-math">\(A\text{,}\)</span> we found the left singular vectors <span class="process-math">\(\uvec_j\)</span> using the expression <span class="process-math">\(A\vvec_j = \sigma_j\uvec_j\text{.}\)</span>  This produces left singular vectors <span class="process-math">\(\uvec_1, \uvec_2,\ldots,\uvec_r\text{,}\)</span> where <span class="process-math">\(r=\rank(A)\text{.}\)</span>  If <span class="process-math">\(r\lt m\text{,}\)</span> however, we still need to find the left singular vectors <span class="process-math">\(\uvec_{r+1},\ldots,\uvec_m\text{.}\)</span>  <a href="" class="xref" data-knowl="./knowl/thm-four-subspaces.html" title="Theorem 7.5.9">Theorem¬†7.5.9</a> tells us how to do that: because those vectors form an orthonormal basis for <span class="process-math">\(\nul(A^{\transpose})\text{,}\)</span> we can find them by solving <span class="process-math">\(A^{\transpose}\xvec = \zerovec\)</span> to obtain a basis for <span class="process-math">\(\nul(A^{\transpose})\)</span> and applying the Gram-Schmidt algorithm.</div>
<div class="para" id="p-8438">We won‚Äôt worry about this issue too much, however, as we will frequently use software to find singular value decompositions for us.</div></section><section class="subsection" id="subsection-134"><h3 class="heading hide-type">
<span class="type">Subsection</span><span class="space"> </span><span class="codenumber">7.5.3</span><span class="space"> </span><span class="title">Reduced singular value decompositions</span>
</h3>
<div class="para" id="p-8439">As we‚Äôll see in the next section, there are times when it is helpful to express a singular value decomposition in a slightly different form.</div>
<article class="activity project-like" id="activity-110"><h4 class="heading">
<span class="type">Activity</span><span class="space"> </span><span class="codenumber">7.5.5</span><span class="period">.</span>
</h4>
<div class="para logical" id="p-8440">
<div class="para">Suppose we have a singular value decomposition <span class="process-math">\(A =
U\Sigma V^{\transpose}\)</span> where</div>
<div class="displaymath process-math">
\begin{equation*}
U = \begin{bmatrix}
\uvec_1 \amp \uvec_2 \amp \uvec_3 \amp \uvec_4
\end{bmatrix},\hspace{24pt}
\Sigma = \begin{bmatrix}
18 \amp 0 \amp 0 \\
0 \amp 4 \amp 0 \\
0 \amp 0 \amp 0 \\
0 \amp 0 \amp 0 \\
\end{bmatrix},\hspace{24pt}
V = \begin{bmatrix}
\vvec_1 \amp \vvec_2 \amp \vvec_3 
\end{bmatrix}\text{.}
\end{equation*}
</div>
<ol class="lower-alpha">
<li id="li-5657"><div class="para" id="p-8441">What is the shape of <span class="process-math">\(A\text{?}\)</span>  What is <span class="process-math">\(\rank(A)\text{?}\)</span>
</div></li>
<li id="li-5658"><div class="para" id="p-8442">Identify bases for <span class="process-math">\(\col(A)\)</span> and <span class="process-math">\(\col(A^{\transpose})\text{.}\)</span>
</div></li>
<li id="li-5659"><div class="para logical" id="p-8443">
<div class="para">Explain why</div>
<div class="displaymath process-math">
\begin{equation*}
U\Sigma = \begin{bmatrix}
\uvec_1 \amp \uvec_2
\end{bmatrix}
\begin{bmatrix}
18 \amp 0 \amp 0 \\
0 \amp 4 \amp 0 \\
\end{bmatrix}\text{.}
\end{equation*}
</div>
</div></li>
<li id="li-5660"><div class="para logical" id="p-8444">
<div class="para">Explain why</div>
<div class="displaymath process-math">
\begin{equation*}
\begin{bmatrix}
18 \amp 0 \amp 0 \\
0 \amp 4 \amp 0 \\
\end{bmatrix}V^{\transpose} =
\begin{bmatrix}
18 \amp 0 \\
0 \amp 4 \\
\end{bmatrix}
\begin{bmatrix}
\vvec_1 \amp \vvec_2
\end{bmatrix}^{\transpose}\text{.}
\end{equation*}
</div>
</div></li>
<li id="li-5661"><div class="para" id="p-8445">If <span class="process-math">\(A = U\Sigma V^{\transpose}\text{,}\)</span> explain why <span class="process-math">\(A=U_r\Sigma_rV_r^{\transpose}\)</span> where the columns of <span class="process-math">\(U_r\)</span> are an orthonormal basis for <span class="process-math">\(\col(A)\text{,}\)</span> <span class="process-math">\(\Sigma_r\)</span> is a square, diagonal, invertible matrix, and the columns of <span class="process-math">\(V_r\)</span> form an orthonormal basis for <span class="process-math">\(\col(A^{\transpose})\text{.}\)</span>
</div></li>
</ol>
</div>
<div class="solutions">
<a href="" data-knowl="" class="id-ref answer-knowl original" data-refid="hk-answer-327" id="answer-327"><span class="type">Answer</span><span class="period">.</span></a><div class="hidden-content tex2jax_ignore" id="hk-answer-327"><div class="answer solution-like"><div class="para logical" id="p-8446"><ol class="lower-alpha">
<li id="li-5662"><div class="para" id="p-8447">
<span class="process-math">\(A\)</span> is a <span class="process-math">\(4\by3\)</span> matrix and <span class="process-math">\(\rank(A) =
2\)</span>
</div></li>
<li id="li-5663"><div class="para" id="p-8448">
<span class="process-math">\(\uvec_1\)</span> and <span class="process-math">\(\uvec_2\)</span> form an orthonormal basis for <span class="process-math">\(\col(A)\text{,}\)</span> and <span class="process-math">\(\vvec_1\)</span> and <span class="process-math">\(\vvec_2\)</span> form an orthonormal basis for <span class="process-math">\(\nul(A)\text{.}\)</span>
</div></li>
<li id="li-5664"><div class="para logical" id="p-8449">
<div class="para">Notice that</div>
<div class="displaymath process-math">
\begin{equation*}
U\Sigma =
\begin{bmatrix}
\uvec_1 \amp \uvec_2 \amp \uvec_3 \amp \uvec_4
\end{bmatrix}
\begin{bmatrix}
18 \amp 0 \amp 0 \\
0 \amp 4 \amp 0 \\
0 \amp 0 \amp 0 \\
0 \amp 0 \amp 0
\end{bmatrix}
= \begin{bmatrix}
18\uvec_1 \amp 4\uvec_2 \amp \zerovec
\end{bmatrix} 
\end{equation*}
</div>
</div></li>
<li id="li-5665"><div class="para logical" id="p-8450">
<div class="para">Notice that</div>
<div class="displaymath process-math">
\begin{equation*}
\begin{bmatrix}
18 \amp 0 \amp 0 \\
0 \amp 4 \amp 0 \\
\end{bmatrix}V^{\transpose} =
\begin{bmatrix}
18 \amp 0 \amp 0 \\
0 \amp 4 \amp 0 \\
\end{bmatrix}
\begin{bmatrix}
\vvec_1^{\transpose} \\
\vvec_2^{\transpose} \\
\vvec_3^{\transpose}
\end{bmatrix} 
\end{equation*}
</div>
</div></li>
<li id="li-5666"><div class="para logical" id="p-8451">
<div class="para">Put together the previous parts to see that <span class="process-math">\(A=U_r\Sigma_rV_r^{\transpose}\)</span> where</div>
<div class="displaymath process-math">
\begin{equation*}
U_r = \begin{bmatrix}
\uvec_1 \amp \uvec_2
\end{bmatrix},\hspace{24pt}
\Sigma_r = \begin{bmatrix}
18 \amp 0 \\
0 \amp 4 \\
\end{bmatrix},\hspace{24pt}
V_r = \begin{bmatrix}
\vvec_1 \amp \vvec_2
\end{bmatrix}\text{.}
\end{equation*}
</div>
</div></li>
</ol></div></div></div>
<a href="" data-knowl="" class="id-ref solution-knowl original" data-refid="hk-solution-415" id="solution-415"><span class="type">Solution</span><span class="period">.</span></a><div class="hidden-content tex2jax_ignore" id="hk-solution-415"><div class="solution solution-like"><div class="para logical" id="p-8452"><ol class="lower-alpha">
<li id="li-5667"><div class="para" id="p-8453">
<span class="process-math">\(A\)</span> is a <span class="process-math">\(4\by3\)</span> matrix and <span class="process-math">\(\rank(A) =
2\)</span> because there are two nonzero singular values.</div></li>
<li id="li-5668"><div class="para" id="p-8454">
<span class="process-math">\(\uvec_1\)</span> and <span class="process-math">\(\uvec_2\)</span> form an orthonormal basis for <span class="process-math">\(\col(A)\text{,}\)</span> and <span class="process-math">\(\vvec_1\)</span> and <span class="process-math">\(\vvec_2\)</span> form an orthonormal basis for <span class="process-math">\(\nul(A)\text{.}\)</span>
</div></li>
<li id="li-5669"><div class="para logical" id="p-8455">
<div class="para">Notice that</div>
<div class="displaymath process-math">
\begin{equation*}
U\Sigma =
\begin{bmatrix}
\uvec_1 \amp \uvec_2 \amp \uvec_3 \amp \uvec_4
\end{bmatrix}
\begin{bmatrix}
18 \amp 0 \amp 0 \\
0 \amp 4 \amp 0 \\
0 \amp 0 \amp 0 \\
0 \amp 0 \amp 0
\end{bmatrix}
= \begin{bmatrix}
18\uvec_1 \amp 4\uvec_2 \amp \zerovec
\end{bmatrix} = 
\begin{bmatrix}
\uvec_1 \amp \uvec_2
\end{bmatrix}
\begin{bmatrix}
18 \amp 0 \amp 0 \\
0 \amp 4 \amp 0 \\
\end{bmatrix}\text{.}
\end{equation*}
</div>
</div></li>
<li id="li-5670"><div class="para logical" id="p-8456">
<div class="para">Notice that</div>
<div class="displaymath process-math">
\begin{equation*}
\begin{bmatrix}
18 \amp 0 \amp 0 \\
0 \amp 4 \amp 0 \\
\end{bmatrix}V^{\transpose} =
\begin{bmatrix}
18 \amp 0 \amp 0 \\
0 \amp 4 \amp 0 \\
\end{bmatrix}
\begin{bmatrix}
\vvec_1^{\transpose} \\
\vvec_2^{\transpose} \\
\vvec_3^{\transpose}
\end{bmatrix} =
\begin{bmatrix}
18 \vvec_1^{\transpose} \\
4 \vvec_2^{\transpose}
\end{bmatrix} = 
\begin{bmatrix}
18 \amp 0 \\
0 \amp 4 \\
\end{bmatrix}
\begin{bmatrix}
\vvec_1 \amp \vvec_2
\end{bmatrix}^{\transpose}\text{.}
\end{equation*}
</div>
</div></li>
<li id="li-5671"><div class="para logical" id="p-8457">
<div class="para">Put together the previous parts to see that <span class="process-math">\(A=U_r\Sigma_rV_r^{\transpose}\)</span> where</div>
<div class="displaymath process-math">
\begin{equation*}
U_r = \begin{bmatrix}
\uvec_1 \amp \uvec_2
\end{bmatrix},\hspace{24pt}
\Sigma_r = \begin{bmatrix}
18 \amp 0 \\
0 \amp 4 \\
\end{bmatrix},\hspace{24pt}
V_r = \begin{bmatrix}
\vvec_1 \amp \vvec_2
\end{bmatrix}\text{.}
\end{equation*}
</div>
</div></li>
</ol></div></div></div>
</div></article><div class="para" id="p-8458">We call this a <dfn class="terminology">reduced singular value decomposition</dfn>.</div>
<article class="proposition theorem-like" id="prop-reduced-svd"><h4 class="heading">
<span class="type">Proposition</span><span class="space"> </span><span class="codenumber">7.5.10</span><span class="period">.</span><span class="space"> </span><span class="title">Reduced singular value decomposition.</span>
</h4>
<div class="para logical" id="p-8459">
<div class="para">If <span class="process-math">\(A\)</span> is an <span class="process-math">\(m\by n\)</span> matrix having rank <span class="process-math">\(r\text{,}\)</span> then <span class="process-math">\(A=U_r \Sigma_r V_r^{\transpose}\)</span> where</div>
<ul class="disc">
<li id="li-5672"><div class="para" id="p-8460">
<span class="process-math">\(U_r\)</span> is an <span class="process-math">\(m\by r\)</span> matrix whose columns form an orthonormal basis for <span class="process-math">\(\col(A)\text{,}\)</span>
</div></li>
<li id="li-5673"><div class="para" id="p-8461">
<span class="process-math">\(\Sigma_r=\begin{bmatrix}
\sigma_1 \amp 0 \amp \ldots \amp 0 \\
0 \amp \sigma_2 \amp \ldots \amp 0 \\
\vdots \amp \vdots \amp \ddots \amp \vdots \\
0 \amp 0 \amp 0 \amp \sigma_r \\
\end{bmatrix}\)</span> is an <span class="process-math">\(r\by r\)</span> diagonal, invertible matrix, and</div></li>
<li id="li-5674"><div class="para" id="p-8462">
<span class="process-math">\(V_r\)</span> is an <span class="process-math">\(n\by r\)</span> matrix whose columns form an orthonormal basis for <span class="process-math">\(\col(A^{\transpose})\text{.}\)</span>
</div></li>
</ul>
</div></article><article class="example example-like" id="example-95"><h4 class="heading">
<span class="type">Example</span><span class="space"> </span><span class="codenumber">7.5.11</span><span class="period">.</span>
</h4>
<div class="para logical" id="p-8463">
<div class="para">In <a href="" class="xref" data-knowl="./knowl/example-svd-nonsquare.html" title="Example 7.5.4">Example¬†7.5.4</a>, we found the singular value decomposition</div>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/example-svd-nonsquare.html">
\begin{equation*}
A=\begin{bmatrix}
2 \amp -2 \amp 1 \\
-4 \amp -8 \amp -8 \\
\end{bmatrix}
= \begin{bmatrix}
0 \amp 1 \\
-1 \amp 0 \\
\end{bmatrix}
\begin{bmatrix}
12 \amp 0 \amp 0 \\
0 \amp 3 \amp 0 \\
\end{bmatrix}
\begin{bmatrix}
1/3 \amp 2/3 \amp 2/3 \\
2/3 \amp -2/3 \amp 1/3 \\
2/3 \amp 1/3 \amp -2/3 \\
\end{bmatrix}^{\transpose}\text{.}
\end{equation*}
</div>
<div class="para">Since there are two nonzero singular values, <span class="process-math">\(\rank(A)
=2\)</span> so that the reduced singular value decomposition is</div>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/example-svd-nonsquare.html">
\begin{equation*}
A=\begin{bmatrix}
2 \amp -2 \amp 1 \\
-4 \amp -8 \amp -8 \\
\end{bmatrix}
= \begin{bmatrix}
0 \amp 1 \\
-1 \amp 0 \\
\end{bmatrix}
\begin{bmatrix}
12 \amp 0  \\
0 \amp 3 \\
\end{bmatrix}
\begin{bmatrix}
1/3 \amp 2/3  \\
2/3 \amp -2/3  \\
2/3 \amp 1/3  \\
\end{bmatrix}^{\transpose}\text{.}
\end{equation*}
</div>
</div></article><div class="para" id="p-8464"> In Python, <code class="code-inline tex2jax_ignore">np.linalg.svd()</code> can be used to compute the reduced SVD for a matrix.</div>
<pre class="ptx-sagecell sagecell-python" id="sage-306"><script type="text/x-sage">import numpy as np 
A = np.column_stack(((2,-4), (-2, -8), (1,-8)))
print(np.linalg.svd(A))
</script></pre>
<div class="para" id="p-8465">Notice that only the diagonal entries of <span class="process-math">\(\Sigma\)</span> are given in the Python output. This save a lot of space when the matrices are big. <code class="code-inline tex2jax_ignore">np.diag()</code> can be used to inflate the diagonal vector to a diagonal matrix, if needed.</div></section><section class="subsection" id="subsection-135"><h3 class="heading hide-type">
<span class="type">Subsection</span><span class="space"> </span><span class="codenumber">7.5.4</span><span class="space"> </span><span class="title">Summary</span>
</h3>
<div class="para logical" id="p-8466">
<div class="para">This section has explored singular value decompositions, how to find them, and how they organize important information about a matrix.</div>
<ul class="disc">
<li id="li-5675"><div class="para" id="p-8467">A singular value decomposition of a matrix <span class="process-math">\(A\)</span> is a factorization where <span class="process-math">\(A=U\Sigma V^{\transpose}\text{.}\)</span>  The matrix <span class="process-math">\(\Sigma\)</span> has the same shape as <span class="process-math">\(A\text{,}\)</span> and its only nonzero entries are the singular values of <span class="process-math">\(A\text{,}\)</span> which appear in decreasing order on the diagonal.  The matrices <span class="process-math">\(U\)</span> and <span class="process-math">\(V\)</span> are orthogonal and contain the left and right singular vectors, respectively, as their columns.</div></li>
<li id="li-5676"><div class="para" id="p-8468">To find a singular value decomposition of a matrix, we construct the Gram matrix <span class="process-math">\(G=A^{\transpose}A\text{,}\)</span> which is symmetric.  The singular values of <span class="process-math">\(A\)</span> are the square roots of the eigenvalues of <span class="process-math">\(G\text{,}\)</span> and the right singular vectors <span class="process-math">\(\vvec_j\)</span> are the associated eigenvectors of <span class="process-math">\(G\text{.}\)</span>  The left singular vectors <span class="process-math">\(\uvec_j\)</span> are determined from the relationship <span class="process-math">\(A\vvec_j=\sigma_j\uvec_j\text{.}\)</span>
</div></li>
<li id="li-5677"><div class="para" id="p-8469">A singular value decomposition reveals fundamental information about a matrix.  For instance, the number of nonzero singular values is the rank <span class="process-math">\(r\)</span> of the matrix.  The first <span class="process-math">\(r\)</span> left singular vectors form an orthonormal basis for <span class="process-math">\(\col(A)\)</span> with the remaining left singular vectors forming an orthonormal basis of <span class="process-math">\(\nul(A^{\transpose})\text{.}\)</span>  The first <span class="process-math">\(r\)</span> right singular vectors form an orthonormal basis for <span class="process-math">\(\col(A^{\transpose})\)</span> while the remaining right singular vectors form an orthonormal basis of <span class="process-math">\(\nul(A)\text{.}\)</span>
</div></li>
<li id="li-5678"><div class="para" id="p-8470">If <span class="process-math">\(A\)</span> is a rank <span class="process-math">\(r\)</span> matrix, we can write a reduced singular value decomposition as <span class="process-math">\(A=U_r\Sigma_rV_r^{\transpose}\)</span> where the columns of <span class="process-math">\(U_r\)</span> form an orthonormal basis for <span class="process-math">\(\col(A)\text{,}\)</span> the columns of <span class="process-math">\(V_r\)</span> form an orthonormal basis for <span class="process-math">\(\col(A^{\transpose})\text{,}\)</span> and <span class="process-math">\(\Sigma_r\)</span> is an <span class="process-math">\(r\by
r\)</span> diagonal, invertible matrix.</div></li>
</ul>
</div></section><section class="exercises" id="exercises-34"><h3 class="heading hide-type">
<span class="type">Exercises</span><span class="space"> </span><span class="codenumber">7.5.5</span><span class="space"> </span><span class="title">Exercises</span>
</h3>
<article class="exercise exercise-like" id="ex-7-4-1"><h4 class="heading"><span class="codenumber">1<span class="period">.</span></span></h4>
<div class="para" id="p-8471">Consider the matrix <span class="process-math">\(A = \begin{bmatrix}
1 \amp 2 \amp 1 \\
0 \amp -1 \amp 2 \\
\end{bmatrix}
\text{.}\)</span>
</div> <pre class="ptx-sagecell sagecell-python" id="sage-307"><script type="text/x-sage">
</script></pre> <div class="para logical" id="p-8472"><ol class="lower-alpha">
<li id="li-5679"><div class="para" id="p-8473">Find the Gram matrix <span class="process-math">\(G=A^{\transpose}A\)</span> and use it to find the singular values and right singular vectors of <span class="process-math">\(A\text{.}\)</span>
</div></li>
<li id="li-5680"><div class="para" id="p-8474">Find the left singular vectors.</div></li>
<li id="li-5681"><div class="para" id="p-8475">Form the matrices <span class="process-math">\(U\text{,}\)</span> <span class="process-math">\(\Sigma\text{,}\)</span> and <span class="process-math">\(V\)</span> and verify that <span class="process-math">\(A=U\Sigma V^{\transpose}\text{.}\)</span>
</div></li>
<li id="li-5682"><div class="para" id="p-8476">What is <span class="process-math">\(\rank(A)\)</span> and what does this say about <span class="process-math">\(\col(A)\text{?}\)</span>
</div></li>
<li id="li-5683"><div class="para" id="p-8477">Determine an orthonormal basis for <span class="process-math">\(\nul(A)\text{.}\)</span>
</div></li>
</ol></div></article><article class="exercise exercise-like" id="exercise-288"><h4 class="heading"><span class="codenumber">2<span class="period">.</span></span></h4>
<div class="para logical" id="p-8492">
<div class="para">Find singular value decompositions for the following matrices:</div>
<ol class="lower-alpha">
<li id="li-5694"><div class="para" id="p-8493"><span class="process-math">\(\begin{bmatrix} 0 \amp 0 \\ 0 \amp -8
\end{bmatrix}\text{.}\)</span></div></li>
<li id="li-5695"><div class="para" id="p-8494"><span class="process-math">\(\begin{bmatrix} 2 \amp 3 \\ 0 \amp 2
\end{bmatrix}\text{.}\)</span></div></li>
<li id="li-5696"><div class="para" id="p-8495"><span class="process-math">\(\displaystyle \begin{bmatrix}
4 \amp 0 \amp 0 \\
0 \amp 0 \amp 2
\end{bmatrix}\)</span></div></li>
<li id="li-5697"><div class="para" id="p-8496"><span class="process-math">\(\displaystyle \begin{bmatrix}
4 \amp 0 \\
0 \amp 0 \\
0 \amp 2 
\end{bmatrix}\)</span></div></li>
</ol>
</div></article><article class="exercise exercise-like" id="exercise-289"><h4 class="heading"><span class="codenumber">3<span class="period">.</span></span></h4>
<div class="para logical" id="p-8507">
<div class="para">Consider the matrix <span class="process-math">\(A = \begin{bmatrix}
2 \amp 1 \\
1 \amp 2
\end{bmatrix}
\text{.}\)</span>
</div>
<ol class="lower-alpha">
<li id="li-5706"><div class="para" id="p-8508">Find a singular value decomposition of <span class="process-math">\(A\)</span> and verify that it is also an orthogonal diagonalization of <span class="process-math">\(A\text{.}\)</span>
</div></li>
<li id="li-5707"><div class="para" id="p-8509">If <span class="process-math">\(A\)</span> is a symmetric, positive semidefinite matrix, explain why a singular value decomposition of <span class="process-math">\(A\)</span> is an orthogonal diagonalization of <span class="process-math">\(A\text{.}\)</span>
</div></li>
</ol>
</div></article><article class="exercise exercise-like" id="exercise-290"><h4 class="heading"><span class="codenumber">4<span class="period">.</span></span></h4>
<div class="para logical" id="p-8518">
<div class="para">Suppose that the matrix <span class="process-math">\(A\)</span> has the singular value decomposition</div>
<div class="displaymath process-math">
\begin{equation*}
\begin{bmatrix}
-0.46 \amp 0.52 \amp 0.46 \amp 0.55 \\
-0.82 \amp 0.00 \amp -0.14 \amp -0.55 \\
-0.04 \amp 0.44 \amp -0.85 \amp 0.28 \\
-0.34 \amp -0.73 \amp -0.18 \amp 0.55
\end{bmatrix}
\begin{bmatrix}
6.2 \amp 0.0 \amp 0.0 \\
0.0 \amp 4.1 \amp 0.0 \\
0.0 \amp 0.0 \amp 0.0 \\
0.0 \amp 0.0 \amp 0.0
\end{bmatrix}
\begin{bmatrix}
-0.74 \amp 0.62 \amp -0.24 \\
0.28 \amp 0.62 \amp 0.73 \\
-0.61 \amp -0.48 \amp 0.64
\end{bmatrix}.
\end{equation*}
</div>
<ol class="lower-alpha">
<li id="li-5712"><div class="para" id="p-8519">What are the dimensions of <span class="process-math">\(A\text{?}\)</span>
</div></li>
<li id="li-5713"><div class="para" id="p-8520">What is <span class="process-math">\(\rank(A)\text{?}\)</span>
</div></li>
<li id="li-5714"><div class="para" id="p-8521">Find orthonormal bases for <span class="process-math">\(\col(A)\text{,}\)</span> <span class="process-math">\(\nul(A)\text{,}\)</span> <span class="process-math">\(\col(A^{\transpose})\text{,}\)</span> and <span class="process-math">\(\nul(A^{\transpose})\text{.}\)</span>
</div></li>
<li id="li-5715"><div class="para" id="p-8522">Find the orthogonal projection of <span class="process-math">\(\bvec=\fourvec102{-1}\)</span> onto <span class="process-math">\(\col(A)\text{.}\)</span>
</div></li>
</ol>
</div></article><article class="exercise exercise-like" id="exercise-291"><h4 class="heading"><span class="codenumber">5<span class="period">.</span></span></h4>
<div class="para" id="p-8533">Consider the matrix <span class="process-math">\(A = \begin{bmatrix}
1 \amp 0 \amp -1 \\
2 \amp 2 \amp 0 \\
-1 \amp 1 \amp 2\\
\end{bmatrix}
\text{.}\)</span>
</div> <pre class="ptx-sagecell sagecell-python" id="sage-308"><script type="text/x-sage">
</script></pre> <div class="para logical" id="p-8534"><ol class="lower-alpha">
<li id="li-5724"><div class="para" id="p-8535">Construct the Gram matrix <span class="process-math">\(G\)</span> and use it to find the singular values and right singular vectors <span class="process-math">\(\vvec_1\text{,}\)</span> <span class="process-math">\(\vvec_2\text{,}\)</span> and <span class="process-math">\(\vvec_3\)</span> of <span class="process-math">\(A\text{.}\)</span>  What are the matrices <span class="process-math">\(\Sigma\)</span> and <span class="process-math">\(V\)</span> in a singular value decomposition?</div></li>
<li id="li-5725"><div class="para" id="p-8536">What is <span class="process-math">\(\rank(A)\text{?}\)</span>
</div></li>
<li id="li-5726"><div class="para" id="p-8537">Find as many left singular <span class="process-math">\(\uvec_j\)</span> as you can using the relationship <span class="process-math">\(A\vvec_j=\sigma_j\uvec_j\text{.}\)</span>
</div></li>
<li id="li-5727"><div class="para" id="p-8538">Find an orthonormal basis for <span class="process-math">\(\nul(A^{\transpose})\)</span> and use it to construct the matrix <span class="process-math">\(U\)</span> so that <span class="process-math">\(A=U\Sigma
V^{\transpose}\text{.}\)</span>
</div></li>
<li id="li-5728"><div class="para" id="p-8539">State an orthonormal basis for <span class="process-math">\(\nul(A)\)</span> and an orthonormal basis for <span class="process-math">\(\col(A)\text{.}\)</span>
</div></li>
</ol></div></article><article class="exercise exercise-like" id="exercise-292"><h4 class="heading"><span class="codenumber">6<span class="period">.</span></span></h4>
<div class="para" id="p-8550">Consider the matrix <span class="process-math">\(B=\begin{bmatrix}
1 \amp 0 \\
2 \amp -1 \\
1 \amp 2
\end{bmatrix}\)</span> and notice that <span class="process-math">\(B=A^{\transpose}\)</span> where <span class="process-math">\(A\)</span> is the matrix in <a href="" class="xref" data-knowl="./knowl/ex-7-4-1.html" title="Exercise 7.5.5.1">Exercise¬†7.5.5.1</a>.</div> <pre class="ptx-sagecell sagecell-python" id="sage-309"><script type="text/x-sage">
</script></pre> <div class="para logical" id="p-8551"><ol class="lower-alpha">
<li id="li-5739"><div class="para" id="p-8552">Use your result from <a href="" class="xref" data-knowl="./knowl/ex-7-4-1.html" title="Exercise 7.5.5.1">Exercise¬†7.5.5.1</a> to find a singular value decomposition of <span class="process-math">\(B=U\Sigma V^{\transpose}\text{.}\)</span>
</div></li>
<li id="li-5740"><div class="para" id="p-8553">What is <span class="process-math">\(\rank(B)\text{?}\)</span>  Determine a basis for <span class="process-math">\(\col(B)\)</span> and <span class="process-math">\(\col(B)^\perp\text{.}\)</span>
</div></li>
<li id="li-5741"><div class="para" id="p-8554">Suppose that <span class="process-math">\(\bvec=\threevec{-3}47\text{.}\)</span>  Use the bases you found in the previous part of this exericse to write <span class="process-math">\(\bvec=\bhat+\bvec^\perp\text{,}\)</span> where <span class="process-math">\(\bhat\)</span> is in <span class="process-math">\(\col(B)\)</span> and <span class="process-math">\(\bvec^\perp\)</span> is in <span class="process-math">\(\col(B)^\perp\text{.}\)</span>
</div></li>
<li id="li-5742"><div class="para" id="p-8555">Find the least squares approximate solution to the equation <span class="process-math">\(B\xvec=\bvec\text{.}\)</span>
</div></li>
</ol></div></article><article class="exercise exercise-like" id="exercise-293"><h4 class="heading"><span class="codenumber">7<span class="period">.</span></span></h4>
<div class="para logical" id="p-8566">
<div class="para">Suppose that <span class="process-math">\(A\)</span> is a square <span class="process-math">\(m\by m\)</span> matrix with singular value decomposition <span class="process-math">\(A=U\Sigma V^{\transpose}\text{.}\)</span>
</div>
<ol class="lower-alpha">
<li id="li-5751"><div class="para" id="p-8567">If <span class="process-math">\(A\)</span> is invertible, find a singular value decomposition of <span class="process-math">\(A^{-1}\text{.}\)</span>
</div></li>
<li id="li-5752"><div class="para" id="p-8568">What condition on the singular values must hold for <span class="process-math">\(A\)</span> to be invertible?</div></li>
<li id="li-5753"><div class="para" id="p-8569">How are the singular values of <span class="process-math">\(A\)</span> and the singular values of <span class="process-math">\(A^{-1}\)</span> related to one another?</div></li>
<li id="li-5754"><div class="para" id="p-8570">How are the right and left singular vectors of <span class="process-math">\(A\)</span> related to the right and left singular vectors of <span class="process-math">\(A^{-1}\text{?}\)</span>
</div></li>
</ol>
</div></article><article class="exercise exercise-like" id="exercise-294"><h4 class="heading"><span class="codenumber">8<span class="period">.</span></span></h4>
<div class="para logical" id="p-8581"><ol class="lower-alpha">
<li id="li-5763"><div class="para" id="p-8582">If <span class="process-math">\(Q\)</span> is an orthogonal matrix, remember that <span class="process-math">\(Q^{\transpose}Q=I\text{.}\)</span>  Explain why <span class="process-math">\(\det Q = \pm 1\text{.}\)</span>
</div></li>
<li id="li-5764"><div class="para" id="p-8583">If <span class="process-math">\(A=U\Sigma V^{\transpose}\)</span> is a singular value decomposition of a square matrix <span class="process-math">\(A\text{,}\)</span> explain why <span class="process-math">\(|\det A|\)</span> is the product of the singular values of <span class="process-math">\(A\text{.}\)</span>
</div></li>
<li id="li-5765"><div class="para" id="p-8584">What does this say about the singular values of <span class="process-math">\(A\)</span> if <span class="process-math">\(A\)</span> is invertible?</div></li>
</ol></div></article><article class="exercise exercise-like" id="exercise-295"><h4 class="heading"><span class="codenumber">9<span class="period">.</span></span></h4>
<div class="para logical" id="p-8593">
<div class="para">If <span class="process-math">\(A\)</span> is a matrix and <span class="process-math">\(G=A^{\transpose}A\)</span> its Gram matrix, remember that</div>
<div class="displaymath process-math">
\begin{equation*}
\xvec\cdot(G\xvec) = 
\xvec\cdot(A^{\transpose}A\xvec) =
(A\xvec)\cdot(A\xvec) = \len{A\xvec}^2.
\end{equation*}
</div>
<ol class="lower-alpha">
<li id="li-5772"><div class="para" id="p-8594">For a general matrix <span class="process-math">\(A\text{,}\)</span> explain why the eigenvalues of <span class="process-math">\(G\)</span> are nonnegative.</div></li>
<li id="li-5773"><div class="para" id="p-8595">Given a symmetric matrix <span class="process-math">\(A\)</span> having an eigenvalue <span class="process-math">\(\lambda\text{,}\)</span> explain why <span class="process-math">\(\lambda^2\)</span> is an eigenvalue of <span class="process-math">\(G\text{.}\)</span>
</div></li>
<li id="li-5774"><div class="para" id="p-8596">If <span class="process-math">\(A\)</span> is symmetric, explain why the singular values of <span class="process-math">\(A\)</span> equal the absolute value of its eigenvalues:  <span class="process-math">\(\sigma_j = |\lambda_j|\text{.}\)</span>
</div></li>
</ol>
</div></article><article class="exercise exercise-like" id="exercise-296"><h4 class="heading"><span class="codenumber">10<span class="period">.</span></span></h4>
<div class="para logical" id="p-8605">
<div class="para">Determine whether the following statements are true or false and explain your reasoning.</div>
<ol class="lower-alpha">
<li id="li-5781"><div class="para" id="p-8606">If <span class="process-math">\(A=U\Sigma V^{\transpose}\)</span> is a singular value decomposition of <span class="process-math">\(A\text{,}\)</span> then <span class="process-math">\(G=V(\Sigma^{\transpose}\Sigma)V^{\transpose}\)</span> is an orthogonal diagonalization of its Gram matrix.</div></li>
<li id="li-5782"><div class="para" id="p-8607">If <span class="process-math">\(A=U\Sigma V^{\transpose}\)</span> is a singular value decomposition of a rank 2 matrix <span class="process-math">\(A\text{,}\)</span> then <span class="process-math">\(\vvec_1\)</span> and <span class="process-math">\(\vvec_2\)</span> form an orthonormal basis for the column space <span class="process-math">\(\col(A)\text{.}\)</span>
</div></li>
<li id="li-5783"><div class="para" id="p-8608">If <span class="process-math">\(A\)</span> is a symmetric matrix, then its set of singular values is the same as its set of eigenvalues.</div></li>
<li id="li-5784"><div class="para" id="p-8609">If <span class="process-math">\(A\)</span> is a <span class="process-math">\(10\by7\)</span> matrix and <span class="process-math">\(\sigma_7
= 4\text{,}\)</span> then the columns of <span class="process-math">\(A\)</span> are linearly independent.</div></li>
<li id="li-5785"><div class="para" id="p-8610">The Gram matrix is always orthogonally diagonalizable.</div></li>
</ol>
</div></article><article class="exercise exercise-like" id="exercise-297"><h4 class="heading"><span class="codenumber">11<span class="period">.</span></span></h4>
<div class="para logical" id="p-8623">
<div class="para">Suppose that <span class="process-math">\(A=U\Sigma V^{\transpose}\)</span> is a singular value decomposition of the <span class="process-math">\(m\by n\)</span> matrix <span class="process-math">\(A\text{.}\)</span>  If <span class="process-math">\(\sigma_1,\ldots,\sigma_r\)</span> are the nonzero singular values, the general form of the matrix <span class="process-math">\(\Sigma\)</span> is</div>
<div class="displaymath process-math">
\begin{equation*}
\Sigma = 
\begin{bmatrix}
\sigma_1 \amp \ldots \amp 0 \amp \ldots \amp 0 \\
0 \amp \ldots \amp 0 \amp \ldots \amp 0 \\
0 \amp \ldots \amp \sigma_r \amp \ldots \amp 0 \\
0 \amp \ldots \amp 0 \amp \ldots \amp 0 \\
0 \amp \vdots \amp 0 \amp \vdots \amp 0 \\
0 \amp \ldots \amp 0 \amp \ldots \amp 0 \\
\end{bmatrix}.
\end{equation*}
</div>
<ol class="lower-alpha">
<li id="li-5796"><div class="para" id="p-8624">If you know that the columns of <span class="process-math">\(A\)</span> are linearly independent, what more can you say about the form of <span class="process-math">\(\Sigma\text{?}\)</span>
</div></li>
<li id="li-5797"><div class="para" id="p-8625">If you know that the columns of <span class="process-math">\(A\)</span> span <span class="process-math">\(\real^m\text{,}\)</span> what more can you say about the form of <span class="process-math">\(\Sigma\text{?}\)</span>
</div></li>
<li id="li-5798"><div class="para" id="p-8626">If you know that the columns of <span class="process-math">\(A\)</span> are linearly independent and span <span class="process-math">\(\real^m\text{,}\)</span> what more can you say about the form of <span class="process-math">\(\Sigma\text{?}\)</span>
</div></li>
</ol>
</div></article></section></section></div>
<div class="ptx-content-footer">
<a class="previous-button button" href="sec-pca.html" title="Previous"><span class="icon">&lt;</span><span class="name">Prev</span></a><a class="top-button button" href="#" title="Top"><span class="icon">^</span><span class="name">Top</span></a><a class="next-button button" href="sec-svd-uses.html" title="Next"><span class="name">Next</span><span class="icon">&gt;</span></a>
</div></main>
</div>
<div id="ptx-page-footer" class="ptx-page-footer">
<a class="pretext-link" href="https://pretextbook.org" title="PreTeXt"><div class="logo"><svg xmlns="http://www.w3.org/2000/svg" width="100%" height="100%" viewBox="338 3000 8772 6866"><g style="stroke-width:.025in; stroke:black; fill:none"><polyline points="472,3590 472,9732 " style="stroke:#000000;stroke-width:174; stroke-linejoin:miter; stroke-linecap:round; "></polyline><path style="stroke:#000000;stroke-width:126;stroke-linecap:butt;" d="M 4724,9448 A 4660 4660  0  0  1  8598  9259"></path><path style="stroke:#000000;stroke-width:174;stroke-linecap:butt;" d="M 4488,9685 A 4228 4228  0  0  0   472  9732"></path><path style="stroke:#000000;stroke-width:126;stroke-linecap:butt;" d="M 4724,3590 A 4241 4241  0  0  1  8598  3496"></path><path style="stroke:#000000;stroke-width:126;stroke-linecap:round;" d="M 850,3496  A 4241 4241  0  0  1  4724  3590"></path><path style="stroke:#000000;stroke-width:126;stroke-linecap:round;" d="M 850,9259  A 4507 4507  0  0  1  4724  9448"></path><polyline points="5385,4299 4062,8125" style="stroke:#000000;stroke-width:300; stroke-linejoin:miter; stroke-linecap:round;"></polyline><polyline points="8598,3496 8598,9259" style="stroke:#000000;stroke-width:126; stroke-linejoin:miter; stroke-linecap:round;"></polyline><polyline points="850,3496 850,9259" style="stroke:#000000;stroke-width:126; stroke-linejoin:miter; stroke-linecap:round;"></polyline><polyline points="4960,9685 4488,9685" style="stroke:#000000;stroke-width:174; stroke-linejoin:miter; stroke-linecap:round;"></polyline><polyline points="3070,4582 1889,6141 3070,7700" style="stroke:#000000;stroke-width:300; stroke-linejoin:miter; stroke-linecap:round;"></polyline><polyline points="6418,4582 7600,6141 6418,7700" style="stroke:#000000;stroke-width:300; stroke-linejoin:miter; stroke-linecap:round;"></polyline><polyline points="8976,3590 8976,9732" style="stroke:#000000;stroke-width:174; stroke-linejoin:miter; stroke-linecap:round;"></polyline><path style="stroke:#000000;stroke-width:174;stroke-linecap:butt;" d="M 4960,9685 A 4228 4228  0  0  1  8976  9732"></path></g></svg></div></a><a class="runestone-link" href="https://runestone.academy" title="Runestone Academy"><img class="logo" src="https://runestone.academy/runestone/static/images/RAIcon_cropped.png"></a><a class="mathjax-link" href="https://www.mathjax.org" title="MathJax"><img class="logo" src="https://www.mathjax.org/badge/badge-square-2.png"></a>
</div>
</body>
</html>
