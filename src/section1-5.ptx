<?xml version="1.0" encoding="UTF-8"?>

<section xml:id="sec-tensors"
	xmlns:xi="http://www.w3.org/2001/XInclude">

	<title> Tensors </title>

	<introduction>
		<p>
			As we have seen, <c>numpy</c> treats vectors and matrices as 1-dimensional 
			and 2-dimensional arrays (both created using <c>np.array()</c>). 
			While mathematically 2-dimensional arrays (i.e, matrices) are the most 
			important (and vectors can be treated like <m>n \by 1</m> matrices); 
			computationally, there is no reason we need to stop at rows 
			and columns. We could add additional dimensions.  Higher dimensional 
			arrays are often called <term>tensors</term>.
		<idx>tensor</idx>
		</p>

	<p>
		There are two primary reasons for taking some time to think about tensors here.
		First, there are some interesting applications that use tensors.  One example of  
		this is color images.  Recall that color images store a matrix of values 
		<em>for each color channel</em>. So we have 3 indices into this data: 
		vertical position (row), horizontal position (column), and color channel. 
		If we have many images, we could store them in a 4-dimensional array, using 
		the additional index to indicate which photo is which.
	</p>

	<p>
		The second reason to discuss tensors is that most of the <c>numpy</c> code that works with 
		vectors and matrices is designed to work with higher dimensional tensors as well. 
		Understanding this can help demistify how some of the <c>numpy</c> functions work.
	</p>
		
	</introduction>

<subsection xml:id="subsec-numpy-tensors">
	<title>Tensors in Numpy</title>
	
	<p>
		Let's create a small 3-dimensional tensor.  Notice that we can assign the shape 
		(as long as the product of the items in our tuple is equal to the number values 
		in the array).

	<sage language="python">
	<input>
import numpy as np
A = np.arange(2 * 4 * 3)
A.shape = (2, 4, 3)
print(A)
	</input>
	</sage>
	</p>

	<p>
		The output above expresses <c>A</c> as two <m>4 \by 3</m> matrices, and we can separate out 
		those two matrices as <c>A[0]</c> and <c>A[1]</c>.  
	</p>

	<p>We can refer to individual numbers in an ndarray by providing the required number of indices.
	<sage language="python">
	<input>
print(A[0,1,2])
	</input>
	</sage>
	</p>

	<p>
		The indexing is more flexible than demonstrated above. In each slot we can provide a 
		<term>slice</term> of values. A slice has the format <c>start:stop:step</c>. If omitted,
		<c>start</c> is taken to be 0, <c>stop</c> is taken to be the length of the array in 
		that dimension, and <c>step</c> is taken to be 1.  To get all the values in some dimension,
		we can use <c>:</c>.  
	<idx> slice, of a matrix or tensor </idx>
	</p>

	<p>
		An interesting question is what the shape of the resulting array should be, and we have some control 
		over whether dimensions are dropped or not. Consider the following examples.
	<sage language="python">
	<input>
print(A[:,:,1].shape)        # integer -> 2d
print(A[:,:,(1)].shape)      # tuple of length 1 -> 2d
print(A[:,:,1:2].shape)      # slice with one value -> 3d
print(A[:,:,[1]].shape)      # list of length 1 -> 3d
	</input>
	<output>
(2, 4)
(2, 4)
(2, 4, 1)
(2, 4, 1)
	</output>
	</sage>
	The first two methods drop a dimension.  The latter two retain all three axes, even though one of them has only one 
	legal index (0). It is always important to know the shape of the arrays you are working with.  When in doubt, check.
	</p>


	<example>
		<statement>
			<p>
				An RGB image that is 400 pixels wide and 300 pixels tall 
				might correspond to a tensor with shape <c>(400, 300, 3)</c>. 
		Or perhaps <c>(3, 300, 400)</c>, or ... 
		The computer doesn't really care, but we need to know which slot is being used for what 
		in order to work with this image correctly.  The usual arrangement is row, column, channel.
		This is called the <term>channels-last convention</term>. But somtimes a channels-first 
		convention is used instead.
		<idx> channels-last convention </idx>
			</p>
			<p>
			  We can plot images (or other matrices that we would like to view as an image)	
			  using a number of different tools.  Here we demonstrate how to do so using 
			  <c>matplotlib</c>. <c>matplotlib</c> supports a variety of image formats. For RGB 
			  images, the RGB values can be integers from 0 to 255 or floating point 
			  values between 0 and 1.

			</p>
			
			<note>
				<title>The Sage Cell Server restricts internet access</title>
				<p>
				Feel free to experiment with this code using other images, but note that 
				the Sage Cell Server only allows  access to images on selected websites.
				This list includes sites like GitHub (used here) and Wikimedia Commons.
				</p>
			</note>
			<p>
			  <sage language="python">
			  <input>
import numpy as np
from skimage import io
import matplotlib.pyplot as plt 
url = "https://rpruim.github.io/data/images/happy-dog.jpeg"
dog = io.imread(url)
print(dog.shape)
print(dog.dtype)
plt.figure()
plt.imshow(dog)
plt.show()
			  </input>
			  </sage>
			</p>

			<p> Notice that <c>dog</c> contains a 3-dimensional array of unsiged 8-bit integers (0 -- 255) and 
			that the format is channels-last. We can plot individual channels in the same way.
			<sage language="python">
				<input>
plt.figure()
plt.imshow(dog[:, :, 0])    # Red channel
plt.show()
				</input>
			</sage>
			</p>
			<p>
				We've added a color bar to this image to show how matplotlib is mapping the values 0 to 255 to colors.
				Remember, this is the <em>red</em> channel. So a colormap that runs from dark blue to bright yellow  
				probably isn't the best choice.  We can use a scale of reds by setting <c>cmap="Reds"</c> 
				like this
			<sage language="python">
				<input>
plt.figure()
plt.imshow(dog[:, :, 0], cmap = "Reds")    # Red channel
plt.show()
				</input>
			</sage>
			If you use <c>cmap  = "Reds_r"</c> (give it a try), the order of the colors will be reversed and provide 
			a better visual representation (for human eyes -- it's the same data no matter what color scheme we  
			use for display).
				</p>
				<p>
					You can find out more about the many colormaps that are available in matplotlib at 
					<url href="https://matplotlib.org/stable/tutorials/colors/index.html"
					   visual="matplotlib.org/stable/tutorials/colors/index.html" />.
				</p>
		</statement>
	</example>

</subsection>

	<subsection xml:id="subsec-axes">
		<title>Aggregation and Axes</title>


	</subsection>

<subsection xml:id="subsec-ndarray-append">
	<title>Expanding an array</title>

	<p>
		Sometimes it is useful to build up a matrix or other <m>n</m>-dimensional
		array bit by bit or to add an additional "layer" (think row or column) to an 
		existing array. For example, to create an augmented matrix, we will often 
		append an additional column matrix to an existing matrix, increasing the number 
		of columns by one. <c>np.append()</c> allows us to do this, provided our arrays 
		(a) have the same number of dimensions and (b) compatible shapes along the desired 
		axis.
	</p>
	<p>
		Here's an example where we add a column onto a <m>3 \by 2 </m> matrix.

		<sage language="python">
			<input>
import numpy as np 
A = np.arange(6).reshape((3,2))
b = np.array([5, 3, 2])
Aplus = np.append(A, b.reshape(3,1), 1)    # need to make b 2-d first
print(Aplus)
			</input>
			<output>
[[0 1 5]
 [2 3 3]
 [4 5 2]]
			</output>
		</sage>
		Notice that <c>np.append()</c> does not modify its arguments. It returns a new (larger) array.
	</p>

	<p>
		Numpy provides several other functions that can be used to create larger arrays by combining smaller arrays.
		<ul>
			<li>
				<p>
					<c>np.concetentate()</c> takes a sequence of arrays and repeatedly appends. This is especially 
					useful for combining three or more arrays.
				</p>
			</li>
			<li>
				<p>
					<c>np.stack()</c> (and specialized versions <c>np.hstack()</c>, <c>np.vstack()</c>, and
					<c>np.column_stack()</c>) concatenate along a <em>new</em> axis. This can be used to combine 
					vectors into an array or arrays into a tensor. The resulting object will have a higher dimension (more axes) 
					than the inputs.
				</p>
			</li>
			<li>
				<p>
					<c>np.block()</c> creates a new array from a nested sequences of blocks. 
				</p>
			</li>
			<li>
				<p>
					<c>np.insert()</c> allows insertion into a slice.  
				</p>
			</li>
		</ul>
	</p>

	<example>
		<statement>
					
			<p>
					In scenes were some regions are very bright and others very dark, it can be challenging 
					to create a good exposure over the entire image. Exposure bracketing is a technique that has 
					been used since the 1850's to help with this situation. This technique involves capturing 
					multiple images, each with a different exposure. Later one can choose the best of the captured 
					images or combine them in some way.  In the 1850's, Gustave Le Gray printed seascape photos 
					from two images, using one exposure for the sky and the other for the water. Modern HDR methods 
					can combine multiple digital images in much more complex ways.
			</p>

			<p>
				In this example we stack multiple images with different exposures and use a very 
				simple method (averaging) to convert the stack of images into a single HDR (high dynamic range) 
				image. 
				<idx><h>high dynamic range (HDR) images</h></idx>
				This works because each images loses some information in the brightest or darkest regions 
				due to the limits on the values (typically 0 to 255) that each pixel may have. The averages will remain 
				in the appropriate range, but do a better job of distinguishing among the very dark and very bright 
				regions of the image.
			</p>

			<p>
				The images were obtained from <url href="https://commons.wikimedia.org/wiki/File:StLouisArchMultExpEV%2B1.51.JPG" />.
				We will use low resolutoin images below, but you can repeat this example with higher resolution 
				images if you like. Notice the use of <c>np.stack()</c> to combine the images into one 4-dimensional 
				tensor, and the use of <c>np.rint()</c> and <c>astype(int)</c> to make sure the resulting data 
				is again integer (the nearest integer to the average).
				<sage language="python">
					<input>
import numpy as np
from skimage import io
import matplotlib.pyplot as plt 
url = "https://rpruim.github.io/data/images/StLouisArchMultExpEV1.jpg"
urls = [url.replace('1', x) for x in ["1","2","3","4"]]
print(urls)

photos = [io.imread(u) for u in urls]
photo_stack = np.stack(photos)
print(p.shape for p in photos)
print(photo_stack.shape)
average_photo = np.rint(photo_stack.mean(axis = 0)).astype(int)
fig, ax = plt.subplots(1, 4)
print("four different exposures")
for i in range(4):
    ax[i].imshow(photos[i])
plt.show()
print("the average image")

plt.subplots(1, 1)

plt.imshow(average_photo)
plt.show()						
					</input>
				</sage>

			More sophisticated algorithms can do an even better job of creating the final image  
			from multiple exposures of the same scene.
				
			</p>
		</statement>
		<solution>
			<p>
				
			</p>
		</solution>
	</example>

	
</subsection>

	<subsection xml:id="subsec-broadcasting">
		<title>Broadcasting</title>

	</subsection>
</section>


