<?xml version="1.0" encoding="UTF-8"?>

<exercises>

  <exercise>
    <statement>
      <p>
	Consider the matrix
	<me>
	  A = \left[\begin{array}{rrrr}
	  3 \amp -1 \amp 1 \amp 4 \\
	  0 \amp 2 \amp 3 \amp 1 \\
	  -2 \amp 1 \amp 0 \amp -2 \\
	  3 \amp 0 \amp 1 \amp 2 \\
	  \end{array}\right]
	</me>.
	<sage>
	  <input>
	  </input>
	</sage>
	<ol marker="a.">
	  <li><p> Explain why <m>A</m> has an
	  inverse. </p></li>

	  <li><p> Find the inverse of <m>A</m> by augmenting by the
	  identity <m>I</m> to form <m>\left[\begin{array}{r|r}A \amp
	  I \end{array}\right]</m>. </p></li>

	  <li><p> Use your inverse to solve the equation <m>A\xvec =
	  \fourvec{3}{2}{-3}{-1}</m>. </p></li>
	</ol>
      </p>
    </statement>

    <solution>
      <p><ol marker="a.">
	<li><p>
	  We see that <m>A\sim I</m>, the identity matrix, which
	  implies that <m>A</m> has an inverse.
	</p></li>

	<li><p>
	  We have
	  <me>
	    \begin{array}{l}
	    \left[\begin{array}{rrrr|rrrr}
	    3 \amp -1 \amp 1 \amp 4 \amp 1 \amp 0 \amp 0 \amp 0 \\
	    0 \amp 2 \amp 3 \amp 1 \amp 0 \amp 1 \amp 0 \amp 0 \\
	    -2 \amp 1 \amp 0 \amp -2 \amp 0 \amp 0 \amp 1 \amp 0 \\
	    3 \amp 0 \amp 1 \amp 2 \amp 0 \amp 0 \amp 0 \amp 1
	    \end{array}\right] \\
	    \sim
	    \left[\begin{array}{rrrr|rrrr}
              1 \amp 0 \amp 0 \amp 0 \amp -\frac{1}{2} \amp 0 \amp -\frac{1}{2} \amp \frac{1}{2} \\
              0 \amp 1 \amp 0 \amp 0 \amp 4 \amp -2 \amp 9 \amp 2 \\
              0 \amp 0 \amp 1 \amp 0 \amp -\frac{7}{2} \amp 2 \amp -\frac{15}{2} \amp -\frac{3}{2} \\
              0 \amp 0 \amp 0 \amp 1 \amp \frac{5}{2} \amp -1 \amp \frac{9}{2} \amp \frac{1}{2}
	    \end{array}\right]\text{,}
	    \end{array}
	  </me>
	  which says that
	  <me>
	    A^{-1} =
	    \left[\begin{array}{rrrr}
              -\frac{1}{2} \amp 0 \amp -\frac{1}{2} \amp \frac{1}{2} \\
              4 \amp -2 \amp 9 \amp 2 \\
              -\frac{7}{2} \amp 2 \amp -\frac{15}{2} \amp -\frac{3}{2} \\
              \frac{5}{2} \amp -1 \amp \frac{9}{2} \amp \frac{1}{2}
	    \end{array}\right]\text{.}
	  </me>
	</p></li>

	<li><p>
	  We compute that <m>\xvec=A^{-1}\fourvec{3}{2}{-3}{-1} =
	  \fourvec{-\frac12}{-21}{\frac{35}2}{-\frac{17}{2}}
	  </m>.
	</p></li>
      </ol></p>
    </solution>

    <answer>
      <p><ol marker="a.">
	<li><p>
	  <m>A\sim I</m>
	</p></li>

	<li><p>
	  <m>
	    A^{-1} =
	    \left[\begin{array}{rrrr}
              -\frac{1}{2} \amp 0 \amp -\frac{1}{2} \amp \frac{1}{2} \\
              4 \amp -2 \amp 9 \amp 2 \\
              -\frac{7}{2} \amp 2 \amp -\frac{15}{2} \amp -\frac{3}{2} \\
              \frac{5}{2} \amp -1 \amp \frac{9}{2} \amp \frac{1}{2}
	    \end{array}\right]\text{.}
	  </m>
	</p></li>

	<li><p>
	  <m>\xvec=
	  \fourvec{-\frac12}{-21}{\frac{35}2}{-\frac{17}{2}}
	  </m>.
	</p></li>
      </ol></p>
    </answer>
	
  </exercise>

  <exercise>
    <statement>
      <p> In this exercise, we will consider <m>2\times 2</m> matrices
      as defining matrix transformations.
      <ol marker="a.">
	<li><p> Write the matrix <m>A</m> that performs a <m>45^\circ</m>
	rotation.  What geometric operation undoes this rotation?
	Find the matrix that perform this operation and verify that it
	is <m>A^{-1}</m>.  </p></li>

	<li><p> Write the matrix <m>A</m> that performs a
	<m>180^\circ</m> rotation.  Verify that <m>A^2 = I</m> so that
	<m>A^{-1} = A</m>, and explain geometrically why this is the
	case.  </p></li>

	<li><p> Find three more matrices <m>A</m> that satisfy <m>A^2
	= I</m>. </p></li>
      </ol></p>
    </statement>

    <solution>
      <p><ol marker="a.">
	<li><p>
	  <m>A=\left[\begin{array}{rr}
	  \frac1{\sqrt{2}} \amp -\frac1{\sqrt{2}} \\
	  \frac1{\sqrt{2}} \amp \frac1{\sqrt{2}} \\
	  \end{array}\right]</m>.  To undo the rotation, we will
	  perform a <m>45^\circ</m> clockwise rotation, which is
	  defined by the matrix
	  <m>A^{-1}=\left[\begin{array}{rr}
	  \frac1{\sqrt{2}} \amp \frac1{\sqrt{2}} \\
	  -\frac1{\sqrt{2}} \amp \frac1{\sqrt{2}} \\
	  \end{array}\right]</m>.
	</p></li>

	<li><p>
	  <m>A=\left[\begin{array}{rr}
	  -1 \amp 0 \\
	  0 \amp -1 \\
	  \end{array}\right]</m>.  We see that <m>A^2=I</m> because
	  rotating by <m>180^\circ</m> is its own inverse.
	</p></li>

	<li><p>
	  We can do this by constructing matrices that define
	  reflections, such as
	  <me>
	    \left[\begin{array}{rr}
	    1 \amp 0 \\
	    0 \amp -1 \\
	    \end{array}\right],
	    \left[\begin{array}{rr}
	    -1 \amp 0 \\
	    0 \amp 1 \\
	    \end{array}\right],
	    \left[\begin{array}{rr}
	    0 \amp 1 \\
	    1 \amp 0 \\
	    \end{array}\right]\text{.}
	  </me>
	</p></li>
      </ol></p>
    </solution>

    <answer>
      <p><ol marker="a.">
	<li><p>
	  <m>A=\left[\begin{array}{rr}
	  \frac1{\sqrt{2}} \amp -\frac1{\sqrt{2}} \\
	  \frac1{\sqrt{2}} \amp \frac1{\sqrt{2}} \\
	  \end{array}\right]</m>
	  and
	  <m>A^{-1}=\left[\begin{array}{rr}
	  \frac1{\sqrt{2}} \amp \frac1{\sqrt{2}} \\
	  -\frac1{\sqrt{2}} \amp \frac1{\sqrt{2}} \\
	  \end{array}\right]</m>.
	</p></li>

	<li><p>
	  <m>A=\left[\begin{array}{rr}
	  -1 \amp 0 \\
	  0 \amp -1 \\
	  \end{array}\right]</m>.  
	</p></li>

	<li><p>
	  <me>
	    \left[\begin{array}{rr}
	    1 \amp 0 \\
	    0 \amp -1 \\
	    \end{array}\right],
	    \left[\begin{array}{rr}
	    -1 \amp 0 \\
	    0 \amp 1 \\
	    \end{array}\right],
	    \left[\begin{array}{rr}
	    0 \amp 1 \\
	    1 \amp 0 \\
	    \end{array}\right]\text{.}
	  </me>
	</p></li>
      </ol></p>
    </answer>
	  
  </exercise>

  <exercise>
    <statement>
      <p> Inverses for certain types of matrices can be found in a
      relatively straightforward fashion.
      <ol marker="a.">
	<li>
	  <p>
	    The matrix
	    <m>D=\begin{bmatrix}
	    2 \amp 0 \amp 0 \\
	    0 \amp -1 \amp 0 \\
	    0 \amp 0 \amp -4 \\
	    \end{bmatrix}
	    </m> is called <em>diagonal</em> since the only nonzero
	    entries are on the diagonal of the matrix.
	  </p>
	  <p>
	    <ol marker="1.">
	      <li>
		<p>
		  Find <m>D^{-1}</m> by augmenting <m>D</m> by the identity
		  and finding its reduced row echelon form.
		</p>
	      </li>
	      <li>
		<p>
		  Under what conditions is a diagonal matrix
		  invertible?
		</p>
	      </li>
	      <li>
		<p>
		  Explain why the inverse of a diagonal matrix is also
		  diagonal and explain the relationship between the
		  diagonal entries in <m>D</m> and <m>D^{-1}</m>.
		</p>
	      </li>
	    </ol>
	  </p>
	</li>
	<li>
	  <p>
	    Consider the lower triangular matrix
	    <m>L = \begin{bmatrix}
	    1 \amp 0 \amp 0 \\
	    -2 \amp 1 \amp 0 \\
	    3 \amp -4 \amp 1 \\
	    \end{bmatrix}
	    </m>.
	    <ol marker="1.">
	      <li>
		<p>
		  Find <m>L^{-1}</m> by augmenting <m>L</m> by the
		  identity and finding its reduced row echelon form.
		</p>
	      </li>
	      <li>
		<p>
		  Explain why the inverse of a lower triangular
		  matrix is also lower triangular.
		</p>
	      </li>
	    </ol>
	  </p>
	</li>
      </ol>
      </p>
    </statement>
    <solution>
      <p>
	<ol marker="a.">
	  <li>
	    <p>
	      <ol marker="1.">
		<li>
		  <p>
		    <m> D^{-1} = \begin{bmatrix}
		    \frac12 \amp 0 \amp 0 \\
		    0 \amp -1 \amp 0 \\
		    0 \amp 0 \amp \frac14 \\
		    \end{bmatrix}
		    </m>.
		  </p>
		</li>
		<li>
		  <p>
		    When the entries on the diagonal are all nonzero.
		  </p>
		</li>
		<li>
		  <p>
		    Because the process of row reducing <m>D</m>
		    augmented by <m>I</m> can be performed using only
		    scalings.  Then the diagonal entries of <m>D</m>
		    and <m>D^{-1}</m> are reciprocals of one another.
		  </p>
		</li>
	      </ol>
	    </p>
	  </li>
	  <li>
	    <p>
	      <ol marker="1.">
		<li>
		  <p>
		    <m>L^{-1} = \begin{bmatrix}
		    1 \amp 0 \amp 0 \\
		    -2 \amp 1 \amp 0 \\
		    -11 \amp 4 \amp 1
		    \end{bmatrix}
		    </m>.
		  </p>
		</li>
		<li>
		  <p>
		    <m>L^{-1}</m> is always lower triangular because
		    the only row operations needed to row reduce
		    <m>L</m> augmented by <m>I</m> are replacements in
		    which a multiple of one row is added to a row
		    underneath it.
		  </p>
		</li>
	      </ol>
	    </p>
	  </li>

	</ol>
      </p>
    </solution>
    <answer>
      <p>
	<ol marker="a.">
	  <li>
	    <p>
	      <ol marker="1.">
		<li>
		  <p>
		    <m> D^{-1} = \begin{bmatrix}
		    \frac12 \amp 0 \amp 0 \\
		    0 \amp -1 \amp 0 \\
		    0 \amp 0 \amp \frac14 \\
		    \end{bmatrix}
		    </m>.
		  </p>
		</li>
		<li>
		  <p>
		    When the entries on the diagonal are all nonzero.
		  </p>
		</li>
		<li>
		  <p>
		    Consider the steps performed in 
		    row reducing <m>D</m>
		    augmented by <m>I</m>.
		  </p>
		</li>
	      </ol>
	    </p>
	  </li>
	  <li>
	    <p>
	      <ol marker="1.">
		<li>
		  <p>
		    <m>L^{-1} = \begin{bmatrix}
		    1 \amp 0 \amp 0 \\
		    -2 \amp 1 \amp 0 \\
		    -11 \amp 4 \amp 1
		    \end{bmatrix}
		    </m>.
		  </p>
		</li>
		<li>
		  <p>
		    Consider the steps in row reducing
		    <m>L</m> augmented by <m>I</m>.
		  </p>
		</li>
	      </ol>
	    </p>
	  </li>
	</ol>
      </p>
    </answer>
  </exercise>
		

  <exercise>
    <statement>
      <p>
	Our definition of an invertible matrix requires that <m>A</m>
	be a square <m>n\times n</m> matrix.  Let's examine what
	happens when <m>A</m> is not square.  For instance, suppose
	that 
	<me>
	  A = \left[\begin{array}{rr}
	  -1 \amp -1 \\
	  -2 \amp -1 \\
	  3 \amp 0 \\
	  \end{array}\right],
	  \hspace{24pt}
	  B = \left[\begin{array}{rrr}
	  -2 \amp 2 \amp 1 \\
	  1 \amp -2 \amp -1 \\
	  \end{array}\right]
	</me>.
	<ol marker="a.">
	  <li><p>
	    Verify that <m>BA = I_2</m>.  In this case, we say that
	    <m>B</m> is a <em>left</em> inverse of <m>A</m>.
	    <sage>
	      <input>
	      </input>
	    </sage>
	  </p></li>

	  <li><p> If <m>A</m> has a left inverse <m>B</m>, we can
	  still use it to find solutions to linear equations.  If we
	  know there is a solution to the equation
	  <m>A\xvec = \bvec</m>, we can
	  multiply both sides of the equation by <m>B</m> to find
	  <m>\xvec = B\bvec</m>.
	</p>
	<p>
	  Suppose you know there is a solution to the equation
	  <m>A\xvec = \threevec{-1}{-3}{6}</m>.  Use the left inverse
	  <m>B</m> to find <m>\xvec</m> and verify that it is a
	  solution.  </p></li>

	  <li><p> Now consider the matrix
	  <me>
	    C = \left[\begin{array}{rrr}
	    1 \amp -1 \amp 0 \\
	    -2 \amp 1 \amp 0 \\
	    \end{array}\right]
	  </me> and verify that <m>C</m> is also a left inverse of
	  <m>A</m>.  This shows that the matrix <m>A</m> may have more
	  than one left inverse.
	  </p></li>
      
	</ol>
      </p>
    </statement>

    <solution>
      <p><ol marker="a.">
	<li><p>
	  We compute that <m>BA=I_2</m>.
	</p></li>

	<li><p>
	  We find <m>\xvec=B\threevec{-1}{-3}{6} = \twovec{2}{-1}</m>,
	  which is indeed a solution to the equation
	  <m>A\xvec=\threevec{-1}{-3}{6}</m>.
	</p></li>

	<li><p>
	  In the same way, we compute <m>CA=I_2</m>.
	</p></li>

      </ol></p>
    </solution>

    <answer>
      <p><ol marker="a.">
	<li><p>
	  <m>BA=I_2</m>.
	</p></li>

	<li><p>
	  <m>\xvec= \twovec{2}{-1}</m>
	</p></li>

	<li><p>
	  <m>CA=I_2</m>.
	</p></li>

      </ol></p>
    </answer>
  </exercise>

  <exercise>
    <statement>
      <p> If a matrix <m>A</m> is invertible, there is a sequence of
      row operations that transforms <m>A</m> into the
      identity matrix <m>I</m>.  We have seen that every row operation can be
      performed by matrix multiplication.  If the <m>j^{th}</m> step
      in the Gaussian elimination process is performed by multiplying
      by <m>E_j</m>, then we have
      <me>
	E_p\cdots E_2E_1 A = I
      </me>,
      which means that
      <me>
	A^{-1} = E_p\cdots E_2E_1
      </me>.
      For each of the following matrices, find a sequence of row
      operations that transforms the matrix to the identity <m>I</m>.
      Write the matrices <m>E_j</m> that perform the steps and use
      them to find <m>A^{-1}</m>.
      <ol marker="a.">
	<li><p>
	  <me>A = \left[\begin{array}{rrr}
	  0 \amp 2 \amp 0 \\
	  -3 \amp 0 \amp 0 \\
	  0 \amp 0 \amp 1 \\
	  \end{array}\right]
	  </me>.
	</p></li>

      	<li><p>
	  <me>A = \left[\begin{array}{rrrr}
	  1 \amp 0 \amp 0 \amp 0 \\
	  2 \amp 1 \amp 0 \amp 0 \\
	  0 \amp -3 \amp 1 \amp 0 \\
	  0 \amp 0 \amp 2 \amp 1 \\
	  \end{array}\right]
	  </me>.
	</p></li>

	<li><p>
	  <me>A = \left[\begin{array}{rrr}
	  1 \amp 1 \amp 1 \\
	  0 \amp 1 \amp 1 \\
	  0 \amp 0 \amp 2 \\
	  \end{array}\right]
	  </me>.
	</p></li>

      </ol></p>
    </statement>

    <solution>
      <p><ol marker="a.">
	<li><p>
	  If
	  <me>
	    P =
	    \left[\begin{array}{rrr}
	    0 \amp 1 \amp 0 \\
	    1 \amp 0 \amp 0 \\
	    0 \amp 0 \amp 1 \\
	    \end{array}\right],
	    S_1 =
	    \left[\begin{array}{rrr}
	    -\frac13 \amp 0 \amp 0 \\
	    0 \amp 1 \amp 0 \\
	    0 \amp 0 \amp 1 \\
	    \end{array}\right],
	    S_2 =
	    \left[\begin{array}{rrr}
	    1 \amp 0 \amp 0 \\
	    0 \amp \frac12 \amp 0 \\
	    0 \amp 0 \amp 1 \\
	    \end{array}\right]\text{,}
	  </me>
	  then <m>S_2S_1P A = I</m> so that <m>A^{-1}=S_2S_1P=
	  \left[\begin{array}{rrr}
	  0 \amp -\frac13 \amp 0 \\
	  \frac12 \amp 0 \amp 0 \\
	  0 \amp 0 \amp 1 \\
	  \end{array}\right]
	  </m>.
	</p></li>

	<li><p>
	  We use three replacement operations
	  <me>
	    \begin{array}{l}
	    L_1 =
	    \left[\begin{array}{rrrr}
	    1 \amp 0 \amp 0 \amp 0 \\
	    -2 \amp 1 \amp 0 \amp 0 \\
	    0 \amp 0 \amp 1 \amp 0 \\
	    0 \amp 0 \amp 0 \amp 1 \\
	    \end{array}\right],
	    L_2 =
	    \left[\begin{array}{rrrr}
	    1 \amp 0 \amp 0 \amp 0 \\
	    0 \amp 1 \amp 0 \amp 0 \\
	    0 \amp 3 \amp 1 \amp 0 \\
	    0 \amp 0 \amp 0 \amp 1 \\
	    \end{array}\right], \\
	    L_3 =
	    \left[\begin{array}{rrrr}
	    1 \amp 0 \amp 0 \amp 0 \\
	    0 \amp 1 \amp 0 \amp 0 \\
	    0 \amp 0 \amp 1 \amp 0 \\
	    0 \amp 0 \amp -2 \amp 1 \\
	    \end{array}\right]\text{.}
	    \end{array}
	  </me>
	  Therefore, <m>L_3L_2L_1A = I</m> so <m>A^{-1} = L_3L_2L_1 =
	    \left[\begin{array}{rrrr}
	    1 \amp 0 \amp 0 \amp 0 \\
	    -2 \amp 1 \amp 0 \amp 0 \\
	    -6 \amp 3 \amp 1 \amp 0 \\
	    12 \amp -6 \amp -2 \amp 1 \\
	    \end{array}\right]
	  </m>.
	</p></li>

	<li><p>
	  We use a scaling followed by replacement operations:
	  <me>
	    S =
	    \left[\begin{array}{rrr}
	    1 \amp 0 \amp 0 \\
	    0 \amp 1 \amp 0 \\
	    0 \amp 0 \amp \frac12 \\
	    \end{array}\right],
	    U_1 =
	    \left[\begin{array}{rrr}
	    1 \amp 0 \amp -1 \\
	    0 \amp 1 \amp -1 \\
	    0 \amp 0 \amp 1 \\
	    \end{array}\right],
	    U_2 = \begin{bmatrix}
	    1 \amp 0 \amp -1 \\
	    0 \amp 1 \amp 0 \\
	    0 \amp 0 \amp 1 \\
	    \end{bmatrix},
	    U_3 = 
	    \left[\begin{array}{rrr}
	    1 \amp -1 \amp 0 \\
	    0 \amp 1 \amp 0 \\
	    0 \amp 0 \amp 1 \\
	    \end{array}\right]\text{.}
	  </me>
	  This gives <m>U_3U_2U_1SA = I</m> so that
	  <m>
	    A^{-1} = U_3U_2U_1S =
	    \left[\begin{array}{rrr}
	    1 \amp -1 \amp 0 \\
	    0 \amp 1 \amp -\frac12 \\
	    0 \amp 0 \amp \frac12 \\
	    \end{array}\right]
	    </m>.
	</p></li>
      </ol></p>
    </solution>

    <answer>
      <p><ol marker="a.">
	<li><p>
	  <m>A^{-1}=
	  \left[\begin{array}{rrr}
	  0 \amp -\frac13 \amp 0 \\
	  \frac12 \amp 0 \amp 0 \\
	  0 \amp 0 \amp 1 \\
	  \end{array}\right]
	  </m>.
	</p></li>

	<li><p>
	  <m>A^{-1} = 
	    \left[\begin{array}{rrrr}
	    1 \amp 0 \amp 0 \amp 0 \\
	    -2 \amp 1 \amp 0 \amp 0 \\
	    -6 \amp 3 \amp 1 \amp 0 \\
	    12 \amp -6 \amp -2 \amp 1 \\
	    \end{array}\right]
	  </m>.
	</p></li>

	<li><p>
	  <m>
	    A^{-1} = 
	    \left[\begin{array}{rrr}
	    1 \amp -1 \amp 0 \\
	    0 \amp 1 \amp -\frac12 \\
	    0 \amp 0 \amp \frac12 \\
	    \end{array}\right]
	    </m>.
	</p></li>
      </ol></p>
    </answer>
    
  </exercise>

  <exercise>
    <statement>
      <p> Suppose that <m>A</m> is an <m>n\times n</m> matrix.
      <ol marker="a.">
	<li><p> Suppose that <m>A^2 = AA</m> is invertible with
	inverse <m>B</m>.  This means that <m>A^2B = AAB = I</m>.
	Explain why <m>A</m> must be invertible with inverse
	<m>AB</m>. </p></li>

	<li><p> Suppose that <m>A^{100}</m> is invertible with inverse
	<m>B</m>.  Explain why <m>A</m> is invertible.  What is
	<m>A^{-1}</m> in terms of <m>A</m> and <m>B</m>? </p></li>
      </ol></p>
    </statement>

    <solution>
      <p><ol marker="a.">
	<li><p>
	  If <m>A^2</m> has inverse <m>B</m>, then <m>A^2B = I</m>.
	  This means that <m>A(AB)=I</m> so <m>A</m> is invertible
	  with inverse <m>AB</m>.
	</p></li>

	<li><p>
	  In the same way, we have <m>A^{100}B = A(A^{99}B)=I</m>,
	  which shows that <m>A^{-1}=A^{99}B</m>.
	</p></li>
      </ol></p>
    </solution>
    <answer>
      <p><ol marker="a.">
	<li><p>
	  If <m>A^2</m> has inverse <m>B</m>, then <m>A^2B = I</m>.
	  This means that <m>A(AB)=I</m> so <m>A</m> is invertible
	  with inverse <m>AB</m>.
	</p></li>

	<li><p>
	  In the same way, we have <m>A^{100}B = A(A^{99}B)=I</m>,
	  which shows that <m>A^{-1}=A^{99}B</m>.
	</p></li>
      </ol></p>
    </answer>
  </exercise>

  <exercise>
    <statement>
      <p>
	Determine whether the following statements are true or false
	and explain your reasoning.
	<ol marker="a.">
	  <li><p> If <m>A</m> is invertible, then the columns of
	  <m>A</m> are linearly independent. </p></li>

	  <li><p> If <m>A</m> is a square matrix whose diagonal
	  entries are all nonzero, then <m>A</m> is
	  invertible.</p></li>

	  <li><p> If <m>A</m> is an invertible <m>n\times n</m>
	  matrix, then span of the columns of <m>A</m> is
	  <m>\real^n</m>. </p></li> 

	  <li><p> If <m>A</m> is invertible, then there is a
	  nonzero solution to the homogeneous equation <m>A\xvec =
	  \zerovec</m>. </p></li>

	  <li><p> If <m>A</m> is an <m>n\times n</m> matrix and the
	  equation <m>A\xvec = \bvec</m> has a solution for every
	  vector <m>\bvec</m>, then <m>A</m> is invertible. </p></li>
	</ol>
      </p>
    </statement>

    <solution>
      <p><ol marker="a.">
	<li><p>
	  True.  If <m>A</m> is invertible, then it has a pivot
	  position in every column, which implies that the columns are
	  linearly independent.
	</p></li>

	<li><p>
	  False.  We only know this if <m>A</m> is a triangular
	  matrix.  For instance, the matrix <m>\left[\begin{array}{rr}
	  1 \amp 1 \\
	  1 \amp 1 \\
	  \end{array}\right]</m> is not invertible.
	</p></li>

	<li><p>
	  True.  If <m>A</m> is invertible, then it has a pivot
	  position in every row, which implies that the columns 
	  span <m>\real^n</m>.
	</p></li>

	<li><p>
	  False. Since there is a pivot position in every column, the
	  homogeneous equation <m>A\xvec=\zerovec</m> has only the
	  zero solution <m>\xvec=\zerovec</m>.
	</p></li>

	<li><p>
	  True.  In this case, the columns of <m>A</m> span
	  <m>\real^n</m> so there must be a pivot position in every
	  row.  Because <m>A</m> is a square matrix, it must be row
	  equivalent to the identity matrix <m>I</m>.
	</p></li>

      </ol></p>
    </solution>

    <answer>
      <p><ol marker="a.">
	<li><p> True </p></li>
	<li><p> False </p></li>
	<li><p> True </p></li>
	<li><p> False</p></li>
	<li><p> True </p></li>
      </ol></p>
    </answer>
  </exercise>

  <exercise>
    <statement>
      <p> Provide a justification for your response to the following
      questions.
      <ol marker="a.">
	<li><p> Suppose that <m>A</m> is a square matrix with two
	identical columns.  Can <m>A</m> be invertible? </p></li>

	<li><p> Suppose that <m>A</m> is a square matrix with two
	identical rows.  Can <m>A</m> be invertible? </p></li>

	<li><p> Suppose that <m>A</m> is an invertible matrix and that
	<m>AB = AC</m>.  Can you conclude that <m>B = C</m>? </p></li>

	<li><p> Suppose that <m>A</m> is an invertible <m>n\times
	n</m> matrix.  What can you say about the span of the columns
	of <m>A^{-1}</m>? </p></li>

	<li><p> Suppose that <m>A</m> is an invertible matrix and that
	<m>B</m> is row equivalent to <m>A</m>. 
	Can you guarantee that <m>B</m> is invertible?
	</p></li> 
      </ol>
      </p>
    </statement>

    <solution>
      <p><ol marker="a.">
	<li><p>
	  No.  If <m>A</m> has two identical columns, then the columns
	  are not linearly independent.  This means there is a column
	  without a pivot position and so <m>A</m> is not row
	  equivalent to the identity matrix <m>I</m>.
	</p></li>

	<li><p>
	  No.  If we perform a replacement operation that multiplies
	  one of the equal rows by <m>-1</m> and adds it to the other
	  equal row, we obtain a matrix having a row whose entries are all
	  zero.  This says that the reduced row echelon form has such a
	  row as well.  Therefore, there is a row that does not
	  contain a pivot position so the reduced row echelon form cannot be
	  the identity <m>I</m>.
	</p></li>

	<li><p>
	  Yes.  If we multiply both sides of <m>AB=AC</m> by
	  <m>A^{-1}</m> on the left, then we see that <m>B=C</m>.
	</p></li>

	<li><p>
	  The inverse <m>A^{-1}</m> is also invertible since <m>A</m>
	  is its inverse.  Therefore, the span of the columns of
	  <m>A^{-1}</m> is <m>\real^n</m>.
	</p></li>

	<li><p>
	  Yes.  Since <m>A</m> is row equivalent to the identity
	  matrix <m>I</m>, the matrix <m>B</m> is as well.  Therefore,
	  <m>B</m> is invertible.
	</p></li>
      </ol></p>
    </solution>

    <answer>
      <p><ol marker="a.">
	<li><p> No </p></li>
	<li><p> No </p></li>
	<li><p> Yes </p></li>
	<li><p> The span is <m>\real^n</m>. </p></li>
	<li><p> Yes </p></li>
      </ol></p>
    </answer>
  </exercise>

  <exercise>
    <statement>
      <p>
	Suppose that we start with the <m>3\times3</m> matrix <m>A</m>,
	perform the following sequence of row operations:
	<ol marker="1.">
	  <li><p>  Multiply row 1 by -2 and add to row 2. </p></li>
	  <li><p>  Multiply row 1 by 4 and add to row 3. </p></li>
	  <li><p>  Scale row 2 by <m>1/2</m>. </p></li>
	  <li><p>  Multiply row 2 by -1 and add to row 3, </p></li>
	</ol>
	and arrive at the upper triangular matrix
	<me>
	  U = \left[\begin{array}{rrr}
	  3 \amp 2 \amp -1 \\
	  0 \amp 1 \amp 3 \\
	  0 \amp 0 \amp -4 \\
	  \end{array}\right].
	</me>
	<sage>
	  <input>
	  </input>
	</sage>
	<ol marker="a.">
	  <li><p> Write the matrices <m>E_1</m>, <m>E_2</m>,
	  <m>E_3</m>, and <m>E_4</m> that perform the four row
	  operations. </p></li>

	  <li><p> 
	  Find the
	  matrix <m>E = E_4E_3E_2E_1</m>. </p></li>

	  <li><p> We then have <m>E_4E_3E_2E_1 A = EA = U</m>.  Now
	  that we have the matrix <m>E</m>, find the original matrix
	  <m>A = E^{-1}U</m>.
	  </p></li>
	</ol>
      </p>
    </statement>

    <solution>
      <p><ol marker="a.">
	<li><p>
	  We have
	  <me>
	    \begin{array}{cc}
	    E_1=\left[\begin{array}{rrr}
	    1 \amp 0 \amp 0 \\
	    -2 \amp 1 \amp 0 \\
	    0 \amp 0 \amp 1
	    \end{array}\right],
	    \amp
	    E_2=\left[\begin{array}{rrr}
	    1 \amp 0 \amp 0 \\
	    0 \amp 1 \amp 0 \\
	    4 \amp 0 \amp 1
	    \end{array}\right], \\
	    E_3 = \left[\begin{array}{rrr}
	    1 \amp 0 \amp 0 \\
	    0 \amp \frac{1}{2} \amp 0 \\
	    0 \amp 0 \amp 1
	    \end{array}\right],
	    \amp
	    E_4 = 
	    \left[\begin{array}{rrr}
	    1 \amp 0 \amp 0 \\
	    0 \amp 1 \amp 0 \\
	    0 \amp -1 \amp 1
	    \end{array}\right]\text{.}
	    \end{array}
	  </me>
	</p></li>

	<li><p>
	  We have
	  <m> E = E_4E_3E_2E_1 = 
	  \left[\begin{array}{rrr}
	  1 \amp 0 \amp 0 \\
	  -1 \amp \frac{1}{2} \amp 0 \\
	  5 \amp -\frac12 \amp 1
	  \end{array}\right]
	  </m>.
	</p></li>

	<li><p>
	  We write <m>A=E^{-1}U=
	  \left[\begin{array}{rrr}
	  3 \amp 2 \amp -1 \\
	  6 \amp 6 \amp 4 \\
	  -12 \amp -7 \amp 3
	  \end{array}\right]
	  </m>.
	</p></li>
      </ol></p>
    </solution>
    
    <answer>
      <p><ol marker="a.">
	<li><p>
	  We have
	  <me>
	    \begin{array}{cc}
	    E_1=\left[\begin{array}{rrr}
	    1 \amp 0 \amp 0 \\
	    -2 \amp 1 \amp 0 \\
	    0 \amp 0 \amp 1
	    \end{array}\right],
	    \amp
	    E_2=\left[\begin{array}{rrr}
	    1 \amp 0 \amp 0 \\
	    0 \amp 1 \amp 0 \\
	    4 \amp 0 \amp 1
	    \end{array}\right], \\
	    E_3 = \left[\begin{array}{rrr}
	    1 \amp 0 \amp 0 \\
	    0 \amp \frac{1}{2} \amp 0 \\
	    0 \amp 0 \amp 1
	    \end{array}\right],
	    \amp
	    E_4 = 
	    \left[\begin{array}{rrr}
	    1 \amp 0 \amp 0 \\
	    0 \amp 1 \amp 0 \\
	    0 \amp -2 \amp 1
	    \end{array}\right]\text{.}
	    \end{array}
	  </me>
	</p></li>

	<li><p>
	  <m> E = 
	  \left[\begin{array}{rrr}
	  1 \amp 0 \amp 0 \\
	  -1 \amp \frac{1}{2} \amp 0 \\
	  6 \amp -1 \amp 1
	  \end{array}\right]
	  </m>.
	</p></li>

	<li><p>
	  <m>A=
	  \left[\begin{array}{rrr}
	  3 \amp 2 \amp -1 \\
	  6 \amp 6 \amp 4 \\
	  -12 \amp -6 \amp 6
	  \end{array}\right]
	  </m>.
	</p></li>
      </ol></p>
    </answer>
    
  </exercise>

  <exercise>
    <statement>
      <p>
	We say that two square matrices <m>A</m> and <m>B</m> are
	<em>similar</em> if there is an invertible matrix <m>P</m>
	such that <m>B = PAP^{-1}</m>.
	<ol marker="a.">
	  <li>
	    <p>
	      If <m>A</m> and <m>B</m> are similar, explain why
	      <m>A^2</m> and <m>B^2</m> are similar as well.  In
	      particular, if <m>B = PAP^{-1}</m>, explain why <m>B^2 =
	      PA^2P^{-1}</m>.
	    </p>
	  </li>
	  <li>
	    <p>
	      If <m>A</m> and <m>B</m> are similar and <m>A</m> is
	      invertible, explain why <m>B</m> is also invertible.
	    </p>
	  </li>
	  <li>
	    <p>
	      If <m>A</m> and <m>B</m> are similar and both are
	      invertible, explain why <m>A^{-1}</m> and <m>B^{-1}</m>
	      are similar.
	    </p>
	  </li>
	  <li>
	    <p>
	      If <m>A</m> is similar to <m>B</m> and <m>B</m> is
	      similar to <m>C</m>, explain why <m>A</m> is similar to
	      <m>C</m>.  To begin, you may wish to assume that <m>B =
	      PAP^{-1}</m> and <m>C = QBQ^{-1}</m>.
	    </p>
	  </li>
	</ol>
      </p>
    </statement>
    <solution>
      <p>
	<ol marker="a.">
	  <li>
	    <p>
	      <m>B^2 = (PAP^{-1})(PAP^{-1}) = PA^2P^{-1}</m>.
	    </p>
	  </li>
	  <li>
	    <p>
	      <m>B (PA^{-1}P^{-1}) = (PAP^{-1})(PA^{-1}P^{-1}) =
	      I</m>.
	    </p>
	  </li>
	  <li>
	    <p>
	      <m>B^{-1}=(PAP^{-1})^{-1} = PA^{-1}P^{-1}</m>.
	    </p>
	  </li>
	  <li>
	    <p>
	      <m>C = QBQ^{-1}=QPAP^{-1}Q^{-1} = (QP)A(QP)^{-1}</m>.
	    </p>
	  </li>
	</ol>
      </p>
    </solution>
	    
    <answer>
      <p>
	<ol marker="a.">
	  <li>
	    <p>
	      <m>B^2 = PA^2P^{-1}</m>.
	    </p>
	  </li>
	  <li>
	    <p>
	      <m>B^{-1} = PA^{-1}P^{-1}</m>.
	    </p>
	  </li>
	  <li>
	    <p>
	      <m>B^{-1}= PA^{-1}P^{-1}</m>.
	    </p>
	  </li>
	  <li>
	    <p>
	      <m>C = (QP)A(QP)^{-1}</m>.
	    </p>
	  </li>
	</ol>
      </p>
    </answer>
  </exercise>
	  
  <exercise>
    <statement>
      <p>
	Suppose that <m>A</m> and <m>B</m> are two <m>n\times n</m>
	matrices and that <m>AB</m> is invertible.  We would like to
	explain why both <m>A</m> and <m>B</m> are invertible.
	<ol marker="a.">
	  <li>
	    <p>
	      We first explain why <m>B</m> is invertible.
	      <ol marker="1.">
		<li>
		  <p>
		    Since <m>AB</m> is invertible, explain why any solution
		    to the homogeneous equation <m>AB\xvec = \zerovec</m> is
		    <m>\xvec=\zerovec</m>.
		  </p>
		</li>
		<li>
		  <p> Use this fact to explain why any solution to
		  <m>B\xvec = \zerovec</m> must be
		  <m>\xvec=\zerovec</m>.
		  </p>
		</li>
		<li>
		  <p>
		    Explain why <m>B</m> must be invertible.
		  </p>
		</li>
	      </ol>
	    </p>
	  </li>
	  <li>
	    <p>
	      Now we explain why <m>A</m> is invertible.
	      <ol marker="1.">
		<li>
		  <p>
		    Since <m>AB</m> is invertible, explain why the
		    equation <m>AB\xvec=\bvec</m> is consistent for
		    every vector <m>\bvec</m>.
		  </p>
		</li>
		<li>
		  <p>
		    Using the fact that <m>AB\xvec = A(B\xvec) =
		    \bvec</m> is consistent for every <m>\bvec</m>,
		    explain why every equation <m>A\xvec = \bvec</m>
		    is consistent.
		  </p>
		</li>
		<li>
		  <p>
		    Explain why <m>A</m> must be invertible.
		  </p>
		</li>
	      </ol>
	    </p>
	  </li>
	</ol>
      </p>
    </statement>
    <solution>
      <p>
	<ol marker="a.">
	  <li>
	    <p>
	      <ol marker="1.">
		<li>
		  <p> Since <m>AB</m> is invertible, <m>AB\sim I</m>,
		  which says that there is pivot position in every
		  column.  Therefore, <m>\xvec=\zerovec</m> is the
		  only solution to the equation <m>AB\xvec =
		  \zerovec</m>.
		  </p>
		</li>
		<li>
		  <p>
		    If <m>\xvec</m> is a solution to the equation
		    <m>B\xvec = \zerovec</m>, then 
		    <m>AB\xvec =
		    A\zerovec = \zerovec</m>, which says that <m>\xvec
		    = \zerovec</m>.
		  </p>
		</li>
		<li>
		  <p>
		    Since the only solution to the homogeneous
		    equation <m>B\xvec = \zerovec</m> is the zero
		    solution, we know that <m>B\sim I</m> so <m>B</m>
		    is invertible.
		  </p>
		</li>
	      </ol>
	    </p>
	  </li>
	  <li>
	    <p>
	      <ol marker="1.">
		<li>
		  <p>
		    Since <m>AB</m> is invertible, the span of the
		    columns of <m>AB</m> is <m>\real^n</m>, which says
		    that every equation <m>AB\xvec = \bvec</m> is
		    consistent.
		  </p>
		</li>
		<li>
		  <p>
		    If <m>\yvec</m> is the solution to the equation
		    <m>AB\xvec = \bvec</m>, then <m>B\yvec</m> satisfies
		    <m>A(B\yvec) = \bvec</m>, which means that
		    <m>A\xvec = \bvec</m> is consistent.
		  </p>
		</li>
		<li>
		  <p>
		    We now know that the span of the columns of
		    <m>A</m> is <m>\real^n</m>, which tells us that
		    <m>A</m> is invertible.
		  </p>
		</li>
	      </ol>
	    </p>
	  </li>
	</ol>
      </p>
    </solution>
		    
    <answer>
      <p>
	<ol marker="a.">
	  <li>
	    <p>
	      <ol marker="1.">
		<li>
		  <p>
		    <m>AB\sim I</m>.
		  </p>
		</li>
		<li>
		  <p>
		    If <m>B\xvec=\zerovec</m>, then <m>AB\xvec =
		    \zerovec</m>. 
		  </p>
		</li>
		<li>
		  <p>
		    We now know that <m>B\sim I</m>.
		  </p>
		</li>
	      </ol>
	    </p>
	  </li>
	  <li>
	    <p>
	      <ol marker="1.">
		<li>
		  <p>
		    The span of the
		    columns of <m>AB</m> is <m>\real^n</m>.
		  </p>
		</li>
		<li>
		  <p>
		    A solution to 
		    <m>AB\xvec = \bvec</m> produces a solution to
		    <m>A\xvec = \bvec</m>.
		  </p>
		</li>
		<li>
		  <p>
		    The span of the columns of
		    <m>A</m> is <m>\real^n</m>.
		  </p>
		</li>
	      </ol>
	    </p>
	  </li>
	</ol>
      </p>
    </answer>
  </exercise>

  <exercise xml:id="ex-right-inverse">
    <statement>
      <p> We defined an <m>n\times n</m> matrix to be invertible if
      there is a matrix <m>B</m> such that <m>AB=I_n</m>.  In this
      exercise, we will explain why it is also true that
      <m>BA = I</m>, which is the statement of
      <xref ref="proposition-inverse-inverse"/>.
      This means that, if <m>B=A^{-1}</m>, then
      <m>A = B^{-1}</m>.
      <ol marker="a.">
	<li><p> Suppose that <m>\xvec</m> is an <m>n</m>-dimensional
	vector.  Since <m>AB=I</m>, explain why <m>AB\xvec =
	\xvec</m> and use this to explain why the only vector for
	which <m>B\xvec = \zerovec</m> is <m>\xvec = \zerovec</m>.
	</p> </li>

	<li><p> Explain why this implies that <m>B</m> must be
	invertible.  We will call the inverse <m>C</m> so that <m>BC =
	I</m>.
	</p></li>

	<li><p> Beginning with <m>AB = I</m>, explain why
	<m>
	  B(AB)C = BIC
	</m>
	and why this tells us that <m>BA = I</m>.
	</p></li>
      </ol>
      </p>
    </statement>

    <solution>
      <p><ol marker="a.">
	<li><p>
	  If <m>B\xvec = \zerovec</m>,
	  then <m>AB\xvec = A\zerovec = \zerovec = \xvec</m>.
	</p></li>
	<li><p>
	  Since the only solution to the homogeneous equation
	  <m>B\xvec = \zerovec</m> is <m>\xvec=\zerovec</m>, we know that
	  the columns of <m>B</m> are linearly independent and so
	  <m>B</m> has a pivot position in every column.  Since
	  <m>B</m> is a square matrix, this tells us that <m>B\sim
	  I</m> so that <m>B</m> is invertible.
	</p></li>

	<li><p>
	  If we multiply <m>AB=I</m> on the left by <m>B</m> and the
	  right by <m>C</m>, then we have
	  <me>
	    \begin{aligned}
	    B(AB)C \amp = BIC \\
	    BA(BC) \amp = BC \\
	    BAI \amp = I \\
	    BA \amp = I
	    \end{aligned}.
	  </me>
	</p></li>
      </ol>
      </p>
    </solution>

    <answer>
      <p><ol marker="a.">
	<li><p>
	  If <m>B\xvec = \zerovec</m>, then <m>AB\xvec = \xvec =
	  \zerovec</m>. 
	</p></li>

	<li><p>
	  <m>B</m> is invertible because <m>B\sim I</m>.
	</p></li>

	<li><p> 
	  Multiply <m>AB=I</m> on the left by <m>B</m> and the right
	  by <m>C</m> and regroup the matrix multiplications.
	</p></li>

      </ol></p>
    </answer>
  </exercise>

</exercises>
