<!DOCTYPE html>
<!--********************************************-->
<!--*       Generated from PreTeXt source      *-->
<!--*                                          *-->
<!--*         https://pretextbook.org          *-->
<!--*                                          *-->
<!--********************************************-->
<html lang="en-US">
<head xmlns:og="http://ogp.me/ns#" xmlns:book="https://ogp.me/ns/book#">
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<title>Symmetric matrices and variance</title>
<meta name="Keywords" content="Authored in PreTeXt">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta property="og:type" content="book">
<meta property="book:title" content="Understanding Linear Algebra">
<meta property="book:author" content=" Randall Pruim ">
<script src="https://sagecell.sagemath.org/static/embedded_sagecell.js"></script><script>var runestoneMathReady = new Promise((resolve) => window.rsMathReady = resolve);
window.MathJax = {
  tex: {
    inlineMath: [['\\(','\\)']],
    tags: "none",
    tagSide: "right",
    tagIndent: ".8em",
    packages: {'[+]': ['base', 'extpfeil', 'ams', 'amscd', 'color', 'newcommand', 'knowl']}
  },
  options: {
    ignoreHtmlClass: "tex2jax_ignore|ignore-math",
    processHtmlClass: "process-math",
    renderActions: {
        findScript: [10, function (doc) {
            document.querySelectorAll('script[type^="math/tex"]').forEach(function(node) {
                var display = !!node.type.match(/; *mode=display/);
                var math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
                var text = document.createTextNode('');
                node.parentNode.replaceChild(text, node);
                math.start = {node: text, delim: '', n: 0};
                math.end = {node: text, delim: '', n: 0};
                doc.math.push(math);
            });
        }, '']
    },
  },
  chtml: {
    scale: 0.98,
    mtextInheritFont: true
  },
  loader: {
    load: ['input/asciimath', '[tex]/extpfeil', '[tex]/amscd', '[tex]/color', '[tex]/newcommand', '[pretext]/mathjaxknowl3.js'],
    paths: {pretext: "https://pretextbook.org/js/lib"},
  },
  startup: {
    pageReady() {
      return MathJax.startup.defaultPageReady().then(function () {
      console.log("in ready function");
      rsMathReady();
      }
    )}
  },
};
</script><script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"></script><script>// Make *any* pre with class 'sagecell-sage' an executable Sage cell
// Their results will be linked, only within language type
sagecell.makeSagecell({inputLocation: 'pre.sagecell-sage',
                       linked: true,
                       languages: ['sage'],
                       evalButtonText: 'Evaluate (Sage)'});
</script><script>// Make *any* pre with class 'sagecell-python' an executable Sage cell
// Their results will be linked, only within language type
sagecell.makeSagecell({inputLocation: 'pre.sagecell-python',
                       linked: true,
                       languages: ['python'],
                       evalButtonText: 'Evaluate (Python)'});
</script><script async="" src="https://cse.google.com/cse.js?cx=015103900096539427448:ngwuia10qci"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/lunr.js/2.3.9/lunr.min.js" integrity="sha512-4xUl/d6D6THrAnXAwGajXkoWaeMNwEKK4iNfq5DotEbLPAfk6FSxSP3ydNxqDgCw1c/0Z1Jg6L8h2j+++9BZmg==" crossorigin="anonymous" referrerpolicy="no-referrer"></script><script src="lunr-pretext-search-index.js" async=""></script><script src="https://pretextbook.org/js/0.2/pretext_search.js"></script><link href="https://pretextbook.org/css/0.6/pretext_search.css" rel="stylesheet" type="text/css">
<script>js_version = 0.2</script><script src="https://pretextbook.org/js/lib/jquery.min.js"></script><script src="https://pretextbook.org/js/lib/jquery.sticky.js"></script><script src="https://pretextbook.org/js/lib/jquery.espy.min.js"></script><script src="https://pretextbook.org/js/0.2/pretext.js"></script><script>miniversion=0.1</script><script src="https://pretextbook.org/js/0.2/pretext_add_on.js?x=1"></script><script src="https://pretextbook.org/js/0.2/user_preferences.js"></script><script src="https://pretextbook.org/js/lib/knowl.js"></script><!--knowl.js code controls Sage Cells within knowls--><script>sagecellEvalName='Evaluate (Sage)';
</script><link rel="preconnect" href="https://fonts.googleapis.com">
<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin="">
<link href="https://fonts.googleapis.com/css2?family=Inconsolata:wght@400;700&amp;family=Noto+Serif:ital,wght@0,400;0,700;1,400;1,700&amp;family=Tinos:ital,wght@0,400;0,700;1,400;1,700&amp;display=swap" rel="stylesheet">
<link href="https://fonts.cdnfonts.com/css/dejavu-serif" rel="stylesheet">
<link href="https://fonts.googleapis.com/css2?family=Roboto+Serif:opsz,wdth,wght@8..144,50..150,100..900&amp;display=swap" rel="stylesheet">
<link href="https://fonts.googleapis.com/css2?family=Open+Sans:wdth,wght@75..100,300..800&amp;display=swap" rel="stylesheet">
<link href="https://pretextbook.org/css/0.6/pretext.css" rel="stylesheet" type="text/css">
<link href="https://pretextbook.org/css/0.6/pretext_add_on.css" rel="stylesheet" type="text/css">
<link href="https://pretextbook.org/css/0.6/shell_default.css" rel="stylesheet" type="text/css">
<link href="https://pretextbook.org/css/0.6/banner_default.css" rel="stylesheet" type="text/css">
<link href="https://pretextbook.org/css/0.6/navbar_default.css" rel="stylesheet" type="text/css">
<link href="https://pretextbook.org/css/0.6/toc_default.css" rel="stylesheet" type="text/css">
<link href="https://pretextbook.org/css/0.6/knowls_default.css" rel="stylesheet" type="text/css">
<link href="https://pretextbook.org/css/0.6/style_default.css" rel="stylesheet" type="text/css">
<link href="https://pretextbook.org/css/0.6/colors_blue_grey.css" rel="stylesheet" type="text/css">
<link href="https://pretextbook.org/css/0.6/setcolors.css" rel="stylesheet" type="text/css">
<!--** eBookCongig is necessary to configure interactive       **-->
<!--** Runestone components to run locally in reader's browser **-->
<!--** No external communication:                              **-->
<!--**     log level is 0, Runestone Services are disabled     **-->
<script type="text/javascript">
eBookConfig = {};
eBookConfig.useRunestoneServices = false;
eBookConfig.host = 'http://127.0.0.1:8000';
eBookConfig.course = 'PTX_Course_Title_Here';
eBookConfig.basecourse = 'PTX_Base_Course';
eBookConfig.isLoggedIn = false;
eBookConfig.email = '';
eBookConfig.isInstructor = false;
eBookConfig.logLevel = 0;
eBookConfig.username = '';
eBookConfig.readings = null;
eBookConfig.activities = null;
eBookConfig.downloadsEnabled = false;
eBookConfig.allow_pairs = false;
eBookConfig.enableScratchAC = false;
eBookConfig.build_info = "";
eBookConfig.python3 = null;
eBookConfig.runestone_version = '7.0.7';
eBookConfig.jobehost = '';
eBookConfig.proxyuri_runs = '';
eBookConfig.proxyuri_files = '';
eBookConfig.enable_chatcodes =  false;
</script>
<!--*** Runestone Services ***-->
<script type="text/javascript" src="https://runestone.academy/cdn/runestone/7.0.7/prefix-runtime.fd9ce61c3c71cb22.bundle.js"></script><script type="text/javascript" src="https://runestone.academy/cdn/runestone/7.0.7/prefix-347.193e36c07abd0197.bundle.js"></script><script type="text/javascript" src="https://runestone.academy/cdn/runestone/7.0.7/prefix-runestone.89acb6c6122954e4.bundle.js"></script><link rel="stylesheet" type="text/css" href="https://runestone.academy/cdn/runestone/7.0.7/prefix-347.f9add1ca35d5ad93.css">
<link rel="stylesheet" type="text/css" href="https://runestone.academy/cdn/runestone/7.0.7/prefix-runestone.8d2f742bc74f4a41.css">
</head>
<body class="pretext book ignore-math">
<a class="assistive" href="#ptx-content">Skip to main content</a><header id="ptx-masthead"><div class="ptx-banner">
<a id="logo-link" href=""></a><div class="title-container">
<h1 class="heading"><a href="ula.html"><span class="title">Understanding Linear Algebra:</span> <span class="subtitle">Data Science Edition</span></a></h1>
<p class="byline">Randall Pruim</p>
</div>
<div id="searchresultsplaceholder" style="display: none">
<button id="closesearchresults" onclick="document.getElementById('searchresultsplaceholder').style.display = 'none'; return false;">x</button><h2>Search Results: <span id="searchterms"></span>
</h2>
<div id="searchempty"><span>No results.</span></div>
<ol id="searchresults"></ol>
</div>
</div></header><nav id="ptx-navbar" class="navbar"><button class="toc-toggle button" aria-label="Show or hide table of contents"><span class="icon">‚ò∞</span><span class="name">Contents</span></button><a class="index-button button" href="index-1.html" title="Index"><span class="name">Index</span></a><button id="user-preferences-button" class="user-preferences-button button" title="Modify user preferences"><span id="theavatarbutton" class="name">You!</span><div id="preferences_menu_holder" class="hidden"><ol id="preferences_menu" style="font-family: 'Roboto Serif', serif;">
<li data-env="avatar" tabindex="-1">Choose avatar<div class="wrap_to_submenu"><span class="to_submenu">‚ñª</span></div>
<ol class="hidden avatar">
<li data-val="You!" tabindex="-1">
<span id="theYou!" class="avatarcheck">‚úîÔ∏è</span>You!</li>
<li data-val="üò∫" tabindex="-1">
<span id="theüò∫" class="avatarcheck"></span>üò∫</li>
<li data-val="üë§" tabindex="-1">
<span id="theüë§" class="avatarcheck"></span>üë§</li>
<li data-val="üëΩ" tabindex="-1">
<span id="theüëΩ" class="avatarcheck"></span>üëΩ</li>
<li data-val="üê∂" tabindex="-1">
<span id="theüê∂" class="avatarcheck"></span>üê∂</li>
<li data-val="üêº" tabindex="-1">
<span id="theüêº" class="avatarcheck"></span>üêº</li>
<li data-val="üåà" tabindex="-1">
<span id="theüåà" class="avatarcheck"></span>üåà</li>
</ol>
</li>
<li data-env="fontfamily" tabindex="-1">Font family<div class="wrap_to_submenu"><span class="to_submenu">‚ñª</span></div>
<ol class="hidden fontfamily">
<li data-val="face" data-change="OS" tabindex="-1" style="font-family: 'Open Sans'">
<span id="theOS" class="ffcheck">‚úîÔ∏è</span><span class="name">Open Sans</span><span class="sample">AaBbCc 123 PreTeXt</span>
</li>
<li data-val="face" data-change="RS" tabindex="-1" style="font-family: 'Roboto Serif'">
<span id="theRS" class="ffcheck"></span><span class="name">Roboto Serif</span><span class="sample">AaBbCc 123 PreTeXt</span>
</li>
</ol>
</li>
<li data-env="font" tabindex="-1">Adjust font<div class="wrap_to_submenu"><span class="to_submenu">‚ñª</span></div>
<ol class="hidden fonts">
<li>Size</li>
<li><span id="thesize">12</span></li>
<li data-val="size" data-change="-1" tabindex="-1" style="font-size: 80%">Smaller</li>
<li data-val="size" data-change="1" tabindex="-1" style="font-size: 110%">Larger</li>
<li>Width</li>
<li><span id="thewdth">100</span></li>
<li data-val="wdth" data-change="-5" tabindex="-1" style="font-variation-settings: 'wdth' 60">narrower</li>
<li data-val="wdth" data-change="5" tabindex="-1" style="font-variation-settings: 'wdth' 150">wider</li>
<li>Weight</li>
<li><span id="thewght">400</span></li>
<li data-val="wght" data-change="-50" tabindex="-1" style="font-weight: 200">thinner</li>
<li data-val="wght" data-change="50" tabindex="-1" style="font-weight: 700">heavier</li>
<li>Letter spacing</li>
<li>
<span id="thelspace">0</span><span class="byunits">/200</span>
</li>
<li data-val="lspace" data-change="-1" tabindex="-1">closer</li>
<li data-val="lspace" data-change="1" tabindex="-1">f a r t h e r</li>
<li>Word spacing</li>
<li>
<span id="thewspace">0</span><span class="byunits">/50</span>
</li>
<li data-val="wspace" data-change="-1" tabindex="-1">smaller‚ÄÖgap‚ÄÉ</li>
<li data-val="wspace" data-change="1" tabindex="-1">larger‚ÄÉgap</li>
<li>Line Spacing</li>
<li>
<span id="theheight">135</span><span class="byunits">/100</span>
</li>
<li data-val="height" data-change="-5" tabindex="-1" style="line-height: 1">closer<br>together</li>
<li data-val="height" data-change="5" tabindex="-1" style="line-height: 1.75">further<br>apart</li>
</ol>
</li>
<li data-env="atmosphere" tabindex="-1">Light/dark mode<div class="wrap_to_submenu"><span class="to_submenu">‚ñª</span></div>
<ol class="hidden atmosphere">
<li data-val="default" tabindex="-1">
<span id="thedefault" class="atmospherecheck">‚úîÔ∏è</span>default</li>
<li data-val="pastel" tabindex="-1">
<span id="thepastel" class="atmospherecheck"></span>pastel</li>
<li data-val="darktwilight" tabindex="-1">
<span id="thedarktwilight" class="atmospherecheck"></span>twilight</li>
<li data-val="dark" tabindex="-1">
<span id="thedark" class="atmospherecheck"></span>dark</li>
<li data-val="darkmidnight" tabindex="-1">
<span id="thedarkmidnight" class="atmospherecheck"></span>midnight</li>
</ol>
</li>
<li data-env="ruler" tabindex="-1">Reading ruler<div class="wrap_to_submenu"><span class="to_submenu">‚ñª</span></div>
<ol class="hidden ruler">
<li data-val="none" tabindex="-1">
<span id="thenone" class="rulercheck">‚úîÔ∏è</span>none</li>
<li data-val="underline" tabindex="-1">
<span id="theunderline" class="rulercheck"></span>underline</li>
<li data-val="lunderline" tabindex="-1">
<span id="thelunderline" class="rulercheck"></span>L-underline</li>
<li data-val="greybar" tabindex="-1">
<span id="thegreybar" class="rulercheck"></span>grey bar</li>
<li data-val="lightbox" tabindex="-1">
<span id="thelightbox" class="rulercheck"></span>light box</li>
<li data-val="sunrise" tabindex="-1">
<span id="thesunrise" class="rulercheck"></span>sunrise</li>
<li data-val="sunriseunderline" tabindex="-1">
<span id="thesunriseunderline" class="rulercheck"></span>sunrise underline</li>
<li class="moveQ">Motion by:</li>
<li data-val="mouse" tabindex="-1">
<span id="themouse" class="motioncheck">‚úîÔ∏è</span>follow the mouse</li>
<li data-val="arrow" tabindex="-1">
<span id="thearrow" class="motioncheck"></span>up/down arrows - not yet</li>
<li data-val="eye" tabindex="-1">
<span id="theeye" class="motioncheck"></span>eye tracking - not yet</li>
</ol>
</li>
</ol></div></button><span class="treebuttons"><a class="previous-button button" href="chap7.html" title="Previous"><span class="icon">&lt;</span><span class="name">Prev</span></a><a class="up-button button" href="chap7.html" title="Up"><span class="icon">^</span><span class="name">Up</span></a><a class="next-button button" href="sec-quadratic-forms.html" title="Next"><span class="name">Next</span><span class="icon">&gt;</span></a></span><div class="searchwrapper" role="search"><div class="gcse-search"></div></div>
<div class="searchbox"><div class="searchwidget">
<input id="ptxsearch" type="text" name="terms" placeholder="Search" onchange="doSearch()"><button id="searchbutton" type="button" onclick="doSearch()">üîç</button>
</div></div></nav><div id="latex-macros" class="hidden-content process-math" style="display:none"><span class="process-math">\(\newcommand{\avec}{{\boldsymbol a}}
\newcommand{\bvec}{{\boldsymbol b}}
\newcommand{\cvec}{{\boldsymbol c}}
\newcommand{\dvec}{{\boldsymbol d}}
\newcommand{\dtil}{\widetilde{\boldsymbol d}}
\newcommand{\evec}{{\boldsymbol e}}
\newcommand{\fvec}{{\boldsymbol f}}
\newcommand{\mvec}{{\boldsymbol m}}
\newcommand{\nvec}{{\boldsymbol n}}
\newcommand{\pvec}{{\boldsymbol p}}
\newcommand{\qvec}{{\boldsymbol q}}
\newcommand{\rvec}{{\boldsymbol r}}
\newcommand{\svec}{{\boldsymbol s}}
\newcommand{\tvec}{{\boldsymbol t}}
\newcommand{\uvec}{{\boldsymbol u}}
\newcommand{\vvec}{{\boldsymbol v}}
\newcommand{\wvec}{{\boldsymbol w}}
\newcommand{\xvec}{{\boldsymbol x}}
\newcommand{\yvec}{{\boldsymbol y}}
\newcommand{\zvec}{{\boldsymbol z}}
\newcommand{\E}{\operatorname{E}}
\newcommand{\zerovec}{{\boldsymbol 0}}
\newcommand{\onevec}{{\boldsymbol 1}}
\newcommand{\real}{{\mathbb R}}
\newcommand{\twovec}[2]{\left[\begin{array}{r}#1 \\ #2
\end{array}\right]}
\newcommand{\ctwovec}[2]{\left[\begin{array}{c}#1 \\ #2
\end{array}\right]}
\newcommand{\threevec}[3]{\left[\begin{array}{r}#1 \\ #2 \\ #3
\end{array}\right]}
\newcommand{\cthreevec}[3]{\left[\begin{array}{c}#1 \\ #2 \\ #3
\end{array}\right]}
\newcommand{\fourvec}[4]{\left[\begin{array}{r}#1 \\ #2 \\ #3 \\ #4
\end{array}\right]}
\newcommand{\cfourvec}[4]{\left[\begin{array}{c}#1 \\ #2 \\ #3 \\ #4
\end{array}\right]}
\newcommand{\fivevec}[5]{\left[\begin{array}{r}#1 \\ #2 \\ #3 \\
#4 \\ #5 \\ \end{array}\right]}
\newcommand{\cfivevec}[5]{\left[\begin{array}{c}#1 \\ #2 \\ #3 \\
#4 \\ #5 \\ \end{array}\right]}
\newcommand{\mattwo}[4]{\left[\begin{array}{rr}#1 \amp #2 \\ #3 \amp #4 \\ \end{array}\right]}
\newcommand{\laspan}[1]{\text{Span}\{#1\}}
\newcommand{\bcal}{{\cal B}}
\newcommand{\ccal}{{\cal C}}
\newcommand{\scal}{{\cal S}}
\newcommand{\wcal}{{\cal W}}
\newcommand{\ecal}{{\cal E}}
\newcommand{\coords}[2]{\left\{#1\right\}_{#2}}
\newcommand{\gray}[1]{\color{gray}{#1}}
\newcommand{\lgray}[1]{\color{lightgray}{#1}}
\newcommand{\rank}{\operatorname{rank}}
\newcommand{\row}{\text{Row}}
\newcommand{\col}{\text{Col}}
\renewcommand{\row}{\text{Row}}
\newcommand{\nul}{\text{Nul}}
\newcommand{\var}{\text{Var}}
\newcommand{\corr}{\text{corr}}
\newcommand{\len}[1]{\left|#1\right|}
\newcommand{\bbar}{\overline{\bvec}}
\newcommand{\bhat}{\widehat{\bvec}}
\newcommand{\bperp}{\bvec^\perp}
\newcommand{\vhat}{\widehat{\vvec}}
\newcommand{\uhat}{\widehat{\uvec}}
\newcommand{\what}{\widehat{\wvec}}
\newcommand{\xhat}{\widehat{\xvec}}
\newcommand{\yhat}{\widehat{\yvec}}
\newcommand{\Sighat}{\widehat{\Sigma}}
\newcommand{\by}{\times}
\newcommand{proj}[2]{\operatorname{proj}\left(#1 \to #2\right)}
\newcommand{projsub}[2]{\operatorname{proj}_{#2}(#1)}
\newcommand{\lt}{&lt;}
\newcommand{\gt}{&gt;}
\newcommand{\amp}{&amp;}
\definecolor{fillinmathshade}{gray}{0.9}
\newcommand{\fillinmath}[1]{\mathchoice{\colorbox{fillinmathshade}{$\displaystyle     \phantom{\,#1\,}$}}{\colorbox{fillinmathshade}{$\textstyle        \phantom{\,#1\,}$}}{\colorbox{fillinmathshade}{$\scriptstyle      \phantom{\,#1\,}$}}{\colorbox{fillinmathshade}{$\scriptscriptstyle\phantom{\,#1\,}$}}}
\)</span></div>
<div class="ptx-page">
<div id="ptx-sidebar"><nav id="ptx-toc" class="depth2"><ul class="structural">
<li>
<div class="toc-item"><a href="frontmatter.html" class="internal"><span class="title">Front Matter</span></a></div>
<ul class="structural">
<li><div class="toc-item"><a href="colophon-1.html" class="internal"><span class="title">Colophon</span></a></div></li>
<li><div class="toc-item"><a href="preface-1.html" class="internal"><span class="title">Our goals</span></a></div></li>
</ul>
</li>
<li>
<div class="toc-item"><a href="chap1.html" class="internal"><span class="codenumber">1</span> <span class="title">Scalars, Vectors and Matrices</span></a></div>
<ul class="structural">
<li>
<div class="toc-item"><a href="sec-vectors.html" class="internal"><span class="codenumber">1.1</span> <span class="title">Vectors</span></a></div>
<ul class="structural">
<li><div class="toc-item"><a href="sec-vectors.html#subsection-1" class="internal"><span class="codenumber">1.1.1</span> <span class="title">Three ways to think about vectors</span></a></div></li>
<li>
<div class="toc-item"><a href="sec-vectors.html#subsection-2" class="internal"><span class="codenumber">1.1.2</span> <span class="title">Vector operations: scalar multiplication and vector addition.</span></a></div>
<ul class="structural">
<li><div class="toc-item"><a href="sec-vectors.html#subsubsec-scalar-multiplication" class="internal"><span class="codenumber">1.1.2.1</span> <span class="title">Scalar Multiplication</span></a></div></li>
<li><div class="toc-item"><a href="sec-vectors.html#subsubsec-vector-addition" class="internal"><span class="codenumber">1.1.2.2</span> <span class="title">Vector addition</span></a></div></li>
<li><div class="toc-item"><a href="sec-vectors.html#subsubsec-vector-properties" class="internal"><span class="codenumber">1.1.2.3</span> <span class="title">Mathematical properties of vector operations</span></a></div></li>
<li><div class="toc-item"><a href="sec-vectors.html#subsubsection-4" class="internal"><span class="codenumber">1.1.2.4</span> <span class="title">Summary</span></a></div></li>
</ul>
</li>
</ul>
</li>
<li>
<div class="toc-item"><a href="sec-vectors-in-python.html" class="internal"><span class="codenumber">1.2</span> <span class="title">Vectors in Python</span></a></div>
<ul class="structural">
<li><div class="toc-item"><a href="sec-vectors-in-python.html#subsec-intro-to-python" class="internal"><span class="codenumber">1.2.1</span> <span class="title">Introduction to Python</span></a></div></li>
<li><div class="toc-item"><a href="sec-vectors-in-python.html#subsec-numpy-vectors" class="internal"><span class="codenumber">1.2.2</span> <span class="title"><code class="code-inline tex2jax_ignore">numpy</code> vectors</span></a></div></li>
</ul>
</li>
<li>
<div class="toc-item"><a href="sec-linear-combos-of-vectors.html" class="internal"><span class="codenumber">1.3</span> <span class="title">Linear combinations of vectors</span></a></div>
<ul class="structural">
<li><div class="toc-item"><a href="sec-linear-combos-of-vectors.html#subsection-5" class="internal"><span class="codenumber">1.3.1</span> <span class="title">Summary</span></a></div></li>
<li><div class="toc-item"><a href="sec-linear-combos-of-vectors.html#exercises-1" class="internal"><span class="codenumber">1.3.2</span> <span class="title">Exercises</span></a></div></li>
</ul>
</li>
<li>
<div class="toc-item"><a href="sec-matrices.html" class="internal"><span class="codenumber">1.4</span> <span class="title">Matrices</span></a></div>
<ul class="structural">
<li><div class="toc-item"><a href="sec-matrices.html#subsec-matrices-and-their-uses" class="internal"><span class="codenumber">1.4.1</span> <span class="title">Matrices and their uses</span></a></div></li>
<li><div class="toc-item"><a href="sec-matrices.html#subsection-7" class="internal"><span class="codenumber">1.4.2</span> <span class="title">Scalar multiplication and addition of matrices</span></a></div></li>
<li><div class="toc-item"><a href="sec-matrices.html#subsection-8" class="internal"><span class="codenumber">1.4.3</span> <span class="title">Matrix-vector multiplication and linear combinations</span></a></div></li>
<li><div class="toc-item"><a href="sec-matrices.html#subsection-9" class="internal"><span class="codenumber">1.4.4</span> <span class="title">Matrix-vector multiplication and linear systems</span></a></div></li>
<li><div class="toc-item"><a href="sec-matrices.html#sec-matrices-in-python" class="internal"><span class="codenumber">1.4.5</span> <span class="title">Matrices in Python</span></a></div></li>
<li><div class="toc-item"><a href="sec-matrices.html#subsection-11" class="internal"><span class="codenumber">1.4.6</span> <span class="title">Matrix-matrix products</span></a></div></li>
<li><div class="toc-item"><a href="sec-matrices.html#subsec-special-matrices" class="internal"><span class="codenumber">1.4.7</span> <span class="title">Some special types of matrices</span></a></div></li>
<li><div class="toc-item"><a href="sec-matrices.html#subsection-13" class="internal"><span class="codenumber">1.4.8</span> <span class="title">Summary</span></a></div></li>
<li><div class="toc-item"><a href="sec-matrices.html#exercises-2" class="internal"><span class="codenumber">1.4.9</span> <span class="title">Exercises</span></a></div></li>
</ul>
</li>
<li>
<div class="toc-item"><a href="sec-tensors.html" class="internal"><span class="codenumber">1.5</span> <span class="title">Tensors</span></a></div>
<ul class="structural">
<li><div class="toc-item"><a href="sec-tensors.html#subsec-numpy-tensors" class="internal"><span class="codenumber">1.5.1</span> <span class="title">Tensors in Numpy</span></a></div></li>
<li><div class="toc-item"><a href="sec-tensors.html#subsec-axes" class="internal"><span class="codenumber">1.5.2</span> <span class="title">Aggregation and Axes</span></a></div></li>
<li><div class="toc-item"><a href="sec-tensors.html#subsec-ndarray-append" class="internal"><span class="codenumber">1.5.3</span> <span class="title">Expanding an array</span></a></div></li>
<li><div class="toc-item"><a href="sec-tensors.html#subsec-broadcasting" class="internal"><span class="codenumber">1.5.4</span> <span class="title">Broadcasting</span></a></div></li>
</ul>
</li>
</ul>
</li>
<li>
<div class="toc-item"><a href="chap2.html" class="internal"><span class="codenumber">2</span> <span class="title">Systems of equations: Solving <span class="process-math">\(A \xvec = \bvec\)</span></span></a></div>
<ul class="structural">
<li>
<div class="toc-item"><a href="sec-expect.html" class="internal"><span class="codenumber">2.1</span> <span class="title">What can we expect</span></a></div>
<ul class="structural">
<li><div class="toc-item"><a href="sec-expect.html#subsection-18" class="internal"><span class="codenumber">2.1.1</span> <span class="title">Some simple examples</span></a></div></li>
<li><div class="toc-item"><a href="sec-expect.html#subsection-19" class="internal"><span class="codenumber">2.1.2</span> <span class="title">Systems of linear equations</span></a></div></li>
<li><div class="toc-item"><a href="sec-expect.html#subsection-20" class="internal"><span class="codenumber">2.1.3</span> <span class="title">Summary</span></a></div></li>
<li><div class="toc-item"><a href="sec-expect.html#exercises-3" class="internal"><span class="codenumber">2.1.4</span> <span class="title">Exercises</span></a></div></li>
</ul>
</li>
<li>
<div class="toc-item"><a href="sec-finding-solutions.html" class="internal"><span class="codenumber">2.2</span> <span class="title">Finding solutions to linear systems</span></a></div>
<ul class="structural">
<li><div class="toc-item"><a href="sec-finding-solutions.html#subsection-21" class="internal"><span class="codenumber">2.2.1</span> <span class="title">Gaussian elimination</span></a></div></li>
<li><div class="toc-item"><a href="sec-finding-solutions.html#subsection-22" class="internal"><span class="codenumber">2.2.2</span> <span class="title">Augmented matrices</span></a></div></li>
<li><div class="toc-item"><a href="sec-finding-solutions.html#subsection-23" class="internal"><span class="codenumber">2.2.3</span> <span class="title">Reduced row echelon form</span></a></div></li>
<li><div class="toc-item"><a href="sec-finding-solutions.html#subsec-solving-matrix-equations" class="internal"><span class="codenumber">2.2.4</span> <span class="title">Solving matrix equations</span></a></div></li>
<li><div class="toc-item"><a href="sec-finding-solutions.html#subsection-25" class="internal"><span class="codenumber">2.2.5</span> <span class="title">Summary</span></a></div></li>
<li><div class="toc-item"><a href="sec-finding-solutions.html#exercises-4" class="internal"><span class="codenumber">2.2.6</span> <span class="title">Exercises</span></a></div></li>
</ul>
</li>
<li>
<div class="toc-item"><a href="sec-python-introduction.html" class="internal"><span class="codenumber">2.3</span> <span class="title">Computational Linear Algebra</span></a></div>
<ul class="structural">
<li><div class="toc-item"><a href="sec-python-introduction.html#subsection-26" class="internal"><span class="codenumber">2.3.1</span> <span class="title">Reduced row echelon form in Python</span></a></div></li>
<li><div class="toc-item"><a href="sec-python-introduction.html#subsec-linalg-solve" class="internal"><span class="codenumber">2.3.2</span> <span class="title">np.linalg.solve()</span></a></div></li>
<li><div class="toc-item"><a href="sec-python-introduction.html#subsec-compute-effort" class="internal"><span class="codenumber">2.3.3</span> <span class="title">Computational effort</span></a></div></li>
<li><div class="toc-item"><a href="sec-python-introduction.html#subsection-29" class="internal"><span class="codenumber">2.3.4</span> <span class="title">Summary</span></a></div></li>
<li><div class="toc-item"><a href="sec-python-introduction.html#exercises-5" class="internal"><span class="codenumber">2.3.5</span> <span class="title">Exercises</span></a></div></li>
<li><div class="toc-item"><a href="sec-python-introduction.html#exercises-6" class="internal"><span class="codenumber">2.3.6</span> <span class="title">Exercises</span></a></div></li>
</ul>
</li>
<li>
<div class="toc-item"><a href="sec-pivots.html" class="internal"><span class="codenumber">2.4</span> <span class="title">Pivots and their relationship to solution spaces</span></a></div>
<ul class="structural">
<li><div class="toc-item"><a href="sec-pivots.html#subsection-30" class="internal"><span class="codenumber">2.4.1</span> <span class="title">The existence of solutions</span></a></div></li>
<li><div class="toc-item"><a href="sec-pivots.html#subsection-31" class="internal"><span class="codenumber">2.4.2</span> <span class="title">The uniqueness of solutions</span></a></div></li>
<li><div class="toc-item"><a href="sec-pivots.html#subsection-32" class="internal"><span class="codenumber">2.4.3</span> <span class="title">Summary</span></a></div></li>
<li><div class="toc-item"><a href="sec-pivots.html#exercises-7" class="internal"><span class="codenumber">2.4.4</span> <span class="title">Exercises</span></a></div></li>
</ul>
</li>
</ul>
</li>
<li>
<div class="toc-item"><a href="chap3.html" class="internal"><span class="codenumber">3</span> <span class="title">Linear combinations and transformations</span></a></div>
<ul class="structural">
<li>
<div class="toc-item"><a href="sec-span.html" class="internal"><span class="codenumber">3.1</span> <span class="title">The span of a set of vectors</span></a></div>
<ul class="structural">
<li><div class="toc-item"><a href="sec-span.html#subsection-33" class="internal"><span class="codenumber">3.1.1</span> <span class="title">The span of a set of vectors</span></a></div></li>
<li><div class="toc-item"><a href="sec-span.html#subsection-34" class="internal"><span class="codenumber">3.1.2</span> <span class="title">Pivot positions and span</span></a></div></li>
<li><div class="toc-item"><a href="sec-span.html#subsection-35" class="internal"><span class="codenumber">3.1.3</span> <span class="title">Summary</span></a></div></li>
<li><div class="toc-item"><a href="sec-span.html#exercises-8" class="internal"><span class="codenumber">3.1.4</span> <span class="title">Exercises</span></a></div></li>
</ul>
</li>
<li>
<div class="toc-item"><a href="sec-linear-dep.html" class="internal"><span class="codenumber">3.2</span> <span class="title">Linear independence</span></a></div>
<ul class="structural">
<li><div class="toc-item"><a href="sec-linear-dep.html#subsection-36" class="internal"><span class="codenumber">3.2.1</span> <span class="title">Linear dependence</span></a></div></li>
<li><div class="toc-item"><a href="sec-linear-dep.html#subsection-37" class="internal"><span class="codenumber">3.2.2</span> <span class="title">How to recognize linear dependence</span></a></div></li>
<li><div class="toc-item"><a href="sec-linear-dep.html#subsection-38" class="internal"><span class="codenumber">3.2.3</span> <span class="title">Homogeneous equations</span></a></div></li>
<li><div class="toc-item"><a href="sec-linear-dep.html#subsection-39" class="internal"><span class="codenumber">3.2.4</span> <span class="title">Summary</span></a></div></li>
<li><div class="toc-item"><a href="sec-linear-dep.html#exercises-9" class="internal"><span class="codenumber">3.2.5</span> <span class="title">Exercises</span></a></div></li>
</ul>
</li>
<li>
<div class="toc-item"><a href="sec-linear-trans.html" class="internal"><span class="codenumber">3.3</span> <span class="title">Matrix transformations</span></a></div>
<ul class="structural">
<li><div class="toc-item"><a href="sec-linear-trans.html#subsection-40" class="internal"><span class="codenumber">3.3.1</span> <span class="title">Matrix transformations</span></a></div></li>
<li><div class="toc-item"><a href="sec-linear-trans.html#subsection-41" class="internal"><span class="codenumber">3.3.2</span> <span class="title">Composing matrix transformations</span></a></div></li>
<li><div class="toc-item"><a href="sec-linear-trans.html#subsec-dynamical-systems" class="internal"><span class="codenumber">3.3.3</span> <span class="title">Discrete Dynamical Systems</span></a></div></li>
<li><div class="toc-item"><a href="sec-linear-trans.html#subsection-43" class="internal"><span class="codenumber">3.3.4</span> <span class="title">Summary</span></a></div></li>
<li><div class="toc-item"><a href="sec-linear-trans.html#exercises-10" class="internal"><span class="codenumber">3.3.5</span> <span class="title">Exercises</span></a></div></li>
</ul>
</li>
<li>
<div class="toc-item"><a href="sec-transforms-geom.html" class="internal"><span class="codenumber">3.4</span> <span class="title">The geometry of matrix transformations</span></a></div>
<ul class="structural">
<li><div class="toc-item"><a href="sec-transforms-geom.html#subsection-44" class="internal"><span class="codenumber">3.4.1</span> <span class="title">The geometry of <span class="process-math">\(2\by2\)</span> matrix transformations</span></a></div></li>
<li><div class="toc-item"><a href="sec-transforms-geom.html#subsection-45" class="internal"><span class="codenumber">3.4.2</span> <span class="title">Matrix transformations and computer animation</span></a></div></li>
<li><div class="toc-item"><a href="sec-transforms-geom.html#subsection-46" class="internal"><span class="codenumber">3.4.3</span> <span class="title">Summary</span></a></div></li>
<li><div class="toc-item"><a href="sec-transforms-geom.html#exercises-11" class="internal"><span class="codenumber">3.4.4</span> <span class="title">Exercises</span></a></div></li>
</ul>
</li>
</ul>
</li>
<li>
<div class="toc-item"><a href="chap4.html" class="internal"><span class="codenumber">4</span> <span class="title">Invertibility, bases, and coordinate systems</span></a></div>
<ul class="structural">
<li>
<div class="toc-item"><a href="sec-matrix-inverse.html" class="internal"><span class="codenumber">4.1</span> <span class="title">Invertibility</span></a></div>
<ul class="structural">
<li><div class="toc-item"><a href="sec-matrix-inverse.html#subsection-47" class="internal"><span class="codenumber">4.1.1</span> <span class="title">Invertible matrices</span></a></div></li>
<li><div class="toc-item"><a href="sec-matrix-inverse.html#subsection-48" class="internal"><span class="codenumber">4.1.2</span> <span class="title">Solving equations with an inverse</span></a></div></li>
<li><div class="toc-item"><a href="sec-matrix-inverse.html#subsection-49" class="internal"><span class="codenumber">4.1.3</span> <span class="title">Summary</span></a></div></li>
<li><div class="toc-item"><a href="sec-matrix-inverse.html#exercises-12" class="internal"><span class="codenumber">4.1.4</span> <span class="title">Exercises</span></a></div></li>
</ul>
</li>
<li>
<div class="toc-item"><a href="subsec-triangular-invertible.html" class="internal"><span class="codenumber">4.2</span> <span class="title">Triangular matrices and Gaussian elimination</span></a></div>
<ul class="structural">
<li><div class="toc-item"><a href="subsec-triangular-invertible.html#subsec-triangular-matrices" class="internal"><span class="codenumber">4.2.1</span> <span class="title">Triangular matrices</span></a></div></li>
<li><div class="toc-item"><a href="subsec-triangular-invertible.html#subsec-elementary-matrices" class="internal"><span class="codenumber">4.2.2</span> <span class="title">Elementary matrices</span></a></div></li>
<li><div class="toc-item"><a href="subsec-triangular-invertible.html#subsection-52" class="internal"><span class="codenumber">4.2.3</span> <span class="title">Summary</span></a></div></li>
<li><div class="toc-item"><a href="subsec-triangular-invertible.html#exercises-13" class="internal"><span class="codenumber">4.2.4</span> <span class="title">Exercises</span></a></div></li>
</ul>
</li>
<li>
<div class="toc-item"><a href="sec-bases.html" class="internal"><span class="codenumber">4.3</span> <span class="title">Bases and coordinate systems</span></a></div>
<ul class="structural">
<li><div class="toc-item"><a href="sec-bases.html#subsection-53" class="internal"><span class="codenumber">4.3.1</span> <span class="title">Bases</span></a></div></li>
<li><div class="toc-item"><a href="sec-bases.html#subsection-54" class="internal"><span class="codenumber">4.3.2</span> <span class="title">Coordinate systems</span></a></div></li>
<li><div class="toc-item"><a href="sec-bases.html#subsection-55" class="internal"><span class="codenumber">4.3.3</span> <span class="title">Examples of bases</span></a></div></li>
<li><div class="toc-item"><a href="sec-bases.html#subsection-56" class="internal"><span class="codenumber">4.3.4</span> <span class="title">Summary</span></a></div></li>
<li><div class="toc-item"><a href="sec-bases.html#exercises-14" class="internal"><span class="codenumber">4.3.5</span> <span class="title">Exercises</span></a></div></li>
</ul>
</li>
<li>
<div class="toc-item"><a href="sec-jpeg.html" class="internal"><span class="codenumber">4.4</span> <span class="title">Image compression</span></a></div>
<ul class="structural">
<li><div class="toc-item"><a href="sec-jpeg.html#subsection-57" class="internal"><span class="codenumber">4.4.1</span> <span class="title">Color models</span></a></div></li>
<li><div class="toc-item"><a href="sec-jpeg.html#subsection-58" class="internal"><span class="codenumber">4.4.2</span> <span class="title">The JPEG compression algorithm</span></a></div></li>
<li><div class="toc-item"><a href="sec-jpeg.html#subsection-59" class="internal"><span class="codenumber">4.4.3</span> <span class="title">Summary</span></a></div></li>
<li><div class="toc-item"><a href="sec-jpeg.html#exercises-15" class="internal"><span class="codenumber">4.4.4</span> <span class="title">Exercises</span></a></div></li>
</ul>
</li>
<li>
<div class="toc-item"><a href="sec-determinants.html" class="internal"><span class="codenumber">4.5</span> <span class="title">Determinants</span></a></div>
<ul class="structural">
<li><div class="toc-item"><a href="sec-determinants.html#subsection-60" class="internal"><span class="codenumber">4.5.1</span> <span class="title">Determinants of <span class="process-math">\(2\by2\)</span> matrices</span></a></div></li>
<li><div class="toc-item"><a href="sec-determinants.html#subsection-61" class="internal"><span class="codenumber">4.5.2</span> <span class="title">Determinants and invertibility</span></a></div></li>
<li><div class="toc-item"><a href="sec-determinants.html#subsection-62" class="internal"><span class="codenumber">4.5.3</span> <span class="title">Cofactor expansions</span></a></div></li>
<li><div class="toc-item"><a href="sec-determinants.html#subsection-63" class="internal"><span class="codenumber">4.5.4</span> <span class="title">Summary</span></a></div></li>
<li><div class="toc-item"><a href="sec-determinants.html#exercises-16" class="internal"><span class="codenumber">4.5.5</span> <span class="title">Exercises</span></a></div></li>
</ul>
</li>
<li>
<div class="toc-item"><a href="sec-subspaces.html" class="internal"><span class="codenumber">4.6</span> <span class="title">Subspaces</span></a></div>
<ul class="structural">
<li><div class="toc-item"><a href="sec-subspaces.html#subsection-64" class="internal"><span class="codenumber">4.6.1</span> <span class="title">Subspaces</span></a></div></li>
<li><div class="toc-item"><a href="sec-subspaces.html#subsection-65" class="internal"><span class="codenumber">4.6.2</span> <span class="title">The column space of <span class="process-math">\(A\)</span></span></a></div></li>
<li><div class="toc-item"><a href="sec-subspaces.html#subsection-66" class="internal"><span class="codenumber">4.6.3</span> <span class="title">The null space of <span class="process-math">\(A\)</span></span></a></div></li>
<li><div class="toc-item"><a href="sec-subspaces.html#subsection-67" class="internal"><span class="codenumber">4.6.4</span> <span class="title">Summary</span></a></div></li>
<li><div class="toc-item"><a href="sec-subspaces.html#exercises-17" class="internal"><span class="codenumber">4.6.5</span> <span class="title">Exercises</span></a></div></li>
</ul>
</li>
<li>
<div class="toc-item"><a href="sec-gaussian-revisited.html" class="internal"><span class="codenumber">4.7</span> <span class="title">Partial pivoting and LU factorizations</span></a></div>
<ul class="structural">
<li><div class="toc-item"><a href="sec-gaussian-revisited.html#subsec-partial-pivot" class="internal"><span class="codenumber">4.7.1</span> <span class="title">Partial pivoting</span></a></div></li>
<li><div class="toc-item"><a href="sec-gaussian-revisited.html#subsection-69" class="internal"><span class="codenumber">4.7.2</span> <span class="title"><span class="process-math">\(LU\)</span> factorizations</span></a></div></li>
<li><div class="toc-item"><a href="sec-gaussian-revisited.html#subsection-70" class="internal"><span class="codenumber">4.7.3</span> <span class="title">Summary</span></a></div></li>
<li><div class="toc-item"><a href="sec-gaussian-revisited.html#exercises-18" class="internal"><span class="codenumber">4.7.4</span> <span class="title">Exercises</span></a></div></li>
</ul>
</li>
</ul>
</li>
<li>
<div class="toc-item"><a href="chap5.html" class="internal"><span class="codenumber">5</span> <span class="title">Eigenvalues and eigenvectors</span></a></div>
<ul class="structural">
<li>
<div class="toc-item"><a href="sec-eigen-intro.html" class="internal"><span class="codenumber">5.1</span> <span class="title">An introduction to eigenvalues and eigenvectors</span></a></div>
<ul class="structural">
<li><div class="toc-item"><a href="sec-eigen-intro.html#subsection-71" class="internal"><span class="codenumber">5.1.1</span> <span class="title">A few examples</span></a></div></li>
<li><div class="toc-item"><a href="sec-eigen-intro.html#subsec-eigen-use" class="internal"><span class="codenumber">5.1.2</span> <span class="title">The usefulness of eigenvalues and eigenvectors</span></a></div></li>
<li><div class="toc-item"><a href="sec-eigen-intro.html#subsection-73" class="internal"><span class="codenumber">5.1.3</span> <span class="title">Summary</span></a></div></li>
<li><div class="toc-item"><a href="sec-eigen-intro.html#exercises-19" class="internal"><span class="codenumber">5.1.4</span> <span class="title">Exercises</span></a></div></li>
</ul>
</li>
<li>
<div class="toc-item"><a href="sec-eigen-find.html" class="internal"><span class="codenumber">5.2</span> <span class="title">Finding eigenvalues and eigenvectors</span></a></div>
<ul class="structural">
<li><div class="toc-item"><a href="sec-eigen-find.html#subsection-74" class="internal"><span class="codenumber">5.2.1</span> <span class="title">The characteristic polynomial</span></a></div></li>
<li><div class="toc-item"><a href="sec-eigen-find.html#subsection-75" class="internal"><span class="codenumber">5.2.2</span> <span class="title">Finding eigenvectors</span></a></div></li>
<li><div class="toc-item"><a href="sec-eigen-find.html#subsection-76" class="internal"><span class="codenumber">5.2.3</span> <span class="title">The characteristic polynomial and the dimension of eigenspaces</span></a></div></li>
<li><div class="toc-item"><a href="sec-eigen-find.html#subsection-77" class="internal"><span class="codenumber">5.2.4</span> <span class="title">Using Python to find eigenvalues and eigenvectors</span></a></div></li>
<li><div class="toc-item"><a href="sec-eigen-find.html#subsection-78" class="internal"><span class="codenumber">5.2.5</span> <span class="title">Summary</span></a></div></li>
<li><div class="toc-item"><a href="sec-eigen-find.html#exercises-20" class="internal"><span class="codenumber">5.2.6</span> <span class="title">Exercises</span></a></div></li>
</ul>
</li>
<li>
<div class="toc-item"><a href="sec-eigen-diag.html" class="internal"><span class="codenumber">5.3</span> <span class="title">Diagonalization, similarity, and powers of a matrix</span></a></div>
<ul class="structural">
<li><div class="toc-item"><a href="sec-eigen-diag.html#subsection-79" class="internal"><span class="codenumber">5.3.1</span> <span class="title">Diagonalization of matrices</span></a></div></li>
<li><div class="toc-item"><a href="sec-eigen-diag.html#subsection-80" class="internal"><span class="codenumber">5.3.2</span> <span class="title">Powers of a diagonalizable matrix</span></a></div></li>
<li><div class="toc-item"><a href="sec-eigen-diag.html#subsection-81" class="internal"><span class="codenumber">5.3.3</span> <span class="title">Similarity and complex eigenvalues</span></a></div></li>
<li><div class="toc-item"><a href="sec-eigen-diag.html#subsection-82" class="internal"><span class="codenumber">5.3.4</span> <span class="title">Summary</span></a></div></li>
<li><div class="toc-item"><a href="sec-eigen-diag.html#exercises-21" class="internal"><span class="codenumber">5.3.5</span> <span class="title">Exercises</span></a></div></li>
</ul>
</li>
<li>
<div class="toc-item"><a href="sec-dynamical.html" class="internal"><span class="codenumber">5.4</span> <span class="title">Dynamical systems</span></a></div>
<ul class="structural">
<li><div class="toc-item"><a href="sec-dynamical.html#subsection-83" class="internal"><span class="codenumber">5.4.1</span> <span class="title">A first example</span></a></div></li>
<li><div class="toc-item"><a href="sec-dynamical.html#subsection-84" class="internal"><span class="codenumber">5.4.2</span> <span class="title">Classifying dynamical systems</span></a></div></li>
<li><div class="toc-item"><a href="sec-dynamical.html#subsection-85" class="internal"><span class="codenumber">5.4.3</span> <span class="title">A <span class="process-math">\(3\by3\)</span> system</span></a></div></li>
<li><div class="toc-item"><a href="sec-dynamical.html#subsection-86" class="internal"><span class="codenumber">5.4.4</span> <span class="title">Summary</span></a></div></li>
<li><div class="toc-item"><a href="sec-dynamical.html#exercises-22" class="internal"><span class="codenumber">5.4.5</span> <span class="title">Exercises</span></a></div></li>
</ul>
</li>
<li>
<div class="toc-item"><a href="sec-stochastic.html" class="internal"><span class="codenumber">5.5</span> <span class="title">Markov chains and Google‚Äôs PageRank algorithm</span></a></div>
<ul class="structural">
<li><div class="toc-item"><a href="sec-stochastic.html#subsection-87" class="internal"><span class="codenumber">5.5.1</span> <span class="title">A first example</span></a></div></li>
<li><div class="toc-item"><a href="sec-stochastic.html#subsection-88" class="internal"><span class="codenumber">5.5.2</span> <span class="title">Markov chains</span></a></div></li>
<li><div class="toc-item"><a href="sec-stochastic.html#subsec-google" class="internal"><span class="codenumber">5.5.3</span> <span class="title">Google‚Äôs PageRank algorithm</span></a></div></li>
<li><div class="toc-item"><a href="sec-stochastic.html#subsection-90" class="internal"><span class="codenumber">5.5.4</span> <span class="title">Summary</span></a></div></li>
<li><div class="toc-item"><a href="sec-stochastic.html#exercises-23" class="internal"><span class="codenumber">5.5.5</span> <span class="title">Exercises</span></a></div></li>
</ul>
</li>
<li>
<div class="toc-item"><a href="sec-power-method.html" class="internal"><span class="codenumber">5.6</span> <span class="title">Finding eigenvectors numerically</span></a></div>
<ul class="structural">
<li><div class="toc-item"><a href="sec-power-method.html#subsection-91" class="internal"><span class="codenumber">5.6.1</span> <span class="title">The power method</span></a></div></li>
<li><div class="toc-item"><a href="sec-power-method.html#subsection-92" class="internal"><span class="codenumber">5.6.2</span> <span class="title">Finding other eigenvalues</span></a></div></li>
<li><div class="toc-item"><a href="sec-power-method.html#subsection-93" class="internal"><span class="codenumber">5.6.3</span> <span class="title">Summary</span></a></div></li>
<li><div class="toc-item"><a href="sec-power-method.html#exercises-24" class="internal"><span class="codenumber">5.6.4</span> <span class="title">Exercises</span></a></div></li>
</ul>
</li>
</ul>
</li>
<li>
<div class="toc-item"><a href="chap6.html" class="internal"><span class="codenumber">6</span> <span class="title">Orthogonality and Least Squares</span></a></div>
<ul class="structural">
<li>
<div class="toc-item"><a href="sec-dot-product.html" class="internal"><span class="codenumber">6.1</span> <span class="title">The dot product</span></a></div>
<ul class="structural">
<li><div class="toc-item"><a href="sec-dot-product.html#sec-projections-and-dot-products" class="internal"><span class="codenumber">6.1.1</span> <span class="title">Projections and dot products</span></a></div></li>
<li><div class="toc-item"><a href="sec-dot-product.html#subsec-computing-dot-products" class="internal"><span class="codenumber">6.1.2</span> <span class="title">Computing dot products</span></a></div></li>
<li><div class="toc-item"><a href="sec-dot-product.html#subsection-96" class="internal"><span class="codenumber">6.1.3</span> <span class="title"><span class="process-math">\(k\)</span>-means clustering</span></a></div></li>
<li><div class="toc-item"><a href="sec-dot-product.html#subsection-97" class="internal"><span class="codenumber">6.1.4</span> <span class="title">Summary</span></a></div></li>
<li><div class="toc-item"><a href="sec-dot-product.html#exercises-25" class="internal"><span class="codenumber">6.1.5</span> <span class="title">Exercises</span></a></div></li>
</ul>
</li>
<li>
<div class="toc-item"><a href="sec-transpose.html" class="internal"><span class="codenumber">6.2</span> <span class="title">Orthogonal complements and the matrix transpose</span></a></div>
<ul class="structural">
<li><div class="toc-item"><a href="sec-transpose.html#subsection-98" class="internal"><span class="codenumber">6.2.1</span> <span class="title">Orthogonal complements</span></a></div></li>
<li><div class="toc-item"><a href="sec-transpose.html#subsection-99" class="internal"><span class="codenumber">6.2.2</span> <span class="title">The matrix transpose</span></a></div></li>
<li><div class="toc-item"><a href="sec-transpose.html#subsection-100" class="internal"><span class="codenumber">6.2.3</span> <span class="title">Properties of the matrix transpose</span></a></div></li>
<li><div class="toc-item"><a href="sec-transpose.html#subsection-101" class="internal"><span class="codenumber">6.2.4</span> <span class="title">Summary</span></a></div></li>
<li><div class="toc-item"><a href="sec-transpose.html#exercises-26" class="internal"><span class="codenumber">6.2.5</span> <span class="title">Exercises</span></a></div></li>
</ul>
</li>
<li>
<div class="toc-item"><a href="sec-orthogonal-bases.html" class="internal"><span class="codenumber">6.3</span> <span class="title">Orthogonal bases and projections</span></a></div>
<ul class="structural">
<li><div class="toc-item"><a href="sec-orthogonal-bases.html#subsection-102" class="internal"><span class="codenumber">6.3.1</span> <span class="title">Orthogonal sets</span></a></div></li>
<li><div class="toc-item"><a href="sec-orthogonal-bases.html#subsection-103" class="internal"><span class="codenumber">6.3.2</span> <span class="title">Orthogonal projections</span></a></div></li>
<li><div class="toc-item"><a href="sec-orthogonal-bases.html#subsection-104" class="internal"><span class="codenumber">6.3.3</span> <span class="title">Summary</span></a></div></li>
<li><div class="toc-item"><a href="sec-orthogonal-bases.html#exercises-27" class="internal"><span class="codenumber">6.3.4</span> <span class="title">Exercises</span></a></div></li>
</ul>
</li>
<li>
<div class="toc-item"><a href="sec-gram-schmidt.html" class="internal"><span class="codenumber">6.4</span> <span class="title">Finding orthogonal bases</span></a></div>
<ul class="structural">
<li><div class="toc-item"><a href="sec-gram-schmidt.html#subsection-105" class="internal"><span class="codenumber">6.4.1</span> <span class="title">Gram-Schmidt orthogonalization</span></a></div></li>
<li><div class="toc-item"><a href="sec-gram-schmidt.html#subsection-106" class="internal"><span class="codenumber">6.4.2</span> <span class="title"><span class="process-math">\(QR\)</span> factorizations</span></a></div></li>
<li><div class="toc-item"><a href="sec-gram-schmidt.html#subsection-107" class="internal"><span class="codenumber">6.4.3</span> <span class="title">Summary</span></a></div></li>
<li><div class="toc-item"><a href="sec-gram-schmidt.html#exercises-28" class="internal"><span class="codenumber">6.4.4</span> <span class="title">Exercises</span></a></div></li>
</ul>
</li>
<li>
<div class="toc-item"><a href="sec-least-squares.html" class="internal"><span class="codenumber">6.5</span> <span class="title">Orthogonal least squares</span></a></div>
<ul class="structural">
<li><div class="toc-item"><a href="sec-least-squares.html#subsection-108" class="internal"><span class="codenumber">6.5.1</span> <span class="title">A first example</span></a></div></li>
<li><div class="toc-item"><a href="sec-least-squares.html#subsection-109" class="internal"><span class="codenumber">6.5.2</span> <span class="title">Solving least squares problems</span></a></div></li>
<li><div class="toc-item"><a href="sec-least-squares.html#subsection-110" class="internal"><span class="codenumber">6.5.3</span> <span class="title">Using <span class="process-math">\(QR\)</span> factorizations</span></a></div></li>
<li><div class="toc-item"><a href="sec-least-squares.html#subsection-111" class="internal"><span class="codenumber">6.5.4</span> <span class="title">Polynomial Regression</span></a></div></li>
<li><div class="toc-item"><a href="sec-least-squares.html#subsection-112" class="internal"><span class="codenumber">6.5.5</span> <span class="title">Summary</span></a></div></li>
<li><div class="toc-item"><a href="sec-least-squares.html#exercises-29" class="internal"><span class="codenumber">6.5.6</span> <span class="title">Exercises</span></a></div></li>
</ul>
</li>
</ul>
</li>
<li>
<div class="toc-item"><a href="chap7.html" class="internal"><span class="codenumber">7</span> <span class="title">The Spectral Theorem and singular value decompositions</span></a></div>
<ul class="structural">
<li class="active">
<div class="toc-item"><a href="sec-symmetric-matrices.html" class="internal"><span class="codenumber">7.1</span> <span class="title">Symmetric matrices and variance</span></a></div>
<ul class="structural">
<li><div class="toc-item"><a href="sec-symmetric-matrices.html#subsection-113" class="internal"><span class="codenumber">7.1.1</span> <span class="title">Symmetric matrices and orthogonal diagonalization</span></a></div></li>
<li><div class="toc-item"><a href="sec-symmetric-matrices.html#subsection-114" class="internal"><span class="codenumber">7.1.2</span> <span class="title">Variance</span></a></div></li>
<li><div class="toc-item"><a href="sec-symmetric-matrices.html#subsection-115" class="internal"><span class="codenumber">7.1.3</span> <span class="title">Summary</span></a></div></li>
<li><div class="toc-item"><a href="sec-symmetric-matrices.html#exercises-30" class="internal"><span class="codenumber">7.1.4</span> <span class="title">Exercises</span></a></div></li>
</ul>
</li>
<li>
<div class="toc-item"><a href="sec-quadratic-forms.html" class="internal"><span class="codenumber">7.2</span> <span class="title">Quadratic forms</span></a></div>
<ul class="structural">
<li><div class="toc-item"><a href="sec-quadratic-forms.html#subsection-116" class="internal"><span class="codenumber">7.2.1</span> <span class="title">Quadratic forms</span></a></div></li>
<li><div class="toc-item"><a href="sec-quadratic-forms.html#subsection-117" class="internal"><span class="codenumber">7.2.2</span> <span class="title">Definite symmetric matrices</span></a></div></li>
<li><div class="toc-item"><a href="sec-quadratic-forms.html#subsection-118" class="internal"><span class="codenumber">7.2.3</span> <span class="title">Summary</span></a></div></li>
<li><div class="toc-item"><a href="sec-quadratic-forms.html#exercises-31" class="internal"><span class="codenumber">7.2.4</span> <span class="title">Exercises</span></a></div></li>
</ul>
</li>
<li>
<div class="toc-item"><a href="sec-pca.html" class="internal"><span class="codenumber">7.3</span> <span class="title">Principal Component Analysis</span></a></div>
<ul class="structural">
<li><div class="toc-item"><a href="sec-pca.html#subsection-119" class="internal"><span class="codenumber">7.3.1</span> <span class="title">Principal Component Analysis</span></a></div></li>
<li><div class="toc-item"><a href="sec-pca.html#subsection-120" class="internal"><span class="codenumber">7.3.2</span> <span class="title">Using Principal Component Analysis</span></a></div></li>
<li><div class="toc-item"><a href="sec-pca.html#subsection-121" class="internal"><span class="codenumber">7.3.3</span> <span class="title">Summary</span></a></div></li>
<li><div class="toc-item"><a href="sec-pca.html#exercises-32" class="internal"><span class="codenumber">7.3.4</span> <span class="title">Exercises</span></a></div></li>
</ul>
</li>
<li>
<div class="toc-item"><a href="sec-svd-intro.html" class="internal"><span class="codenumber">7.4</span> <span class="title">Singular Value Decompositions</span></a></div>
<ul class="structural">
<li><div class="toc-item"><a href="sec-svd-intro.html#subsection-122" class="internal"><span class="codenumber">7.4.1</span> <span class="title">Finding singular value decompositions</span></a></div></li>
<li><div class="toc-item"><a href="sec-svd-intro.html#subsection-123" class="internal"><span class="codenumber">7.4.2</span> <span class="title">The structure of singular value decompositions</span></a></div></li>
<li><div class="toc-item"><a href="sec-svd-intro.html#subsection-124" class="internal"><span class="codenumber">7.4.3</span> <span class="title">Reduced singular value decompositions</span></a></div></li>
<li><div class="toc-item"><a href="sec-svd-intro.html#subsection-125" class="internal"><span class="codenumber">7.4.4</span> <span class="title">Summary</span></a></div></li>
<li><div class="toc-item"><a href="sec-svd-intro.html#exercises-33" class="internal"><span class="codenumber">7.4.5</span> <span class="title">Exercises</span></a></div></li>
</ul>
</li>
<li>
<div class="toc-item"><a href="sec-svd-uses.html" class="internal"><span class="codenumber">7.5</span> <span class="title">Using Singular Value Decompositions</span></a></div>
<ul class="structural">
<li><div class="toc-item"><a href="sec-svd-uses.html#subsection-126" class="internal"><span class="codenumber">7.5.1</span> <span class="title">Least squares problems</span></a></div></li>
<li><div class="toc-item"><a href="sec-svd-uses.html#subsection-127" class="internal"><span class="codenumber">7.5.2</span> <span class="title">Rank <span class="process-math">\(k\)</span> approximations</span></a></div></li>
<li><div class="toc-item"><a href="sec-svd-uses.html#subsection-128" class="internal"><span class="codenumber">7.5.3</span> <span class="title">Principal component analysis</span></a></div></li>
<li><div class="toc-item"><a href="sec-svd-uses.html#subsection-129" class="internal"><span class="codenumber">7.5.4</span> <span class="title">Image compressing and denoising</span></a></div></li>
<li><div class="toc-item"><a href="sec-svd-uses.html#subsection-130" class="internal"><span class="codenumber">7.5.5</span> <span class="title">Analyzing Supreme Court cases</span></a></div></li>
<li><div class="toc-item"><a href="sec-svd-uses.html#subsection-131" class="internal"><span class="codenumber">7.5.6</span> <span class="title">Summary</span></a></div></li>
<li><div class="toc-item"><a href="sec-svd-uses.html#exercises-34" class="internal"><span class="codenumber">7.5.7</span> <span class="title">Exercises</span></a></div></li>
</ul>
</li>
</ul>
</li>
<li>
<div class="toc-item"><a href="backmatter.html" class="internal"><span class="title">Back Matter</span></a></div>
<ul class="structural">
<li><div class="toc-item"><a href="app-notation.html" class="internal"><span class="codenumber">A</span> <span class="title">Notation</span></a></div></li>
<li>
<div class="toc-item"><a href="app-python-reference.html" class="internal"><span class="codenumber">B</span> <span class="title">Python Reference</span></a></div>
<ul class="structural">
<li><div class="toc-item"><a href="subsection-132.html" class="internal"><span class="codenumber">B.1</span> <span class="title">Accessing Python</span></a></div></li>
<li><div class="toc-item"><a href="subsection-133.html" class="internal"><span class="codenumber">B.2</span> <span class="title">Packages and libraries for data science</span></a></div></li>
<li><div class="toc-item"><a href="subsec-frequently-used-python.html" class="internal"><span class="codenumber">B.3</span> <span class="title">Freuqently used Python commands</span></a></div></li>
</ul>
</li>
<li><div class="toc-item"><a href="index-1.html" class="internal"><span class="title">Index</span></a></div></li>
<li><div class="toc-item"><a href="colophon-2.html" class="internal"><span class="title">Colophon</span></a></div></li>
</ul>
</li>
</ul></nav></div>
<main class="ptx-main"><div id="ptx-content" class="ptx-content"><section class="section" id="sec-symmetric-matrices"><h2 class="heading hide-type">
<span class="type">Section</span> <span class="codenumber">7.1</span> <span class="title">Symmetric matrices and variance</span>
</h2>
<section class="introduction" id="introduction-38"><div class="para" id="p-7096">In this section, we will revisit the theory of eigenvalues and eigenvectors for the special class of matrices that are <dfn class="terminology">symmetric</dfn>, meaning that the matrix equals its transpose.  This understanding of symmetric matrices will enable us to form singular value decompositions later in the chapter. We‚Äôll also begin studying variance in this section as it provides an important context that motivates some of our later work.</div> <div class="para" id="p-7097">To begin, remember that if <span class="process-math">\(A\)</span> is a square matrix, we say that <span class="process-math">\(\vvec\)</span> is an eigenvector of <span class="process-math">\(A\)</span> with associated eigenvalue <span class="process-math">\(\lambda\)</span> if <span class="process-math">\(A\vvec=\lambda\vvec\text{.}\)</span>  In other words, for these special vectors, the operation of matrix multiplication simplifies to scalar multiplication.</div> <article class="exploration project-like" id="exploration-25"><h3 class="heading">
<span class="type">Preview Activity</span><span class="space"> </span><span class="codenumber">7.1.1</span><span class="period">.</span>
</h3>
<div class="para" id="p-7098">This preview activity reminds us how a basis of eigenvectors can be used to relate a square matrix to a diagonal one.</div> <figure class="figure figure-like" id="fig-preview-similar"><div class="sidebyside"><div class="sbsrow" style="margin-left:2.5%;margin-right:2.5%;">
<div class="sbspanel top" style="width:47.3684210526316%;"><img src="external/images/empty-5.svg" role="img" class="contained"></div>
<div class="sbspanel top" style="width:47.3684210526316%;"><img src="external/images/empty-5.svg" role="img" class="contained"></div>
</div></div>
<figcaption><span class="type">Figure</span><span class="space"> </span><span class="codenumber">7.1.1<span class="period">.</span></span><span class="space"> </span>Use these plots to sketch the vectors requested in the preview activity.</figcaption></figure> <div class="para logical" id="p-7099"><ol class="lower-alpha">
<li id="li-4879"><div class="para logical" id="p-7100">
<div class="para">Suppose that <span class="process-math">\(D=\begin{bmatrix}
3 \amp 0 \\
0 \amp -1
\end{bmatrix}\)</span> and that <span class="process-math">\(\evec_1 = \twovec10\)</span> and <span class="process-math">\(\evec_2=\twovec01\text{.}\)</span>
</div>
<ol class="decimal">
<li id="li-4880"><div class="para" id="p-7101">Sketch the vectors <span class="process-math">\(\evec_1\)</span> and <span class="process-math">\(D\evec_1\)</span> on the left side of <a href="" class="xref" data-knowl="./knowl/fig-preview-similar.html" title="Figure 7.1.1">Figure¬†7.1.1</a>.</div></li>
<li id="li-4881"><div class="para" id="p-7102">Sketch the vectors <span class="process-math">\(\evec_2\)</span> and <span class="process-math">\(D\evec_2\)</span> on the left side of <a href="" class="xref" data-knowl="./knowl/fig-preview-similar.html" title="Figure 7.1.1">Figure¬†7.1.1</a>.</div></li>
<li id="li-4882"><div class="para" id="p-7103">Sketch the vectors <span class="process-math">\(\evec_1+2\evec_2\)</span> and <span class="process-math">\(D(\evec_1+2\evec_2)\)</span> on the left side.</div></li>
<li id="li-4883"><div class="para" id="p-7104">Give a geometric description of the matrix transformation defined by <span class="process-math">\(D\text{.}\)</span>
</div></li>
</ol>
</div></li>
<li id="li-4884"><div class="para logical" id="p-7105">
<div class="para">Now suppose we have vectors <span class="process-math">\(\vvec_1=\twovec11\)</span> and <span class="process-math">\(\vvec_2=\twovec{-1}1\)</span> and that <span class="process-math">\(A\)</span> is a <span class="process-math">\(2\by2\)</span> matrix such that</div>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/fig-preview-similar.html ./knowl/fig-preview-similar.html">
\begin{equation*}
A\vvec_1 = 3\vvec_1, \hspace{24pt}
A\vvec_2 = -\vvec_2.
\end{equation*}
</div>
<div class="para">That is, <span class="process-math">\(\vvec_1\)</span> and <span class="process-math">\(\vvec_2\)</span> are eigenvectors of <span class="process-math">\(A\)</span> with associated eigenvalues <span class="process-math">\(3\)</span> and <span class="process-math">\(-1\text{.}\)</span>
</div>
<ol class="decimal">
<li id="li-4885"><div class="para" id="p-7106">Sketch the vectors <span class="process-math">\(\vvec_1\)</span> and <span class="process-math">\(A\vvec_1\)</span> on the right side of <a href="" class="xref" data-knowl="./knowl/fig-preview-similar.html" title="Figure 7.1.1">Figure¬†7.1.1</a>.</div></li>
<li id="li-4886"><div class="para" id="p-7107">Sketch the vectors <span class="process-math">\(\vvec_2\)</span> and <span class="process-math">\(A\vvec_2\)</span> on the right side of <a href="" class="xref" data-knowl="./knowl/fig-preview-similar.html" title="Figure 7.1.1">Figure¬†7.1.1</a>.</div></li>
<li id="li-4887"><div class="para" id="p-7108">Sketch the vectors <span class="process-math">\(\vvec_1+2\vvec_2\)</span> and <span class="process-math">\(A(\vvec_1+2\vvec_2)\)</span> on the right side.</div></li>
<li id="li-4888"><div class="para" id="p-7109">Give a geometric description of the matrix transformation defined by <span class="process-math">\(A\text{.}\)</span>
</div></li>
</ol>
</div></li>
<li id="li-4889"><div class="para" id="p-7110">In what ways are the matrix transformations defined by <span class="process-math">\(D\)</span> and <span class="process-math">\(A\)</span> related to one another?</div></li>
</ol></div>
<div class="solutions">
<a href="" data-knowl="" class="id-ref solution-knowl original has-image" data-refid="hk-solution-363" id="solution-363"><span class="type">Solution</span><span class="period">.</span></a><div class="hidden-content tex2jax_ignore" id="hk-solution-363"><div class="solution solution-like"><div class="para logical" id="p-7111"><ol class="lower-alpha">
<li id="li-4890"><div class="para logical" id="p-7112"><ol class="decimal">
<li id="li-4891"><div class="sidebyside"><div class="sbsrow" style="margin-left:25%;margin-right:25%;"><div class="sbspanel top" style="width:100%;"><img src="external/images/diag-D-a.svg" role="img" class="contained"></div></div></div></li>
<li id="li-4892"><div class="sidebyside"><div class="sbsrow" style="margin-left:25%;margin-right:25%;"><div class="sbspanel top" style="width:100%;"><img src="external/images/diag-D-b.svg" role="img" class="contained"></div></div></div></li>
<li id="li-4893"><div class="sidebyside"><div class="sbsrow" style="margin-left:25%;margin-right:25%;"><div class="sbspanel top" style="width:100%;"><img src="external/images/diag-D-c.svg" role="img" class="contained"></div></div></div></li>
<li id="li-4894"><div class="para" id="p-7113">
<span class="process-math">\(D\)</span> stretches vectors horizontally by a factor of 3 and reflects them in the horizontal axis.</div></li>
</ol></div></li>
<li id="li-4895"><div class="para logical" id="p-7114"><ol class="decimal">
<li id="li-4896"><div class="sidebyside"><div class="sbsrow" style="margin-left:25%;margin-right:25%;"><div class="sbspanel top" style="width:100%;"><img src="external/images/eigen-A-a.svg" role="img" class="contained"></div></div></div></li>
<li id="li-4897"><div class="sidebyside"><div class="sbsrow" style="margin-left:25%;margin-right:25%;"><div class="sbspanel top" style="width:100%;"><img src="external/images/eigen-A-b.svg" role="img" class="contained"></div></div></div></li>
<li id="li-4898"><div class="sidebyside"><div class="sbsrow" style="margin-left:25%;margin-right:25%;"><div class="sbspanel top" style="width:100%;"><img src="external/images/eigen-A-c.svg" role="img" class="contained"></div></div></div></li>
<li id="li-4899"><div class="para" id="p-7115">
<span class="process-math">\(A\)</span> stretches vectors in the direction of <span class="process-math">\(\vvec_1\)</span>  by a factor of 3 and reflects them in the line defined by <span class="process-math">\(\vvec_1\text{.}\)</span>
</div></li>
</ol></div></li>
<li id="li-4900"><div class="para" id="p-7116">The effect of the two transformations are the same when viewed in the coordinate systems given by the appropriate set of vectors.</div></li>
</ol></div></div></div>
</div></article> <div class="para" id="p-7117">The preview activity asks us to compare the matrix transformations defined by two matrices, a diagonal matrix <span class="process-math">\(D\)</span> and a matrix <span class="process-math">\(A\)</span> whose eigenvectors are given to us.  The transformation defined by <span class="process-math">\(D\)</span> stretches horizontally by a factor of 3 and reflects in the horizontal axis, as shown in <a href="" class="xref" data-knowl="./knowl/fig-eigen-diag-D.html" title="Figure 7.1.2">Figure¬†7.1.2</a>
</div> <figure class="figure figure-like" id="fig-eigen-diag-D"><div class="sidebyside"><div class="sbsrow" style="margin-left:10%;margin-right:10%;"><div class="sbspanel top" style="width:100%;"><img src="external/images/eigen-diag-D.svg" role="img" class="contained"></div></div></div>
<figcaption><span class="type">Figure</span><span class="space"> </span><span class="codenumber">7.1.2<span class="period">.</span></span><span class="space"> </span>The matrix transformation defined by <span class="process-math">\(D\text{.}\)</span></figcaption></figure> <div class="para" id="p-7118">By contrast, the transformation defined by <span class="process-math">\(A\)</span> stretches the plane by a factor of 3 in the direction of <span class="process-math">\(\vvec_1\)</span> and reflects in the line defined by <span class="process-math">\(\vvec_1\text{,}\)</span> as seen in <a href="" class="xref" data-knowl="./knowl/fig-eigen-diag-general.html" title="Figure 7.1.3">Figure¬†7.1.3</a>.</div> <figure class="figure figure-like" id="fig-eigen-diag-general"><div class="sidebyside"><div class="sbsrow" style="margin-left:10%;margin-right:10%;"><div class="sbspanel top" style="width:100%;"><img src="external/images/eigen-diag-A.svg" role="img" class="contained"></div></div></div>
<figcaption><span class="type">Figure</span><span class="space"> </span><span class="codenumber">7.1.3<span class="period">.</span></span><span class="space"> </span>The matrix transformation defined by <span class="process-math">\(A\text{.}\)</span></figcaption></figure> <div class="para logical" id="p-7119">
<div class="para">In this way, we see that the matrix transformations defined by these two matrices are equivalent after a <span class="process-math">\(45^\circ\)</span> rotation.  This notion of equivalence is what we called <dfn class="terminology">similarity</dfn> in <a href="sec-eigen-diag.html" class="internal" title="Section 5.3: Diagonalization, similarity, and powers of a matrix">Section¬†5.3</a>.  There we considered a square <span class="process-math">\(m\by m\)</span> matrix <span class="process-math">\(A\)</span> that provided enough eigenvectors to form a basis of <span class="process-math">\(\real^m\text{.}\)</span>  For example, suppose we can construct a basis for <span class="process-math">\(\real^m\)</span> using eigenvectors <span class="process-math">\(\vvec_1,\vvec_2,\ldots,\vvec_m\)</span> having associated eigenvalues <span class="process-math">\(\lambda_1,\lambda_2,\ldots,\lambda_m\text{.}\)</span>  Forming the matrices,</div>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/sec-eigen-diag.html">
\begin{equation*}
P = \begin{bmatrix}
\vvec_1\amp\vvec_2\amp\ldots\amp\vvec_m
\end{bmatrix},
\hspace{24pt}
D = \begin{bmatrix}
\lambda_1 \amp 0 \amp \ldots \amp 0 \\
0 \amp \lambda_2 \amp \ldots \amp 0 \\
\vdots\amp\vdots\amp\ddots\amp\vdots\\
0 \amp 0 \amp \ldots \amp \lambda_m
\end{bmatrix},
\end{equation*}
</div>
<div class="para">enables us to write <span class="process-math">\(A = PDP^{-1}\text{.}\)</span>  This is what it means for <span class="process-math">\(A\)</span> to be <dfn class="terminology">diagonalizable</dfn>.</div>
</div> <div class="para logical" id="p-7120">
<div class="para">For the example in the preview activity, we are led to form</div>
<div class="displaymath process-math">
\begin{equation*}
P = \begin{bmatrix}
1 \amp -1 \\
1 \amp 1
\end{bmatrix},
\hspace{24pt}
D = \begin{bmatrix}
3 \amp 0 \\
0 \amp - 1
\end{bmatrix}
\end{equation*}
</div>
<div class="para">which tells us that <span class="process-math">\(A=PDP^{-1} =
\begin{bmatrix}
1 \amp 2 \\
2 \amp 1
\end{bmatrix}
\text{.}\)</span>
</div>
</div> <div class="para" id="p-7121">Notice that the matrix <span class="process-math">\(A\)</span> has eigenvectors <span class="process-math">\(\vvec_1\)</span> and <span class="process-math">\(\vvec_2\)</span> that not only form a basis for <span class="process-math">\(\real^2\)</span> but, in fact, form an orthogonal basis for <span class="process-math">\(\real^2\text{.}\)</span> Given the prominent role played by orthogonal bases in the last chapter, we would like to understand what conditions on a matrix enable us to form an orthogonal basis of eigenvectors.</div></section><section class="subsection" id="subsection-113"><h3 class="heading hide-type">
<span class="type">Subsection</span> <span class="codenumber">7.1.1</span> <span class="title">Symmetric matrices and orthogonal diagonalization</span>
</h3>
<div class="para" id="p-7122">Let‚Äôs begin by looking at some examples in the next activity.</div>
<article class="activity project-like" id="activity-88"><h4 class="heading">
<span class="type">Activity</span><span class="space"> </span><span class="codenumber">7.1.2</span><span class="period">.</span>
</h4>
<div class="para logical" id="p-7123">
<div class="para">Remember that the Python command <code class="code-inline tex2jax_ignore">scipy.linalg.eig(A)</code> attempts to find a basis for <span class="process-math">\(\real^m\)</span> consisting of eigenvectors of <span class="process-math">\(A\text{.}\)</span>  If successful, <code class="code-inline tex2jax_ignore">e, E = linalg.aig(A)</code> provides a vector of eigen values <code class="code-inline tex2jax_ignore">e</code> and a matrix <code class="code-inline tex2jax_ignore">E</code> containing the associated eigenvectors as columns. <pre class="ptx-sagecell sagecell-python" id="sage-221"><script type="text/x-sage">
</script></pre>
</div>
<ol class="lower-alpha">
<li id="li-4901"><div class="para logical" id="p-7124">
<div class="para">For each of the following matrices, determine whether there is a basis for <span class="process-math">\(\real^2\)</span> consisting of eigenvectors of that matrix.  When there is such a basis, form the matrices <span class="process-math">\(P\)</span> and <span class="process-math">\(D\)</span> such that <span class="process-math">\(A = PDP^{-1}\text{.}\)</span>
</div>
<ol class="decimal">
<li id="li-4902"><div class="para" id="p-7125"><span class="process-math">\(\begin{bmatrix}
3 \amp -4 \\
4 \amp 3
\end{bmatrix}
\text{.}\)</span></div></li>
<li id="li-4903"><div class="para" id="p-7126"><span class="process-math">\(\begin{bmatrix}
1 \amp 1 \\
-1 \amp 3
\end{bmatrix}
\text{.}\)</span></div></li>
<li id="li-4904"><div class="para" id="p-7127"><span class="process-math">\(\begin{bmatrix}
1 \amp 0\\
-1 \amp 2
\end{bmatrix}
\text{.}\)</span></div></li>
<li id="li-4905"><div class="para" id="p-7128"><span class="process-math">\(\begin{bmatrix}
9 \amp 2 \\
2 \amp 6
\end{bmatrix}
\text{.}\)</span></div></li>
</ol>
</div></li>
<li id="li-4906"><div class="para" id="p-7129">For which of these examples is it possible to form an orthogonal basis for <span class="process-math">\(\real^2\)</span> consisting of eigenvectors?</div></li>
<li id="li-4907"><div class="para" id="p-7130">For any such matrix <span class="process-math">\(A\text{,}\)</span> find an orthonormal basis of eigenvectors and explain why <span class="process-math">\(A=QDQ^{-1}\)</span> where <span class="process-math">\(Q\)</span> is an orthogonal matrix.</div></li>
<li id="li-4908"><div class="para" id="p-7131">Finally, explain why <span class="process-math">\(A=QDQ^T\)</span> in this case.</div></li>
<li id="li-4909"><div class="para" id="p-7132">When <span class="process-math">\(A=QDQ^T\text{,}\)</span> what is the relationship between <span class="process-math">\(A\)</span> and <span class="process-math">\(A^T\text{?}\)</span>
</div></li>
</ol>
</div>
<div class="solutions">
<a href="" data-knowl="" class="id-ref answer-knowl original" data-refid="hk-answer-286" id="answer-286"><span class="type">Answer</span><span class="period">.</span></a><div class="hidden-content tex2jax_ignore" id="hk-answer-286"><div class="answer solution-like"><div class="para logical" id="p-7143"><ol class="lower-alpha">
<li id="li-4919"><div class="para logical" id="p-7144"><ol class="decimal">
<li id="li-4920"><div class="para" id="p-7145">There is no such basis.</div></li>
<li id="li-4921"><div class="para" id="p-7146">There is no such basis.</div></li>
<li id="li-4922"><div class="para logical" id="p-7147">
<div class="para">This matrix is diagonalizable with</div>
<div class="displaymath process-math">
\begin{equation*}
D = \begin{bmatrix}
2 \amp 0 \\
0 \amp 1 \\
\end{bmatrix},
\hspace{24pt}
P = \begin{bmatrix}
0 \amp 1 \\
1 \amp 1 \\
\end{bmatrix}\text{.}
\end{equation*}
</div>
</div></li>
<li id="li-4923"><div class="para logical" id="p-7148">
<div class="para">This matrix is also diagonalizable with</div>
<div class="displaymath process-math">
\begin{equation*}
D = \begin{bmatrix}
10 \amp 0 \\
0 \amp 5 \\
\end{bmatrix},
\hspace{24pt}
P = \begin{bmatrix}
2 \amp 1 \\
1 \amp -2 \\
\end{bmatrix}\text{.}
\end{equation*}
</div>
</div></li>
</ol></div></li>
<li id="li-4924"><div class="para" id="p-7149">Only the last matrix.</div></li>
<li id="li-4925"><div class="para" id="p-7150"><span class="process-math">\(\displaystyle Q = \begin{bmatrix}
2/\sqrt{5} \amp 1/\sqrt{5} \\
1/\sqrt{5} \amp -2/\sqrt{5} \\
\end{bmatrix}\)</span></div></li>
<li id="li-4926"><div class="para" id="p-7151"><span class="process-math">\(\displaystyle Q^{-1} =  Q^T\)</span></div></li>
<li id="li-4927"><div class="para" id="p-7152"><span class="process-math">\(\displaystyle A=A^T\)</span></div></li>
</ol></div></div></div>
<a href="" data-knowl="" class="id-ref solution-knowl original" data-refid="hk-solution-364" id="solution-364"><span class="type">Solution</span><span class="period">.</span></a><div class="hidden-content tex2jax_ignore" id="hk-solution-364"><div class="solution solution-like"><div class="para logical" id="p-7133"><ol class="lower-alpha">
<li id="li-4910"><div class="para logical" id="p-7134"><ol class="decimal">
<li id="li-4911"><div class="para" id="p-7135">The eigenvalues of this matrix are complex so there is no such basis.</div></li>
<li id="li-4912"><div class="para" id="p-7136">There is one eigenvalue <span class="process-math">\(\lambda=2\)</span> with multiplicity two.  The associated eigenspace <span class="process-math">\(E_2\)</span> is one-dimensional so there is not a basis of <span class="process-math">\(\real^2\)</span> consisting of eigenvectors.</div></li>
<li id="li-4913"><div class="para logical" id="p-7137">
<div class="para">This matrix is diagonalizable with</div>
<div class="displaymath process-math">
\begin{equation*}
D = \begin{bmatrix}
2 \amp 0 \\
0 \amp 1 \\
\end{bmatrix},
\hspace{24pt}
P = \begin{bmatrix}
0 \amp 1 \\
1 \amp 1 \\
\end{bmatrix}\text{.}
\end{equation*}
</div>
</div></li>
<li id="li-4914"><div class="para logical" id="p-7138">
<div class="para">This matrix is also diagonalizable with</div>
<div class="displaymath process-math">
\begin{equation*}
D = \begin{bmatrix}
10 \amp 0 \\
0 \amp 5 \\
\end{bmatrix},
\hspace{24pt}
P = \begin{bmatrix}
2 \amp 1 \\
1 \amp -2 \\
\end{bmatrix}\text{.}
\end{equation*}
</div>
</div></li>
</ol></div></li>
<li id="li-4915"><div class="para" id="p-7139">Only the last matrix <span class="process-math">\(A=\begin{bmatrix}
9 \amp 2 \\
2 \amp 6
\end{bmatrix}\text{.}\)</span>
</div></li>
<li id="li-4916"><div class="para" id="p-7140">We form an orthonormal basis by scaling the eigenvectors to have length 1.  This gives <span class="process-math">\(Q = \begin{bmatrix}
2/\sqrt{5} \amp 1/\sqrt{5} \\
1/\sqrt{5} \amp -2/\sqrt{5} \\
\end{bmatrix}\text{,}\)</span> which is orthogonal since the columns form an orthonormal basis of <span class="process-math">\(\real^2\text{.}\)</span>
</div></li>
<li id="li-4917"><div class="para" id="p-7141">Orthogonal matrices are invertible and have <span class="process-math">\(Q^{-1}
= Q^T\)</span>
</div></li>
<li id="li-4918"><div class="para" id="p-7142">If <span class="process-math">\(A=QDQ^T\text{,}\)</span> we have <span class="process-math">\(A^T=(QDQ^T)^T =
(Q^T)^TD^TQ^T = QDQ^T = A\text{.}\)</span>  This means that the matrix is symmetric.</div></li>
</ol></div></div></div>
</div></article><div class="para" id="p-7153">The examples in this activity illustrate a range of possibilities.  First, a matrix may have complex eigenvalues, in which case it will not be diagonalizable.  Second, even if all the eigenvalues are real, there may not be a basis of eigenvalues if the dimension of one of the eigenspaces is less than the algebraic multiplicity of the associated eigenvalue.</div>
<div class="para logical" id="p-7154">
<div class="para">We are interested in matrices for which there is an orthogonal basis of eigenvectors.  When this happens, we can create an orthonormal basis of eigenvectors by scaling each eigenvector in the basis so that its length is 1.  Putting these orthonormal vectors into a matrix <span class="process-math">\(Q\)</span> produces an orthogonal matrix, which means that <span class="process-math">\(Q^T=Q^{-1}\text{.}\)</span>  We then have</div>
<div class="displaymath process-math">
\begin{equation*}
A = QDQ^{-1} = QDQ^T.
\end{equation*}
</div>
<div class="para">In this case, we say that <span class="process-math">\(A\)</span> is <dfn class="terminology">orthogonally diagonalizable</dfn>.</div>
</div>
<article class="definition definition-like" id="def-orthog-diag"><h4 class="heading">
<span class="type">Definition</span><span class="space"> </span><span class="codenumber">7.1.4</span><span class="period">.</span>
</h4> <div class="para" id="p-7155">If there is an orthonormal basis of <span class="process-math">\(\real^n\)</span> consisting of eigenvectors of the matrix <span class="process-math">\(A\text{,}\)</span> we say that <span class="process-math">\(A\)</span> is <dfn class="terminology">orthogonally diagonalizable</dfn>.  In particular, we can write <span class="process-math">\(A=QDQ^T\)</span> where <span class="process-math">\(Q\)</span> is an orthogonal matrix.</div></article><div class="para logical" id="p-7156">
<div class="para">When <span class="process-math">\(A\)</span> is orthogonally diagonalizable, notice that</div>
<div class="displaymath process-math">
\begin{equation*}
A^T=(QDQ^T)^T = (Q^T)^TD^TQ^T = QDQ^T = A.
\end{equation*}
</div>
<div class="para">That is, when <span class="process-math">\(A\)</span> is orthogonally diagonalizable, <span class="process-math">\(A=A^T\)</span> and we say that <span class="process-math">\(A\)</span> is <dfn class="terminology">symmetric</dfn>.</div>
</div>
<article class="definition definition-like" id="definition-37"><h4 class="heading">
<span class="type">Definition</span><span class="space"> </span><span class="codenumber">7.1.5</span><span class="period">.</span>
</h4> <div class="para" id="p-7157">A <dfn class="terminology">symmetric</dfn> matrix <span class="process-math">\(A\)</span> is one for which <span class="process-math">\(A=A^T\text{.}\)</span>
</div></article><article class="example example-like" id="example-74"><h4 class="heading">
<span class="type">Example</span><span class="space"> </span><span class="codenumber">7.1.6</span><span class="period">.</span>
</h4>
<div class="para logical" id="p-7158">
<div class="para">Consider the matrix <span class="process-math">\(A =
\begin{bmatrix}
-2 \amp 36 \\
36 \amp -23
\end{bmatrix}
\text{,}\)</span> which has eigenvectors <span class="process-math">\(\vvec_1 = \twovec43\text{,}\)</span> with associated eigenvalue <span class="process-math">\(\lambda_1=25\text{,}\)</span> and <span class="process-math">\(\vvec_2=\twovec{3}{-4}\text{,}\)</span> with associated eigenvalue <span class="process-math">\(\lambda_2=-50\text{.}\)</span>  Notice that <span class="process-math">\(\vvec_1\)</span> and <span class="process-math">\(\vvec_2\)</span> are orthogonal so we can form an orthonormal basis of eigenvectors:</div>
<div class="displaymath process-math">
\begin{equation*}
\uvec_1 = \twovec{4/5}{3/5},
\hspace{24pt}
\uvec_2 = \twovec{3/5}{-4/5}\text{.}
\end{equation*}
</div>
</div> <div class="para logical" id="p-7159">
<div class="para">In this way, we construct the matrices</div>
<div class="displaymath process-math">
\begin{equation*}
Q = \begin{bmatrix}
4/5 \amp 3/5 \\
3/5 \amp -4/5 \\
\end{bmatrix},
\hspace{24pt}
D = \begin{bmatrix}
25 \amp 0 \\
0 \amp -50
\end{bmatrix}
\end{equation*}
</div>
<div class="para">and note that <span class="process-math">\(A = QDQ^T\text{.}\)</span>
</div>
</div> <div class="para" id="p-7160">Notice also that, as expected, <span class="process-math">\(A\)</span> is symmetric;  that is, <span class="process-math">\(A=A^T\text{.}\)</span>
</div></article><article class="example example-like" id="example-75"><h4 class="heading">
<span class="type">Example</span><span class="space"> </span><span class="codenumber">7.1.7</span><span class="period">.</span>
</h4>
<div class="para logical" id="p-7161">
<div class="para">If <span class="process-math">\(A = \begin{bmatrix}
1 \amp 2 \\
2 \amp 1 \\
\end{bmatrix}
\text{,}\)</span> then there is an orthogonal basis of eigenvectors <span class="process-math">\(\vvec_1 = \twovec11\)</span> and <span class="process-math">\(\vvec_2 =
\twovec{-1}1\)</span> with eigenvalues <span class="process-math">\(\lambda_1=3\)</span> and <span class="process-math">\(\lambda_2=-1\text{.}\)</span>  Using these eigenvectors, we form the orthogonal matrix <span class="process-math">\(Q\)</span> consisting of eigenvectors and the diagonal matrix <span class="process-math">\(D\text{,}\)</span> where</div>
<div class="displaymath process-math">
\begin{equation*}
Q = \begin{bmatrix}
1/\sqrt{2} \amp -1/\sqrt{2} \\
1/\sqrt{2} \amp 1/\sqrt{2}
\end{bmatrix},\hspace{24pt}
D = \begin{bmatrix}
3 \amp 0 \\
0 \amp - 1
\end{bmatrix}.
\end{equation*}
</div>
<div class="para">Then we have <span class="process-math">\(A = QDQ^T\text{.}\)</span>
</div>
</div> <div class="para logical" id="p-7162">
<div class="para">Notice that the matrix transformation represented by <span class="process-math">\(Q\)</span> is a <span class="process-math">\(45^\circ\)</span> rotation while that represented by <span class="process-math">\(Q^T=Q^{-1}\)</span> is a <span class="process-math">\(-45^\circ\)</span> rotation. Therefore, if we multiply a vector <span class="process-math">\(\xvec\)</span> by <span class="process-math">\(A\text{,}\)</span> we can decompose the multiplication as</div>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/fig-diag-factors.html">
\begin{equation*}
A\xvec = Q(D(Q^T\xvec)).
\end{equation*}
</div>
<div class="para">That is, we first rotate <span class="process-math">\(\xvec\)</span> by <span class="process-math">\(-45^\circ\text{,}\)</span> then apply the diagonal matrix <span class="process-math">\(D\text{,}\)</span> which stretches and reflects, and finally rotate by <span class="process-math">\(45^\circ\text{.}\)</span>  We may visualize this factorization as in <a href="" class="xref" data-knowl="./knowl/fig-diag-factors.html" title="Figure 7.1.8">Figure¬†7.1.8</a>.</div>
</div> <figure class="figure figure-like" id="fig-diag-factors"><div class="sidebyside"><div class="sbsrow" style="margin-left:5%;margin-right:5%;"><div class="sbspanel top" style="width:100%;"><img src="external/images/eigen-diag.svg" role="img" class="contained"></div></div></div>
<figcaption><span class="type">Figure</span><span class="space"> </span><span class="codenumber">7.1.8<span class="period">.</span></span><span class="space"> </span>The transformation defined by <span class="process-math">\(A=QDQ^T\)</span> can be interpreted as a sequence of geometric transformations: <span class="process-math">\(Q^T\)</span> rotates by <span class="process-math">\(-45^\circ\text{,}\)</span> <span class="process-math">\(D\)</span> stretches and reflects, and <span class="process-math">\(Q\)</span> rotates by <span class="process-math">\(45^\circ\text{.}\)</span></figcaption></figure> <div class="para" id="p-7163">In fact, a similar picture holds any time the matrix <span class="process-math">\(A\)</span> is orthogonally diagonalizable.</div></article><div class="para" id="p-7164">We have seen that a matrix that is orthogonally diagonalizable must be symmetric.  In fact, it turns out that any symmetric matrix is orthogonally diagonalizable.  We record this fact in the next theorem.</div>
<article class="theorem theorem-like" id="theorem-3"><h4 class="heading">
<span class="type">Theorem</span><span class="space"> </span><span class="codenumber">7.1.9</span><span class="period">.</span><span class="space"> </span><span class="title">The Spectral Theorem.</span>
</h4>
<div class="para" id="p-7165">The matrix <span class="process-math">\(A\)</span> is orthogonally diagonalizable if and only if <span class="process-math">\(A\)</span> is symmetric.</div></article><article class="activity project-like" id="activity-orthog-diag"><h4 class="heading">
<span class="type">Activity</span><span class="space"> </span><span class="codenumber">7.1.3</span><span class="period">.</span>
</h4>
<div class="para" id="p-7166">Each of the following matrices is symmetric so the Spectral Theorem tells us that each is orthogonally diagonalizable. The point of this activity is to find an orthogonal diagonalization for each matrix.</div> <div class="para logical" id="p-7167">
<div class="para">To begin, find a basis for each eigenspace.  Use this basis to find an orthogonal basis for each eigenspace and put these bases together to find an orthogonal basis for <span class="process-math">\(\real^m\)</span> consisting of eigenvectors.  Use this basis to write an orthogonal diagonalization of the matrix. <pre class="ptx-sagecell sagecell-python" id="sage-222"><script type="text/x-sage">
</script></pre>
</div>
<ol class="lower-alpha">
<li id="li-4928"><div class="para" id="p-7168"><span class="process-math">\(\begin{bmatrix}
0 \amp 2 \\
2 \amp 3
\end{bmatrix}
\text{.}\)</span></div></li>
<li id="li-4929"><div class="para" id="p-7169"><span class="process-math">\(\begin{bmatrix}
4 \amp -2 \amp 14 \\
-2 \amp 19 \amp -16 \\
14 \amp -16 \amp 13
\end{bmatrix}
\text{.}\)</span></div></li>
<li id="li-4930"><div class="para" id="p-7170"><span class="process-math">\(\begin{bmatrix}
5 \amp 4 \amp 2 \\
4 \amp 5 \amp 2 \\
2 \amp 2 \amp 2
\end{bmatrix}
\text{.}\)</span></div></li>
<li id="li-4931"><div class="para" id="p-7171">Consider the matrix <span class="process-math">\(A = B^TB\)</span> where <span class="process-math">\(B = \begin{bmatrix}
0 \amp 1 \amp 2 \\
2 \amp 0 \amp 1 
\end{bmatrix}
\text{.}\)</span> Explain how we know that <span class="process-math">\(A\)</span> is symmetric and then find an orthogonal diagonalization of <span class="process-math">\(A\text{.}\)</span>
</div></li>
</ol>
</div>
<div class="solutions">
<a href="" data-knowl="" class="id-ref answer-knowl original" data-refid="hk-answer-287" id="answer-287"><span class="type">Answer</span><span class="period">.</span></a><div class="hidden-content tex2jax_ignore" id="hk-answer-287"><div class="answer solution-like"><div class="para logical" id="p-7177"><ol class="lower-alpha">
<li id="li-4936"><div class="para logical" id="p-7178"><div class="displaymath process-math">
\begin{equation*}
D = \begin{bmatrix}
4 \amp 0 \\
0 \amp -1 \\
\end{bmatrix},
\hspace{24pt}
Q = \begin{bmatrix}
1/\sqrt{5} \amp 2/\sqrt{5} \\
2/\sqrt{5} \amp -1/\sqrt{5} \\
\end{bmatrix}\text{.}
\end{equation*}
</div></div></li>
<li id="li-4937"><div class="para logical" id="p-7179"><div class="displaymath process-math">
\begin{equation*}
D = \begin{bmatrix}
36 \amp 0 \amp 0 \\
0 \amp 9 \amp 0 \\
0 \amp 0 \amp -9 \\
\end{bmatrix},
\hspace{24pt}
Q = \begin{bmatrix}
1/3 \amp 2/3 \amp 2/3 \\
-2/3 \amp 2/3 \amp -1/3 \\
2/3 \amp 1/3 \amp -2/3 \\
\end{bmatrix}\text{.}
\end{equation*}
</div></div></li>
<li id="li-4938"><div class="para logical" id="p-7180"><div class="displaymath process-math">
\begin{equation*}
D = \begin{bmatrix}
10 \amp 0 \amp 0 \\
0 \amp 1 \amp 0 \\
0 \amp 0 \amp 1 \\
\end{bmatrix},
\hspace{24pt}
Q = \begin{bmatrix}
2/3 \amp 1/\sqrt{5} \amp -4/\sqrt{45} \\
2/3 \amp 0 \amp 5/\sqrt{45} \\
1/3 \amp -2/\sqrt{5} \amp -2/\sqrt{45} \\
\end{bmatrix}\text{.}
\end{equation*}
</div></div></li>
<li id="li-4939"><div class="para logical" id="p-7181"><div class="displaymath process-math">
\begin{equation*}
D = \begin{bmatrix}
7 \amp 0 \amp 0 \\
0 \amp 3 \amp 0 \\
0 \amp 0 \amp 0 \\
\end{bmatrix},
\hspace{24pt}
Q = \begin{bmatrix}
2/\sqrt{14} \amp 2/\sqrt{6} \amp 1/\sqrt{21} \\
1/\sqrt{14} \amp -1/\sqrt{6} \amp 4/\sqrt{21} \\
3/\sqrt{14} \amp -1/\sqrt{6} \amp -2/\sqrt{21} \\
\end{bmatrix}\text{.}
\end{equation*}
</div></div></li>
</ol></div></div></div>
<a href="" data-knowl="" class="id-ref solution-knowl original" data-refid="hk-solution-365" id="solution-365"><span class="type">Solution</span><span class="period">.</span></a><div class="hidden-content tex2jax_ignore" id="hk-solution-365"><div class="solution solution-like"><div class="para logical" id="p-7172"><ol class="lower-alpha">
<li id="li-4932"><div class="para logical" id="p-7173">
<div class="para">We have eigenvectors <span class="process-math">\(\vvec_1=\twovec12\)</span> and <span class="process-math">\(\vvec_2 = \twovec{2}{-1}\)</span> with associated eigenvalues <span class="process-math">\(\lambda_1 = 4\)</span> and <span class="process-math">\(\lambda_2=-1\text{.}\)</span>  We form an orthonormal basis of eigenvectors, <span class="process-math">\(\uvec_1=\twovec{1/\sqrt{5}}{2/\sqrt{5}}\)</span> and <span class="process-math">\(\uvec_2=\twovec{2/\sqrt{5}}{-1/\sqrt{5}}\text{.}\)</span> This gives</div>
<div class="displaymath process-math">
\begin{equation*}
D = \begin{bmatrix}
4 \amp 0 \\
0 \amp -1 \\
\end{bmatrix},
\hspace{24pt}
Q = \begin{bmatrix}
1/\sqrt{5} \amp 2/\sqrt{5} \\
2/\sqrt{5} \amp -1/\sqrt{5} \\
\end{bmatrix}\text{.}
\end{equation*}
</div>
</div></li>
<li id="li-4933"><div class="para logical" id="p-7174">
<div class="para">We find</div>
<div class="displaymath process-math">
\begin{equation*}
D = \begin{bmatrix}
36 \amp 0 \amp 0 \\
0 \amp 9 \amp 0 \\
0 \amp 0 \amp -9 \\
\end{bmatrix},
\hspace{24pt}
Q = \begin{bmatrix}
1/3 \amp 2/3 \amp 2/3 \\
-2/3 \amp 2/3 \amp -1/3 \\
2/3 \amp 1/3 \amp -2/3 \\
\end{bmatrix}\text{.}
\end{equation*}
</div>
</div></li>
<li id="li-4934"><div class="para logical" id="p-7175">
<div class="para">We have eigenvalues <span class="process-math">\(\lambda_1=10\)</span> with associated eigenvector <span class="process-math">\(\vvec_1=\threevec211\)</span> and <span class="process-math">\(\lambda_2 = 1\)</span> with associated eigenvectors <span class="process-math">\(\vvec_2=\threevec10{-2}\)</span> and <span class="process-math">\(\vvec_3=\threevec01{-2}\text{.}\)</span>  Notice that <span class="process-math">\(\vvec_1\)</span> is orthogonal to both <span class="process-math">\(\vvec_2\)</span> and <span class="process-math">\(\vvec_3\text{,}\)</span> but <span class="process-math">\(\vvec_2\)</span> and <span class="process-math">\(\vvec_3\)</span> are not orthogonal to one another.  We can, however, apply Gram-Schmidt to create an orthogonal basis of the eigenspace <span class="process-math">\(E_1\text{.}\)</span>  We can then form an orthonormal basis so that</div>
<div class="displaymath process-math">
\begin{equation*}
D = \begin{bmatrix}
10 \amp 0 \amp 0 \\
0 \amp 1 \amp 0 \\
0 \amp 0 \amp 1 \\
\end{bmatrix},
\hspace{24pt}
Q = \begin{bmatrix}
2/3 \amp 1/\sqrt{5} \amp -4/\sqrt{45} \\
2/3 \amp 0 \amp 5/\sqrt{45} \\
1/3 \amp -2/\sqrt{5} \amp -2/\sqrt{45} \\
\end{bmatrix}\text{.}
\end{equation*}
</div>
</div></li>
<li id="li-4935"><div class="para logical" id="p-7176">
<div class="para">We have <span class="process-math">\(A^T = (B^TB)^T = B^T(B^T)^T=B^TB = A\)</span> so <span class="process-math">\(A\)</span> must be symmetric.  Then we find the orthogonal diagonalization</div>
<div class="displaymath process-math">
\begin{equation*}
D = \begin{bmatrix}
7 \amp 0 \amp 0 \\
0 \amp 3 \amp 0 \\
0 \amp 0 \amp 0 \\
\end{bmatrix},
\hspace{24pt}
Q = \begin{bmatrix}
2/\sqrt{14} \amp 2/\sqrt{6} \amp 1/\sqrt{21} \\
1/\sqrt{14} \amp -1/\sqrt{6} \amp 4/\sqrt{21} \\
3/\sqrt{14} \amp -1/\sqrt{6} \amp -2/\sqrt{21} \\
\end{bmatrix}\text{.}
\end{equation*}
</div>
</div></li>
</ol></div></div></div>
</div></article><div class="para logical" id="p-7182">
<div class="para">As the examples in <a href="" class="xref" data-knowl="./knowl/activity-orthog-diag.html" title="Activity 7.1.3">Activity¬†7.1.3</a> illustrate, the Spectral Theorem implies a number of things. Namely, if <span class="process-math">\(A\)</span> is a symmetric <span class="process-math">\(m\by m\)</span> matrix, then</div>
<ul class="disc">
<li id="li-4940"><div class="para" id="p-7183">the eigenvalues of <span class="process-math">\(A\)</span> are real.</div></li>
<li id="li-4941"><div class="para" id="p-7184">there is a basis of <span class="process-math">\(\real^m\)</span> consisting of eigenvectors.</div></li>
<li id="li-4942"><div class="para" id="p-7185">two eigenvectors that are associated to different eigenvalues are orthogonal.</div></li>
</ul>
</div>
<div class="para logical" id="p-7186">
<div class="para">We won‚Äôt justify the first two facts here since that would take us rather far afield.  However, it will be helpful to explain the third fact.  To begin, notice the following:</div>
<div class="displaymath process-math">
\begin{equation*}
\vvec\cdot(A\wvec) = \vvec^TA\wvec = (A^T\vvec)^T\wvec =
(A^T\vvec)\cdot \wvec.
\end{equation*}
</div>
<div class="para">This is a useful fact that we‚Äôll employ quite a bit in the future so let‚Äôs summarize it in the following proposition.</div>
</div>
<article class="proposition theorem-like" id="prop-symmetric-dot"><h4 class="heading">
<span class="type">Proposition</span><span class="space"> </span><span class="codenumber">7.1.10</span><span class="period">.</span>
</h4>
<div class="para logical" id="p-7187">
<div class="para">For any matrix <span class="process-math">\(A\text{,}\)</span> we have</div>
<div class="displaymath process-math">
\begin{equation*}
\vvec\cdot(A\wvec) = (A^T\vvec)\cdot\wvec.
\end{equation*}
</div>
<div class="para">In particular, if <span class="process-math">\(A\)</span> is symmetric, then</div>
<div class="displaymath process-math">
\begin{equation*}
\vvec\cdot(A\wvec) = (A\vvec)\cdot\wvec.
\end{equation*}
</div>
</div></article><article class="example example-like" id="example-76"><h4 class="heading">
<span class="type">Example</span><span class="space"> </span><span class="codenumber">7.1.11</span><span class="period">.</span>
</h4>
<div class="para logical" id="p-7188">
<div class="para">Suppose a symmetric matrix <span class="process-math">\(A\)</span> has eigenvectors <span class="process-math">\(\vvec_1\text{,}\)</span> with associated eigenvalue <span class="process-math">\(\lambda_1=3\text{,}\)</span> and <span class="process-math">\(\vvec_2\text{,}\)</span> with associated eigenvalue <span class="process-math">\(\lambda_2 = 10\text{.}\)</span>  Notice that</div>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/prop-symmetric-dot.html" id="md-25">
\begin{align*}
(A\vvec_1)\cdot\vvec_2 \amp = 3\vvec_1\cdot\vvec_2\\
\vvec_1\cdot(A\vvec_2) \amp = 10\vvec_1\cdot\vvec_2.
\end{align*}
</div>
<div class="para">Since <span class="process-math">\((A\vvec_1)\cdot\vvec_2 = \vvec_1\cdot(A\vvec_2)\)</span> by <a href="" class="xref" data-knowl="./knowl/prop-symmetric-dot.html" title="Proposition 7.1.10">Proposition¬†7.1.10</a>, we have</div>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/prop-symmetric-dot.html">
\begin{equation*}
3\vvec_1\cdot\vvec_2 = 10 \vvec_1\cdot\vvec_2,
\end{equation*}
</div>
<div class="para">which can only happen if <span class="process-math">\(\vvec_1\cdot\vvec_2 = 0\text{.}\)</span> Therefore, <span class="process-math">\(\vvec_1\)</span> and <span class="process-math">\(\vvec_2\)</span> are orthogonal.</div>
</div> <div class="para" id="p-7189">More generally, the same argument shows that any two eigenvectors of any symmetric matrix associated to distinct eigenvalues must be orthogonal.</div></article><article class="proposition theorem-like" id="prop-symmetric-implies-orthogonal-eigenvectors"><h4 class="heading">
<span class="type">Proposition</span><span class="space"> </span><span class="codenumber">7.1.12</span><span class="period">.</span>
</h4>
<div class="para" id="p-7190">If <span class="process-math">\(A\)</span> is symmetric, then any pair of eigenvectors for <span class="process-math">\(A\)</span> with distinct eigenvalues  are orthogonal.</div> <div class="para" id="p-7191">That is, if <span class="process-math">\(\vvec_1\)</span> and <span class="process-math">\(\vvec_2\)</span> are  eigenvectors associated with distinct eigenvalues <span class="process-math">\(\lambda_1 \neq lambda_2\text{,}\)</span> then <span class="process-math">\(\vvec \perp \vvec_2\text{.}\)</span>
</div></article></section><section class="subsection" id="subsection-114"><h3 class="heading hide-type">
<span class="type">Subsection</span> <span class="codenumber">7.1.2</span> <span class="title">Variance</span>
</h3>
<div class="para" id="p-7192">Many of the ideas we‚Äôll encounter in this chapter, such as orthogonal diagonalizations, can be applied to the study of data.  In fact, it can be useful to understand these applications because they provide an important context in which mathematical ideas have a more concrete meaning and their motivation appears more clearly.  For that reason, we will now introduce the statistical concept of variance as a way to gain insight into the significance of orthogonal diagonalizations.</div>
<div class="para" id="p-7193">Given a set of data points, their variance measures how spread out the points are.  The next activity looks at some examples.</div>
<article class="activity project-like" id="activity-90"><h4 class="heading">
<span class="type">Activity</span><span class="space"> </span><span class="codenumber">7.1.4</span><span class="period">.</span>
</h4>
<div class="para logical" id="p-7194">
<div class="para">We‚Äôll begin with a set of three data points</div>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/fig-variance-data.html ./knowl/fig-variance-demeaned.html ./knowl/fig-variance-projection.html ./knowl/fig-variance-projection-2.html">
\begin{equation*}
\dvec_1=\twovec11, \hspace{24pt}
\dvec_2=\twovec21, \hspace{24pt}
\dvec_3=\twovec34.
\end{equation*}
</div>
<ol class="lower-alpha">
<li id="li-4943">
<div class="para" id="p-7195">Find the centroid, or mean, <span class="process-math">\(\overline{\dvec} =
\frac1N\sum_j \dvec_j\text{.}\)</span>  Then plot the data points and their centroid in <a href="" class="xref" data-knowl="./knowl/fig-variance-data.html" title="Figure 7.1.13">Figure¬†7.1.13</a>.</div>
<figure class="figure figure-like" id="fig-variance-data"><div class="sidebyside"><div class="sbsrow" style="margin-left:25%;margin-right:25%;"><div class="sbspanel top" style="width:100%;"><img src="external/images/empty-4.svg" role="img" class="contained"></div></div></div>
<figcaption><span class="type">Figure</span><span class="space"> </span><span class="codenumber">7.1.13<span class="period">.</span></span><span class="space"> </span>Plot the data points and their centroid here.</figcaption></figure>
</li>
<li id="li-4944">
<div class="para logical" id="p-7196">
<div class="para">Notice that the centroid lies in the center of the data so the spread of the data will be measured by how far away the points are from the centroid.  To simplify our calculations, find the demeaned data points</div>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/fig-variance-demeaned.html">
\begin{equation*}
\dtil_j = \dvec_j - \overline{\dvec}
\end{equation*}
</div>
<div class="para">and plot them in <a href="" class="xref" data-knowl="./knowl/fig-variance-demeaned.html" title="Figure 7.1.14">Figure¬†7.1.14</a>.</div>
</div>
<figure class="figure figure-like" id="fig-variance-demeaned"><div class="sidebyside"><div class="sbsrow" style="margin-left:25%;margin-right:25%;"><div class="sbspanel top" style="width:100%;"><img src="external/images/empty-4.svg" role="img" class="contained"></div></div></div>
<figcaption><span class="type">Figure</span><span class="space"> </span><span class="codenumber">7.1.14<span class="period">.</span></span><span class="space"> </span>Plot the demeaned data points <span class="process-math">\(\dtil_j\)</span> here.</figcaption></figure>
</li>
<li id="li-4945"><div class="para logical" id="p-7197">
<div class="para">Now that the data has been demeaned, we will define the total variance as the average of the squares of the distances from the origin; that is, the total variance is</div>
<div class="displaymath process-math">
\begin{equation*}
V = \frac 1N\sum_j~|\dtil_j|^2.
\end{equation*}
</div>
<div class="para">Find the total variance <span class="process-math">\(V\)</span> for our set of three points.</div>
</div></li>
<li id="li-4946">
<div class="para" id="p-7198">Now plot the projections of the demeaned data onto the <span class="process-math">\(x\)</span> and <span class="process-math">\(y\)</span> axes using <a href="" class="xref" data-knowl="./knowl/fig-variance-projection.html" title="Figure 7.1.15">Figure¬†7.1.15</a> and find the variances <span class="process-math">\(V_x\)</span> and <span class="process-math">\(V_y\)</span> of the projected points.</div>
<figure class="figure figure-like" id="fig-variance-projection"><div class="sidebyside"><div class="sbsrow" style="margin-left:2.5%;margin-right:2.5%;">
<div class="sbspanel top" style="width:47.3684210526316%;"><img src="external/images/x-axis-4.svg" role="img" class="contained"></div>
<div class="sbspanel top" style="width:47.3684210526316%;"><img src="external/images/y-axis-4.svg" role="img" class="contained"></div>
</div></div>
<figcaption><span class="type">Figure</span><span class="space"> </span><span class="codenumber">7.1.15<span class="period">.</span></span><span class="space"> </span>Plot the projections of the demeaned data onto the <span class="process-math">\(x\)</span> and <span class="process-math">\(y\)</span> axes.</figcaption></figure>
</li>
<li id="li-4947"><div class="para" id="p-7199">Which of the variances, <span class="process-math">\(V_x\)</span> and <span class="process-math">\(V_y\text{,}\)</span> is larger and how does the plot of the projected points explain your response?</div></li>
<li id="li-4948"><div class="para" id="p-7200">What do you notice about the relationship between <span class="process-math">\(V\text{,}\)</span> <span class="process-math">\(V_x\text{,}\)</span> and <span class="process-math">\(V_y\text{?}\)</span>  How does the Pythagorean theorem explain this relationship?</div></li>
<li id="li-4949">
<div class="para" id="p-7201">Plot the projections of the demeaned data points onto the lines defined by vectors <span class="process-math">\(\vvec_1=\twovec11\)</span> and <span class="process-math">\(\vvec_2=\twovec{-1}1\)</span> using <a href="" class="xref" data-knowl="./knowl/fig-variance-projection-2.html" title="Figure 7.1.16">Figure¬†7.1.16</a> and find the variances <span class="process-math">\(V_{\vvec_1}\)</span> and <span class="process-math">\(V_{\vvec_2}\)</span> of these projected points.</div>
<figure class="figure figure-like" id="fig-variance-projection-2"><div class="sidebyside"><div class="sbsrow" style="margin-left:25%;margin-right:25%;"><div class="sbspanel top" style="width:100%;"><img src="external/images/empty-4-diag.svg" role="img" class="contained"></div></div></div>
<figcaption><span class="type">Figure</span><span class="space"> </span><span class="codenumber">7.1.16<span class="period">.</span></span><span class="space"> </span>Plot the projections of the deameaned data onto the lines defined by <span class="process-math">\(\vvec_1\)</span> and <span class="process-math">\(\vvec_2\text{.}\)</span></figcaption></figure>
</li>
<li id="li-4950"><div class="para" id="p-7202">What is the relationship between the total variance <span class="process-math">\(V\)</span> and <span class="process-math">\(V_{\vvec_1}\)</span> and <span class="process-math">\(V_{\vvec_2}\text{?}\)</span> How does the Pythagorean theorem explain your response?</div></li>
</ol>
</div>
<div class="solutions">
<a href="" data-knowl="" class="id-ref answer-knowl original" data-refid="hk-answer-288" id="answer-288"><span class="type">Answer</span><span class="period">.</span></a><div class="hidden-content tex2jax_ignore" id="hk-answer-288"><div class="answer solution-like"><div class="para logical" id="p-7212"><ol class="lower-alpha">
<li id="li-4958"><div class="para" id="p-7213"><span class="process-math">\(\overline{d} = \twovec22\text{.}\)</span></div></li>
<li id="li-4959"><div class="para logical" id="p-7214"><div class="displaymath process-math">
\begin{equation*}
\dtil_1=\twovec{-1}{-1},\hspace{24pt}
\dtil_2=\twovec{0}{-1},\hspace{24pt}
\dtil_3=\twovec{1}{2}\text{.}
\end{equation*}
</div></div></li>
<li id="li-4960"><div class="para" id="p-7215"><span class="process-math">\(V=8/3\text{.}\)</span></div></li>
<li id="li-4961"><div class="para" id="p-7216">
<span class="process-math">\(V_x = 2/3\)</span> and <span class="process-math">\(V_y=2\)</span>
</div></li>
<li id="li-4962"><div class="para" id="p-7217"><span class="process-math">\(\displaystyle V=V_x+V_y\)</span></div></li>
<li id="li-4963">
<div class="para" id="p-7218"><span class="process-math">\(V_{\vvec_1} = 7/3\)</span></div>
<div class="para" id="p-7219"><span class="process-math">\(V_{\vvec_2} = 1/3\)</span></div>
</li>
<li id="li-4964"><div class="para" id="p-7220"><span class="process-math">\(\displaystyle V = V_{\vvec_1} + V_{\vvec_2}\)</span></div></li>
</ol></div></div></div>
<a href="" data-knowl="" class="id-ref solution-knowl original" data-refid="hk-solution-366" id="solution-366"><span class="type">Solution</span><span class="period">.</span></a><div class="hidden-content tex2jax_ignore" id="hk-solution-366"><div class="solution solution-like"><div class="para logical" id="p-7203"><ol class="lower-alpha">
<li id="li-4951"><div class="para" id="p-7204">The centroid is <span class="process-math">\(\overline{d} = \twovec22\text{.}\)</span>
</div></li>
<li id="li-4952"><div class="para logical" id="p-7205">
<div class="para">The demeaned data points are</div>
<div class="displaymath process-math">
\begin{equation*}
\dtil_1=\twovec{-1}{-1},\hspace{24pt}
\dtil_2=\twovec{0}{-1},\hspace{24pt}
\dtil_3=\twovec{1}{2}\text{.}
\end{equation*}
</div>
</div></li>
<li id="li-4953"><div class="para" id="p-7206">The total variance is <span class="process-math">\(V=8/3\text{.}\)</span>
</div></li>
<li id="li-4954"><div class="para" id="p-7207">We find <span class="process-math">\(V_x = 2/3\)</span> and <span class="process-math">\(V_y=2\text{.}\)</span>  Notice that <span class="process-math">\(V_y\)</span> is larger because the points are more spread out in the vertical direction.</div></li>
<li id="li-4955"><div class="para" id="p-7208">We have <span class="process-math">\(V=V_x+V_y\)</span> due to the Pythagorean theorem.</div></li>
<li id="li-4956">
<div class="para" id="p-7209">The points projected onto the line defined by <span class="process-math">\(\vvec_1\)</span> are <span class="process-math">\(\twovec{-1}{-1}\text{,}\)</span> <span class="process-math">\(\twovec{-1/2}{-1/2}\text{,}\)</span> and <span class="process-math">\(\twovec{3/2}{3/2}\text{.}\)</span>  This gives the variance <span class="process-math">\(V_{\vvec_1} = 7/3\text{.}\)</span>
</div>
<div class="para" id="p-7210">The points projected onto the line defined by <span class="process-math">\(\vvec_2\)</span> are <span class="process-math">\(\twovec{0}{0}\text{,}\)</span> <span class="process-math">\(\twovec{1/2}{-1/2}\text{,}\)</span> and <span class="process-math">\(\twovec{-1/2}{1/2}\text{.}\)</span>  This gives the variance <span class="process-math">\(V_{\vvec_2} = 1/3\text{.}\)</span>
</div>
</li>
<li id="li-4957"><div class="para" id="p-7211">Once again, <span class="process-math">\(V = V_{\vvec_1} + V_{\vvec_2}\)</span> because of the Pythagorean theorem.</div></li>
</ol></div></div></div>
</div></article><div class="para logical" id="p-7221">
<div class="para">Notice that variance enjoys an additivity property.  Consider, for instance, the situation where our data points are two-dimensional and suppose that the demeaned points are <span class="process-math">\(\dtil_j=\twovec{\widetilde{x}_j}{\widetilde{y}_j}\text{.}\)</span>  We have</div>
<div class="displaymath process-math">
\begin{equation*}
|\dtil_j|^2 = \widetilde{x}_j^2 + \widetilde{y}_j^2.
\end{equation*}
</div>
<div class="para">If we take the average over all data points, we find that the total variance <span class="process-math">\(V\)</span> is the sum of the variances in the <span class="process-math">\(x\)</span> and <span class="process-math">\(y\)</span> directions:</div>
<div class="displaymath process-math" id="md-26">
\begin{align*}
\frac1N \sum_j~ |\dtil_j|^2 \amp =
\frac1N \sum_j~ \widetilde{x}_j^2 + 
\frac1N \sum_j~ \widetilde{y}_j^2 \\
V \amp = V_x + V_y.
\end{align*}
</div>
</div>
<div class="para logical" id="p-7222">
<div class="para">More generally, suppose that we have an orthonormal basis <span class="process-math">\(\uvec_1\)</span> and <span class="process-math">\(\uvec_2\text{.}\)</span>  If we project the demeaned points onto the line defined by <span class="process-math">\(\uvec_1\text{,}\)</span> we obtain the points <span class="process-math">\((\dtil_j\cdot\uvec_1)\uvec_1\)</span> so that</div>
<div class="displaymath process-math">
\begin{equation*}
V_{\uvec_1} = \frac1N\sum_j
~|(\dtil_j\cdot\uvec_1)~\uvec_1|^2 =
\frac1N~(\dtil_j\cdot\uvec_1)^2.
\end{equation*}
</div>
</div>
<div class="para logical" id="p-7223">
<div class="para">For each of our demeaned data points, the Projection Formula tells us that</div>
<div class="displaymath process-math">
\begin{equation*}
\dtil_j = (\dtil_j\cdot\uvec_1)~\uvec_1 + 
(\dtil_j\cdot\uvec_2)~\uvec_2.
\end{equation*}
</div>
<div class="para">We then have</div>
<div class="displaymath process-math">
\begin{equation*}
|\dtil_j|^2 = \dtil_j\cdot\dtil_j =
(\dtil_j\cdot\uvec_1)^2 + (\dtil_j\cdot\uvec_2)^2
\end{equation*}
</div>
<div class="para">since <span class="process-math">\(\uvec_1\cdot\uvec_2 = 0\text{.}\)</span>  When we average over all the data points, we find that the total variance <span class="process-math">\(V\)</span> is the sum of the variances in the <span class="process-math">\(\uvec_1\)</span> and <span class="process-math">\(\uvec_2\)</span> directions.  This leads to the following proposition, in which this observation is expressed more generally.</div>
</div>
<article class="proposition theorem-like" id="prop-variance-additivity"><h4 class="heading">
<span class="type">Proposition</span><span class="space"> </span><span class="codenumber">7.1.17</span><span class="period">.</span><span class="space"> </span><span class="title">Additivity of Variance.</span>
</h4>
<div class="para logical" id="p-7224">
<div class="para">If <span class="process-math">\(W\)</span> is a subspace with orthonormal basis <span class="process-math">\(\uvec_1,\uvec_2,\ldots, \uvec_n\text{,}\)</span> then the variance of the points projected onto <span class="process-math">\(W\)</span> is the sum of the variances in the <span class="process-math">\(\uvec_j\)</span> directions:</div>
<div class="displaymath process-math">
\begin{equation*}
V_W = V_{\uvec_1} + V_{\uvec_2} + \ldots + V_{\uvec_n}.
\end{equation*}
</div>
</div></article><div class="para" id="p-7225">The next activity demonstrates a more efficient way to find the variance <span class="process-math">\(V_{\uvec}\)</span> in a particular direction and connects our discussion of variance with symmetric matrices.</div>
<article class="activity project-like" id="activity-91"><h4 class="heading">
<span class="type">Activity</span><span class="space"> </span><span class="codenumber">7.1.5</span><span class="period">.</span>
</h4>
<div class="para logical" id="p-7226">
<div class="para">Let‚Äôs return to the dataset from the previous activity in which we have demeaned data points:</div>
<div class="displaymath process-math">
\begin{equation*}
\dtil_1=\twovec{-1}{-1},\hspace{24pt}
\dtil_2=\twovec{0}{-1},\hspace{24pt}
\dtil_3=\twovec{1}{2}.
\end{equation*}
</div>
<div class="para">Our goal is to compute the variance <span class="process-math">\(V_{\uvec}\)</span> in the direction defined by a unit vector <span class="process-math">\(\uvec\text{.}\)</span>
</div>
</div> <div class="para logical" id="p-7227">
<div class="para">To begin, form the demeaned data matrix</div>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/prop-symmetric-dot.html">
\begin{equation*}
A = \begin{bmatrix}
\dtil_1 \amp \dtil_2 \amp \dtil_3
\end{bmatrix}
\end{equation*}
</div>
<div class="para">and suppose that <span class="process-math">\(\uvec\)</span> is a unit vector.</div>
<ol class="lower-alpha">
<li id="li-4965"><div class="para" id="p-7228">Write the vector <span class="process-math">\(A^T\uvec\)</span> in terms of the dot products <span class="process-math">\(\dtil_j\cdot\uvec\text{.}\)</span>
</div></li>
<li id="li-4966"><div class="para" id="p-7229">Explain why <span class="process-math">\(V_{\uvec} = \frac13|A^T\uvec|^2\text{.}\)</span>
</div></li>
<li id="li-4967"><div class="para logical" id="p-7230">
<div class="para">Apply <a href="" class="xref" data-knowl="./knowl/prop-symmetric-dot.html" title="Proposition 7.1.10">Proposition¬†7.1.10</a> to explain why</div>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/prop-symmetric-dot.html">
\begin{equation*}
V_{\uvec} =
\frac13|A^T\uvec|^2 = 
\frac13 (A^T\uvec)\cdot(A^T\uvec) =
\uvec^T\left(\frac13 AA^T\right)\uvec = 
\uvec\cdot\left(\frac13 AA^T\right)\uvec = 
\end{equation*}
</div>
</div></li>
<li id="li-4968"><div class="para" id="p-7231">In general, the matrix <span class="process-math">\(C=\frac1N~AA^T\)</span> is called the <dfn class="terminology">covariance matrix</dfn> of the dataset, and it is useful because the variance <span class="process-math">\(V_{\uvec} = \uvec\cdot(C\uvec)\text{,}\)</span> as we have just seen.  Find the matrix <span class="process-math">\(C\)</span> for our dataset with three points. <pre class="ptx-sagecell sagecell-python" id="sage-223"><script type="text/x-sage">
</script></pre>
</div></li>
<li id="li-4969"><div class="para" id="p-7232">Use the covariance matrix to find the variance <span class="process-math">\(V_{\uvec_1}\)</span> when <span class="process-math">\(\uvec_1=\twovec{1/\sqrt{5}}{2/\sqrt{5}}\text{.}\)</span>
</div></li>
<li id="li-4970"><div class="para" id="p-7233">Use the covariance matrix to find the variance <span class="process-math">\(V_{\uvec_2}\)</span> when <span class="process-math">\(\uvec_2=\twovec{-2/\sqrt{5}}{1/\sqrt{5}}\text{.}\)</span> Since <span class="process-math">\(\uvec_1\)</span> and <span class="process-math">\(\uvec_2\)</span> are orthogonal, verify that the sum of <span class="process-math">\(V_{\uvec_1}\)</span> and <span class="process-math">\(V_{\uvec_2}\)</span> gives the total variance.</div></li>
<li id="li-4971"><div class="para" id="p-7234">Explain why the covariance matrix <span class="process-math">\(C\)</span> is a symmetric matrix.</div></li>
</ol>
</div>
<div class="solutions">
<a href="" data-knowl="" class="id-ref answer-knowl original" data-refid="hk-answer-289" id="answer-289"><span class="type">Answer</span><span class="period">.</span></a><div class="hidden-content tex2jax_ignore" id="hk-answer-289"><div class="answer solution-like"><div class="para logical" id="p-7242"><ol class="lower-alpha">
<li id="li-4979"><div class="para" id="p-7243"><span class="process-math">\(\displaystyle A^T\uvec=\threevec{\dtil_1\cdot\uvec}
{\dtil_2\cdot\uvec}
{\dtil_3\cdot\uvec}\)</span></div></li>
<li id="li-4980"><div class="para logical" id="p-7244"><div class="displaymath process-math">
\begin{equation*}
V_{\uvec} = \frac13\left((\dtil_1\cdot\uvec)^2 +
(\dtil_2\cdot\uvec)^2 + (\dtil_3\cdot\uvec)^2\right)
= \frac13|A^T\uvec|^2\text{.}
\end{equation*}
</div></div></li>
<li id="li-4981"><div class="para logical" id="p-7245"><div class="displaymath process-math">
\begin{equation*}
\frac13(A^T\uvec)\cdot(A^T\uvec) =
\frac13\uvec\cdot(A^T)^TA^T\uvec =
\uvec\cdot\left(\frac13AA^T\right)\uvec
\end{equation*}
</div></div></li>
<li id="li-4982"><div class="para" id="p-derived-li-4982"><span class="process-math">\(\displaystyle C=\begin{bmatrix}
2/3 \amp 1 \\
1 \amp 2
\end{bmatrix}\)</span></div></li>
<li id="li-4983"><div class="para" id="p-7246"><span class="process-math">\(\displaystyle V_{\uvec_1} = 38/15\)</span></div></li>
<li id="li-4984"><div class="para" id="p-7247"><span class="process-math">\(V_{\uvec_2} = 2/15\text{.}\)</span></div></li>
<li id="li-4985"><div class="para" id="p-7248"><span class="process-math">\(\displaystyle C^T = \left(\frac13 AA^T\right)^T = \frac13(A^T)^TA^T
= \frac13 AA^T = C\)</span></div></li>
</ol></div></div></div>
<a href="" data-knowl="" class="id-ref solution-knowl original" data-refid="hk-solution-367" id="solution-367"><span class="type">Solution</span><span class="period">.</span></a><div class="hidden-content tex2jax_ignore" id="hk-solution-367"><div class="solution solution-like"><div class="para logical" id="p-7235"><ol class="lower-alpha">
<li id="li-4972"><div class="para" id="p-7236"><span class="process-math">\(\displaystyle A^T\uvec=\threevec{\dtil_1\cdot\uvec}
{\dtil_2\cdot\uvec}
{\dtil_3\cdot\uvec}\)</span></div></li>
<li id="li-4973"><div class="para logical" id="p-7237">
<div class="para">Projecting <span class="process-math">\(\dtil_j\)</span> onto <span class="process-math">\(\uvec\)</span> gives <span class="process-math">\((\dtil_j\cdot\uvec)\uvec\text{,}\)</span> whose length squared is <span class="process-math">\((\dtil_j\cdot\uvec)^2\text{.}\)</span>  Then</div>
<div class="displaymath process-math">
\begin{equation*}
V_{\uvec} = \frac13\left((\dtil_1\cdot\uvec)^2 +
(\dtil_2\cdot\uvec)^2 + (\dtil_3\cdot\uvec)^2\right)
= \frac13|A^T\uvec|^2\text{.}
\end{equation*}
</div>
</div></li>
<li id="li-4974"><div class="para logical" id="p-7238"><div class="displaymath process-math">
\begin{equation*}
\frac13(A^T\uvec)\cdot(A^T\uvec) =
\frac13\uvec\cdot(A^T)^TA^T\uvec =
\uvec\cdot\left(\frac13AA^T\right)\uvec
\end{equation*}
</div></div></li>
<li id="li-4975"><div class="para" id="p-derived-li-4975"><span class="process-math">\(\displaystyle C=\begin{bmatrix}
2/3 \amp 1 \\
1 \amp 2
\end{bmatrix}\)</span></div></li>
<li id="li-4976"><div class="para" id="p-7239"><span class="process-math">\(\displaystyle V_{\uvec_1} = 38/15\)</span></div></li>
<li id="li-4977"><div class="para" id="p-7240">
<span class="process-math">\(V_{\uvec_2} = 2/15\text{.}\)</span>  Then <span class="process-math">\(V_{\uvec_1}+V_{\uvec_2} = 8/3\text{,}\)</span> which is the total variance.</div></li>
<li id="li-4978"><div class="para" id="p-7241"><span class="process-math">\(\displaystyle C^T = \left(\frac13 AA^T\right)^T = \frac13(A^T)^TA^T
= \frac13 AA^T = C\)</span></div></li>
</ol></div></div></div>
</div></article><div class="para logical" id="p-7249">
<div class="para">This activity introduced the covariance matrix of a dataset, which is defined to be <span class="process-math">\(C=\frac1N~AA^T\)</span> where <span class="process-math">\(A\)</span> is the matrix of demeaned data points.  Notice that</div>
<div class="displaymath process-math">
\begin{equation*}
C^T = \frac1N~(AA^T)^T = \frac1N~AA^T = C,
\end{equation*}
</div>
<div class="para">which tells us that <span class="process-math">\(C\)</span> is symmetric.  In particular, we know that it is orthogonally diagonalizable, an observation that will play an important role in the future.</div>
</div>
<div class="para" id="p-7250">This activity also demonstrates the significance of the covariance matrix, which is recorded in the following proposition.</div>
<article class="proposition theorem-like" id="prop-covariance"><h4 class="heading">
<span class="type">Proposition</span><span class="space"> </span><span class="codenumber">7.1.18</span><span class="period">.</span>
</h4>
<div class="para logical" id="p-7251">
<div class="para">If <span class="process-math">\(C\)</span> is the covariance matrix associated to a demeaned dataset and <span class="process-math">\(\uvec\)</span> is a unit vector, then the variance of the demeaned points projected onto the line defined by <span class="process-math">\(\uvec\)</span> is</div>
<div class="displaymath process-math">
\begin{equation*}
V_{\uvec} = \uvec\cdot C\uvec.
\end{equation*}
</div>
</div></article><div class="para" id="p-7252">Our goal in the future will be to find directions <span class="process-math">\(\uvec\)</span> where the variance is as large as possible and directions where it is as small as possible.  The next activity demonstrates why this is useful.</div>
<article class="activity project-like" id="activity-92"><h4 class="heading">
<span class="type">Activity</span><span class="space"> </span><span class="codenumber">7.1.6</span><span class="period">.</span>
</h4>
<div class="para logical" id="p-7253"><ol class="lower-alpha">
<li id="li-4986">
<div class="para" id="p-7254">Evaluating the following Sage cell loads a dataset consisting of 100 demeaned data points and provides a plot of them.  It also provides the demeaned data matrix <span class="process-math">\(A\text{.}\)</span> <pre class="ptx-sagecell sagecell-python" id="sage-224"><script type="text/x-sage">import pandas as pd
df = pd.read_csv('https://raw.githubusercontent.com/davidaustinm/ula_modules/master/data/variance-data.csv', header=None)
data = [vector(row) for row in df.values]
A = matrix(data).T
list_plot(data, size=20, color='blue', aspect_ratio=1)
</script></pre>
</div>
<div class="para" id="p-7255">What is the shape of the covariance matrix <span class="process-math">\(C\text{?}\)</span>  Find <span class="process-math">\(C\)</span> and verify your response. <pre class="ptx-sagecell sagecell-python" id="sage-225"><script type="text/x-sage">
</script></pre>
</div>
</li>
<li id="li-4987"><div class="para" id="p-7256">By visually inspecting the data, determine which is larger, <span class="process-math">\(V_x\)</span> or <span class="process-math">\(V_y\text{.}\)</span>  Then compute both of these quantities to verify your response.</div></li>
<li id="li-4988"><div class="para" id="p-7257">What is the total variance <span class="process-math">\(V\text{?}\)</span>
</div></li>
<li id="li-4989"><div class="para" id="p-7258">In approximately what direction is the variance greatest?  Choose a reasonable vector <span class="process-math">\(\uvec\)</span> that points in approximately that direction and find <span class="process-math">\(V_{\uvec}\text{.}\)</span>
</div></li>
<li id="li-4990"><div class="para" id="p-7259">In approximately what direction is the variance smallest?  Choose a reasonable vector <span class="process-math">\(\wvec\)</span> that points in approximately that direction and find <span class="process-math">\(V_{\wvec}\text{.}\)</span>
</div></li>
<li id="li-4991"><div class="para" id="p-7260">How are the directions <span class="process-math">\(\uvec\)</span> and <span class="process-math">\(\wvec\)</span> in the last two parts of this problem related to one another?  Why does this relationship hold?</div></li>
</ol></div>
<div class="solutions">
<a href="" data-knowl="" class="id-ref answer-knowl original" data-refid="hk-answer-290" id="answer-290"><span class="type">Answer</span><span class="period">.</span></a><div class="hidden-content tex2jax_ignore" id="hk-answer-290"><div class="answer solution-like"><div class="para logical" id="p-7268"><ol class="lower-alpha">
<li id="li-4998"><div class="para" id="p-7269"><span class="process-math">\(\displaystyle C=\begin{bmatrix}
1.38 \amp 0.70 \\
0.70 \amp 0.37
\end{bmatrix}\)</span></div></li>
<li id="li-4999"><div class="para" id="p-7270">
<span class="process-math">\(V_x = 1.38\)</span> and <span class="process-math">\(V_y=0.37\)</span>
</div></li>
<li id="li-5000"><div class="para" id="p-7271"><span class="process-math">\(\displaystyle V=1.75\)</span></div></li>
<li id="li-5001"><div class="para" id="p-7272">If <span class="process-math">\(\uvec_1=\twovec{2/\sqrt{5}}{1/\sqrt{5}}\text{,}\)</span> then <span class="process-math">\(V_{\uvec_1} = 1.74\text{.}\)</span>
</div></li>
<li id="li-5002"><div class="para" id="p-7273">If <span class="process-math">\(\uvec_2=\twovec{-1/\sqrt{5}}{2/\sqrt{5}}\text{,}\)</span> then <span class="process-math">\(V_{\uvec_2} = 0.01\text{.}\)</span>
</div></li>
<li id="li-5003"><div class="para" id="p-7274">They are orthogonal to one another.</div></li>
</ol></div></div></div>
<a href="" data-knowl="" class="id-ref solution-knowl original" data-refid="hk-solution-368" id="solution-368"><span class="type">Solution</span><span class="period">.</span></a><div class="hidden-content tex2jax_ignore" id="hk-solution-368"><div class="solution solution-like"><div class="para logical" id="p-7261"><ol class="lower-alpha">
<li id="li-4992"><div class="para" id="p-7262">
<span class="process-math">\(C\)</span> will be the <span class="process-math">\(2\by2\)</span> matrix <span class="process-math">\(C=\begin{bmatrix}
1.38 \amp 0.70 \\
0.70 \amp 0.37
\end{bmatrix}\)</span>
</div></li>
<li id="li-4993"><div class="para" id="p-7263">
<span class="process-math">\(V_x = 1.38\)</span> and <span class="process-math">\(V_y=0.37\text{,}\)</span> which agrees with the fact that the data is more spread out in the horizontal than vertical direction.</div></li>
<li id="li-4994"><div class="para" id="p-7264"><span class="process-math">\(\displaystyle V=V_x+V_y=1.75\)</span></div></li>
<li id="li-4995"><div class="para" id="p-7265">It looks like the direction <span class="process-math">\(\twovec21\)</span> defined by the unit vector <span class="process-math">\(\uvec_1=\twovec{2/\sqrt{5}}{1/\sqrt{5}}\text{.}\)</span>  We find that <span class="process-math">\(V_{\uvec_1} = 1.74\text{,}\)</span> which is almost all of the total variance.</div></li>
<li id="li-4996"><div class="para" id="p-7266">It looks like the direction <span class="process-math">\(\twovec{-1}{2}\)</span> defined by the unit vector <span class="process-math">\(\uvec_2=\twovec{-1/\sqrt{5}}{2/\sqrt{5}}\text{.}\)</span>  We find that <span class="process-math">\(V_{\uvec_2} = 0.01\text{.}\)</span>
</div></li>
<li id="li-4997"><div class="para" id="p-7267">They are orthogonal to one another.  Since the total variance <span class="process-math">\(V=V_{\uvec_1}+V_{\uvec_2}\)</span> when <span class="process-math">\(\uvec_1\)</span> and <span class="process-math">\(\uvec_2\)</span> are orthogonal, <span class="process-math">\(V_{\uvec_1}\)</span> will be as large as possible when <span class="process-math">\(V_{\uvec_2}\)</span> is as small as possible.</div></li>
</ol></div></div></div>
</div></article><div class="para" id="p-7275">This activity illustrates how variance can identify a line along which the data are concentrated.  When the data primarily lie along a line defined by a vector <span class="process-math">\(\uvec_1\text{,}\)</span> then the variance in that direction will be large while the variance in an orthogonal direction <span class="process-math">\(\uvec_2\)</span> will be small.</div>
<div class="para logical" id="p-7276">
<div class="para">Remember that variance is additive, according to <a href="" class="xref" data-knowl="./knowl/prop-variance-additivity.html" title="Proposition 7.1.17: Additivity of Variance">Proposition¬†7.1.17</a>, so that if <span class="process-math">\(\uvec_1\)</span> and <span class="process-math">\(\uvec_2\)</span> are orthogonal unit vectors, then the total variance is</div>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/prop-variance-additivity.html">
\begin{equation*}
V = V_{\uvec_1} + V_{\uvec_2}.
\end{equation*}
</div>
<div class="para">Therefore, if we choose <span class="process-math">\(\uvec_1\)</span> to be the direction where <span class="process-math">\(V_{\uvec_1}\)</span> is a maximum, then <span class="process-math">\(V_{\uvec_2}\)</span> will be a minimum.</div>
</div>
<div class="para" id="p-7277">In the next section, we will use an orthogonal diagonalization of the covariance matrix <span class="process-math">\(C\)</span> to find the directions having the greatest and smallest variances. In this way, we will be able to determine when data are concentrated along a line or subspace.</div></section><section class="subsection" id="subsection-115"><h3 class="heading hide-type">
<span class="type">Subsection</span> <span class="codenumber">7.1.3</span> <span class="title">Summary</span>
</h3>
<div class="para logical" id="p-7278">
<div class="para">This section explored both symmetric matrices and variance.  In particular, we saw that</div>
<ul class="disc">
<li id="li-5004"><div class="para" id="p-7279">A matrix <span class="process-math">\(A\)</span> is orthogonally diagonalizable if there is an orthonormal basis of eigenvectors.  In particular, we can write <span class="process-math">\(A=QDQ^T\text{,}\)</span> where <span class="process-math">\(D\)</span> is a diagonal matrix of eigenvalues and <span class="process-math">\(Q\)</span> is an orthogonal matrix of eigenvectors.</div></li>
<li id="li-5005"><div class="para" id="p-7280">The Spectral Theorem tells us that a matrix <span class="process-math">\(A\)</span> is orthogonally diagonalizable if and only if it is symmetric;  that is, <span class="process-math">\(A=A^T\text{.}\)</span>
</div></li>
<li id="li-5006"><div class="para" id="p-7281">The variance of a dataset can be computed using the covariance matrix <span class="process-math">\(C=\frac1N~AA^T\text{,}\)</span> where <span class="process-math">\(A\)</span> is the matrix of demeaned data points.  In particular, the variance of the demeaned data points projected onto the line defined by the unit vector <span class="process-math">\(\uvec\)</span> is <span class="process-math">\(V_{\uvec} = \uvec\cdot C\uvec\text{.}\)</span>
</div></li>
<li id="li-5007"><div class="para logical" id="p-7282">
<div class="para">Variance is additive so that if <span class="process-math">\(W\)</span> is a subspace with orthonormal basis <span class="process-math">\(\uvec_1,
\uvec_2,\ldots,\uvec_n\text{,}\)</span> then</div>
<div class="displaymath process-math">
\begin{equation*}
V_W = V_{\uvec_1} + V_{\uvec_2} + \ldots + V_{\uvec_n}.
\end{equation*}
</div>
</div></li>
</ul>
</div></section><section class="exercises" id="exercises-30"><h3 class="heading hide-type">
<span class="type">Exercises</span> <span class="codenumber">7.1.4</span> <span class="title">Exercises</span>
</h3>
<article class="exercise exercise-like" id="exercise-257"><h4 class="heading"><span class="codenumber">1<span class="period">.</span></span></h4>
<div class="para logical" id="p-7283">
<div class="para">For each of the following matrices, find the eigenvalues and a basis for each eigenspace.  Determine whether the matrix is diagonalizable and, if so, find a diagonalization.  Determine whether the matrix is orthogonally diagonalizable and, if so, find an orthogonal diagonalization. <pre class="ptx-sagecell sagecell-sage" id="sage-226"><script type="text/x-sage">
</script></pre>
</div>
<ol class="lower-alpha">
<li id="li-5008"><div class="para" id="p-7284"><span class="process-math">\(\begin{bmatrix}
5 \amp 1 \\
-1 \amp 3 \\
\end{bmatrix}
\text{.}\)</span></div></li>
<li id="li-5009"><div class="para" id="p-7285"><span class="process-math">\(\displaystyle \begin{bmatrix}
0 \amp 1  \\
1 \amp 0 \\
\end{bmatrix}\)</span></div></li>
<li id="li-5010"><div class="para" id="p-7286"><span class="process-math">\(\displaystyle \begin{bmatrix}
1 \amp 0 \amp 0 \\
2 \amp -2 \amp 0 \\
0 \amp 1 \amp 4 \\
\end{bmatrix}\)</span></div></li>
<li id="li-5011"><div class="para" id="p-7287"><span class="process-math">\(\displaystyle \begin{bmatrix}
2 \amp 5 \amp -4\\
5 \amp -7 \amp 5 \\
-4 \amp 5 \amp 2 \\
\end{bmatrix}\)</span></div></li>
</ol>
</div></article><article class="exercise exercise-like" id="exercise-258"><h4 class="heading"><span class="codenumber">2<span class="period">.</span></span></h4>
<div class="para logical" id="p-7298">
<div class="para">Consider the matrix <span class="process-math">\(A = 
\begin{bmatrix}
1 \amp 2 \amp 2 \\
2 \amp 1 \amp 2 \\
2 \amp 2 \amp 1 \\
\end{bmatrix}\)</span> whose eigenvalues are <span class="process-math">\(\lambda_1=5\text{,}\)</span> <span class="process-math">\(\lambda_2=-1\text{,}\)</span> and <span class="process-math">\(\lambda_3 = -1\text{.}\)</span> <pre class="ptx-sagecell sagecell-sage" id="sage-227"><script type="text/x-sage">
</script></pre>
</div>
<ol class="lower-alpha">
<li id="li-5020"><div class="para" id="p-7299">Explain why <span class="process-math">\(A\)</span> is orthogonally diagonalizable.</div></li>
<li id="li-5021"><div class="para" id="p-7300">Find an orthonormal basis for the eigenspace <span class="process-math">\(E_5\text{.}\)</span>
</div></li>
<li id="li-5022"><div class="para" id="p-7301">Find a basis for the eigenspace <span class="process-math">\(E_{-1}\text{.}\)</span>
</div></li>
<li id="li-5023"><div class="para" id="p-7302">Now find an orthonormal basis for <span class="process-math">\(E_{-1}\text{.}\)</span>
</div></li>
<li id="li-5024"><div class="para" id="p-7303">Find matrices <span class="process-math">\(D\)</span> and <span class="process-math">\(Q\)</span> such that <span class="process-math">\(A=QDQ^T\text{.}\)</span>
</div></li>
</ol>
</div></article><article class="exercise exercise-like" id="exercise-259"><h4 class="heading"><span class="codenumber">3<span class="period">.</span></span></h4>
<div class="para logical" id="p-7316">
<div class="para">Find an orthogonal diagonalization, if one exists, for the following matrices. <pre class="ptx-sagecell sagecell-sage" id="sage-228"><script type="text/x-sage">
</script></pre>
</div>
<ol class="lower-alpha">
<li id="li-5035"><div class="para" id="p-7317"><span class="process-math">\(\begin{bmatrix}
11 \amp 4 \amp 12 \\
4 \amp -3 \amp -16 \\
12 \amp -16 \amp 1
\end{bmatrix}
\text{.}\)</span></div></li>
<li id="li-5036"><div class="para" id="p-7318"><span class="process-math">\(\begin{bmatrix}
1 \amp 0 \amp 2 \\
0 \amp 1 \amp 2 \\
-2 \amp -2 \amp 1 \\
\end{bmatrix}
\text{.}\)</span></div></li>
<li id="li-5037"><div class="para" id="p-7319"><span class="process-math">\(\begin{bmatrix}
9 \amp 3 \amp 3 \amp 3\\
3 \amp 9 \amp 3 \amp 3\\
3 \amp 3 \amp 9 \amp 3\\
3 \amp 3 \amp 3 \amp 9\\
\end{bmatrix}
\text{.}\)</span></div></li>
</ol>
</div></article><article class="exercise exercise-like" id="exercise-260"><h4 class="heading"><span class="codenumber">4<span class="period">.</span></span></h4>
<div class="para logical" id="p-7328">
<div class="para">Suppose that <span class="process-math">\(A\)</span> is an <span class="process-math">\(m\by n\)</span> matrix and that <span class="process-math">\(B=A^TA\text{.}\)</span>
</div>
<ol class="lower-alpha">
<li id="li-5044"><div class="para" id="p-7329">Explain why <span class="process-math">\(B\)</span> is orthogonally diagonalizable.</div></li>
<li id="li-5045"><div class="para" id="p-7330">Explain why <span class="process-math">\(\vvec\cdot(B\vvec) = \len{A\vvec}^2\text{.}\)</span>
</div></li>
<li id="li-5046"><div class="para" id="p-7331">Suppose that <span class="process-math">\(\uvec\)</span> is an eigenvector of <span class="process-math">\(B\)</span> with associated eigenvalue <span class="process-math">\(\lambda\)</span> and that <span class="process-math">\(\uvec\)</span> has unit length.  Explain why <span class="process-math">\(\lambda =
\len{A\uvec}^2\text{.}\)</span>
</div></li>
<li id="li-5047"><div class="para" id="p-7332">Explain why the eigenvalues of <span class="process-math">\(B\)</span> are nonnegative.</div></li>
<li id="li-5048"><div class="para" id="p-7333">If <span class="process-math">\(C\)</span> is the covariance matrix associated to a demeaned dataset, explain why the eigenvalues of <span class="process-math">\(C\)</span> are nonnegative.</div></li>
</ol>
</div></article><article class="exercise exercise-like" id="exercise-261"><h4 class="heading"><span class="codenumber">5<span class="period">.</span></span></h4>
<div class="para logical" id="p-7346">
<div class="para">Suppose that you have the data points</div>
<div class="displaymath process-math">
\begin{equation*}
(2,0), (2,3), (4,1), (3,2), (4,4).
\end{equation*}
</div>
<ol class="lower-alpha">
<li id="li-5059"><div class="para" id="p-7347">Find the demeaned data points.</div></li>
<li id="li-5060"><div class="para" id="p-7348">Find the total variance <span class="process-math">\(V\)</span> of the dataset.</div></li>
<li id="li-5061"><div class="para" id="p-7349">Find the variance in the direction <span class="process-math">\(\evec_1 =
\twovec10\)</span> and the variance in the direction <span class="process-math">\(\evec_2=\twovec01\text{.}\)</span>
</div></li>
<li id="li-5062"><div class="para" id="p-7350">Project the demeaned data points onto the line defined by <span class="process-math">\(\vvec_1=\twovec21\)</span> and find the variance of these projected points.</div></li>
<li id="li-5063"><div class="para" id="p-7351">Project the demeaned data points onto the line defined by <span class="process-math">\(\vvec_2=\twovec1{-2}\)</span> and find the variance of these projected points.</div></li>
<li id="li-5064"><div class="para" id="p-7352">How and why are the results of from the last two parts related to the total variance?</div></li>
</ol>
</div></article><article class="exercise exercise-like" id="exercise-262"><h4 class="heading"><span class="codenumber">6<span class="period">.</span></span></h4>
<div class="para logical" id="p-7365">
<div class="para">Suppose you have six 2-dimensional data points arranged in the matrix</div>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/ex-demean-plot.html">
\begin{equation*}
\begin{bmatrix}
2 \amp 0 \amp 4 \amp 4 \amp 5 \amp 3 \\
1 \amp 0 \amp 3 \amp 5 \amp 4 \amp 5
\end{bmatrix}.
\end{equation*}
</div>
<ol class="lower-alpha">
<li id="li-5077"><div class="para" id="p-7366">Find the matrix <span class="process-math">\(A\)</span> of demeaned data points and plot the points in <a href="" class="xref" data-knowl="./knowl/ex-demean-plot.html" title="Figure 7.1.19">Figure¬†7.1.19</a>. <figure class="figure figure-like" id="ex-demean-plot"><div class="sidebyside"><div class="sbsrow" style="margin-left:25%;margin-right:25%;"><div class="sbspanel top" style="width:100%;"><img src="external/images/empty-4.svg" role="img" class="contained"></div></div></div>
<figcaption><span class="type">Figure</span><span class="space"> </span><span class="codenumber">7.1.19<span class="period">.</span></span><span class="space"> </span>A plot for the demeaned data points.</figcaption></figure>
</div></li>
<li id="li-5078"><div class="para" id="p-7367">Construct the covariance matrix <span class="process-math">\(C\)</span> and explain why you know that it is orthogonally diagonalizable.</div></li>
<li id="li-5079"><div class="para" id="p-7368">Find an orthogonal diagonalization of <span class="process-math">\(C\text{.}\)</span>
</div></li>
<li id="li-5080"><div class="para" id="p-7369">Sketch the lines corresponding to the two eigenvectors on the plot above.</div></li>
<li id="li-5081"><div class="para" id="p-7370">Find the variances in the directions of the eigenvectors.</div></li>
</ol>
</div></article><article class="exercise exercise-like" id="exercise-263"><h4 class="heading"><span class="codenumber">7<span class="period">.</span></span></h4>
<div class="para logical" id="p-7383">
<div class="para">Suppose that <span class="process-math">\(C\)</span> is the covariance matrix of a demeaned dataset.</div>
<ol class="lower-alpha">
<li id="li-5092"><div class="para" id="p-7384">Suppose that <span class="process-math">\(\uvec\)</span> is an eigenvector of <span class="process-math">\(C\)</span> with associated eigenvalue <span class="process-math">\(\lambda\)</span> and that <span class="process-math">\(\uvec\)</span> has unit length.  Explain why <span class="process-math">\(V_{\uvec} = \lambda\text{.}\)</span>
</div></li>
<li id="li-5093"><div class="para logical" id="p-7385">
<div class="para">Suppose that the covariance matrix of a demeaned dataset can be written as <span class="process-math">\(C=QDQ^T\)</span> where</div>
<div class="displaymath process-math">
\begin{equation*}
Q = \begin{bmatrix} \uvec_1 \amp \uvec_2 \end{bmatrix},
\hspace{24pt}
D = \begin{bmatrix}
10 \amp 0 \\
0 \amp 0 \\
\end{bmatrix}.
\end{equation*}
</div>
<div class="para">What is <span class="process-math">\(V_{\uvec_2}\text{?}\)</span>  What does this tell you about the demeaned data?</div>
</div></li>
<li id="li-5094"><div class="para" id="p-7386">Explain why the total variance of a dataset equals the sum of the eigenvalues of the covariance matrix.</div></li>
</ol>
</div></article><article class="exercise exercise-like" id="exercise-264"><h4 class="heading"><span class="codenumber">8<span class="period">.</span></span></h4>
<div class="para logical" id="p-7395">
<div class="para">Determine whether the following statements are true or false and explain your thinking.</div>
<ol class="lower-alpha">
<li id="li-5101"><div class="para" id="p-7396">If <span class="process-math">\(A\)</span> is an invertible, orthogonally diagonalizable matrix, then so is <span class="process-math">\(A^{-1}\text{.}\)</span>
</div></li>
<li id="li-5102"><div class="para" id="p-7397">If <span class="process-math">\(\lambda=2+i\)</span> is an eigenvalue of <span class="process-math">\(A\text{,}\)</span> then <span class="process-math">\(A\)</span> cannot be orthogonally diagonalizable.</div></li>
<li id="li-5103"><div class="para" id="p-7398">If there is a basis for <span class="process-math">\(\real^m\)</span> consisting of eigenvectors of <span class="process-math">\(A\text{,}\)</span> then <span class="process-math">\(A\)</span> is orthogonally diagonalizable.</div></li>
<li id="li-5104"><div class="para" id="p-7399">If <span class="process-math">\(\uvec\)</span> and <span class="process-math">\(\vvec\)</span> are eigenvectors of a symmetric matrix associated to eigenvalues -2 and 3, then <span class="process-math">\(\uvec\cdot\vvec=0\text{.}\)</span>
</div></li>
<li id="li-5105"><div class="para" id="p-7400">If <span class="process-math">\(A\)</span> is a square matrix, then <span class="process-math">\(\uvec\cdot(A\vvec) = (A\uvec)\cdot\vvec\text{.}\)</span>
</div></li>
</ol>
</div></article><article class="exercise exercise-like" id="exercise-265"><h4 class="heading"><span class="codenumber">9<span class="period">.</span></span></h4>
<div class="para logical" id="p-7413">
<div class="para">Suppose that <span class="process-math">\(A\)</span> is a noninvertible, symmetric <span class="process-math">\(3\by3\)</span> matrix having eigenvectors</div>
<div class="displaymath process-math">
\begin{equation*}
\vvec_1 = \threevec2{-1}2,\hspace{24pt}
\vvec_2 = \threevec141
\end{equation*}
</div>
<div class="para">and associated eigenvalues <span class="process-math">\(\lambda_1 = 20\)</span> and <span class="process-math">\(\lambda_2 = -4\text{.}\)</span> Find matrices <span class="process-math">\(Q\)</span> and <span class="process-math">\(D\)</span> such that <span class="process-math">\(A =
QDQ^T\text{.}\)</span>
</div>
</div></article><article class="exercise exercise-like" id="exercise-266"><h4 class="heading"><span class="codenumber">10<span class="period">.</span></span></h4>
<div class="para logical" id="p-7416">
<div class="para">Suppose that <span class="process-math">\(W\)</span> is a plane in <span class="process-math">\(\real^3\)</span> and that <span class="process-math">\(P\)</span> is the <span class="process-math">\(3\by3\)</span> matrix that projects vectors orthogonally onto <span class="process-math">\(W\text{.}\)</span>
</div>
<ol class="lower-alpha">
<li id="li-5116"><div class="para" id="p-7417">Explain why <span class="process-math">\(P\)</span> is orthogonally diagonalizable.</div></li>
<li id="li-5117"><div class="para" id="p-7418">What are the eigenvalues of <span class="process-math">\(P\text{?}\)</span>
</div></li>
<li id="li-5118"><div class="para" id="p-7419">Explain the relationship between the eigenvectors of <span class="process-math">\(P\)</span> and the plane <span class="process-math">\(W\text{.}\)</span>
</div></li>
</ol>
</div></article></section></section></div>
<div class="ptx-content-footer">
<a class="previous-button button" href="chap7.html" title="Previous"><span class="icon">&lt;</span><span class="name">Prev</span></a><a class="top-button button" href="#" title="Top"><span class="icon">^</span><span class="name">Top</span></a><a class="next-button button" href="sec-quadratic-forms.html" title="Next"><span class="name">Next</span><span class="icon">&gt;</span></a>
</div></main>
</div>
<div id="ptx-page-footer">
<a class="pretext-link" href="https://pretextbook.org" title="PreTeXt"><div class="logo"><svg xmlns="http://www.w3.org/2000/svg" width="100%" height="100%" viewBox="338 3000 8772 6866"><g style="stroke-width:.025in; stroke:black; fill:none"><polyline points="472,3590 472,9732 " style="stroke:#000000;stroke-width:174; stroke-linejoin:miter; stroke-linecap:round; "></polyline><path style="stroke:#000000;stroke-width:126;stroke-linecap:butt;" d="M 4724,9448 A 4660 4660  0  0  1  8598  9259"></path><path style="stroke:#000000;stroke-width:174;stroke-linecap:butt;" d="M 4488,9685 A 4228 4228  0  0  0   472  9732"></path><path style="stroke:#000000;stroke-width:126;stroke-linecap:butt;" d="M 4724,3590 A 4241 4241  0  0  1  8598  3496"></path><path style="stroke:#000000;stroke-width:126;stroke-linecap:round;" d="M 850,3496  A 4241 4241  0  0  1  4724  3590"></path><path style="stroke:#000000;stroke-width:126;stroke-linecap:round;" d="M 850,9259  A 4507 4507  0  0  1  4724  9448"></path><polyline points="5385,4299 4062,8125" style="stroke:#000000;stroke-width:300; stroke-linejoin:miter; stroke-linecap:round;"></polyline><polyline points="8598,3496 8598,9259" style="stroke:#000000;stroke-width:126; stroke-linejoin:miter; stroke-linecap:round;"></polyline><polyline points="850,3496 850,9259" style="stroke:#000000;stroke-width:126; stroke-linejoin:miter; stroke-linecap:round;"></polyline><polyline points="4960,9685 4488,9685" style="stroke:#000000;stroke-width:174; stroke-linejoin:miter; stroke-linecap:round;"></polyline><polyline points="3070,4582 1889,6141 3070,7700" style="stroke:#000000;stroke-width:300; stroke-linejoin:miter; stroke-linecap:round;"></polyline><polyline points="6418,4582 7600,6141 6418,7700" style="stroke:#000000;stroke-width:300; stroke-linejoin:miter; stroke-linecap:round;"></polyline><polyline points="8976,3590 8976,9732" style="stroke:#000000;stroke-width:174; stroke-linejoin:miter; stroke-linecap:round;"></polyline><path style="stroke:#000000;stroke-width:174;stroke-linecap:butt;" d="M 4960,9685 A 4228 4228  0  0  1  8976  9732"></path></g></svg></div></a><a class="runestone-link" href="https://runestone.academy" title="Runestone Academy"><img class="logo" src="https://runestone.academy/runestone/static/images/RAIcon_cropped.png"></a><a class="mathjax-link" href="https://www.mathjax.org" title="MathJax"><img class="logo" src="https://www.mathjax.org/badge/badge-square-2.png"></a>
</div>
</body>
</html>
