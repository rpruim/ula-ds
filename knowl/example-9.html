<!DOCTYPE html>
<html lang="en-US" dir="ltr">
<!--********************************************-->
<!--*       Generated from PreTeXt source      *-->
<!--*                                          *-->
<!--*         https://pretextbook.org          *-->
<!--*                                          *-->
<!--********************************************-->
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta name="robots" content="noindex, nofollow">
<script>// Make *any* pre with class 'sagecell-python' an executable Sage cell
// Their results will be linked, only within language type
sagecell.makeSagecell({
  "inputLocation": "pre.sagecell-python",
  "linked": true,
  "linkKey": "linked-python",
  "autoeval": false,
  "languages": [
    "python"
  ],
  "evalButtonText": "Evaluate (Python)"
});
</script>
</head>
<body class="ignore-math">
<article class="example example-like"><h4 class="heading">
<span class="type">Example</span><span class="space"> </span><span class="codenumber">1.5.4</span><span class="period">.</span>
</h4>
<div class="para">In scenes were some regions are very bright and others very dark, it can be challenging to create a good exposure over the entire image. Exposure bracketing is a technique that has been used since the 1850’s to help with this situation. This technique involves capturing multiple images, each with a different exposure. Later one can choose the best of the captured images or combine them in some way.  In the 1850’s, Gustave Le Gray printed seascape photos from two images, using one exposure for the sky and the other for the water. Modern HDR methods can combine multiple digital images in much more complex ways.</div> <div class="para">In this example we stack multiple images with different exposures and use a very simple method (averaging) to convert the stack of images into a single HDR (high dynamic range) image.  This works because each images loses some information in the brightest or darkest regions due to the limits on the values (typically 0 to 255) that each pixel may have. The averages will remain in the appropriate range, but do a better job of distinguishing among the very dark and very bright regions of the image.</div> <div class="para">The images were obtained from <a class="external" href="https://commons.wikimedia.org/wiki/File:StLouisArchMultExpEV%2B1.51.JPG" target="_blank"><code class="code-inline tex2jax_ignore">https://commons.wikimedia.org/wiki/File:StLouisArchMultExpEV%2B1.51.JPG</code></a>. We will use low resolutoin images below, but you can repeat this example with higher resolution images if you like. Notice the use of <code class="code-inline tex2jax_ignore">np.stack()</code> to combine the images into one 4-dimensional tensor, and the use of <code class="code-inline tex2jax_ignore">np.rint()</code> and <code class="code-inline tex2jax_ignore">astype(int)</code> to make sure the resulting data is again integer (the nearest integer to the average).</div> <pre class="ptx-sagecell sagecell-python" id="sage-41"><script type="text/x-sage">from skimage import io
import matplotlib.pyplot as plt 
url = "https://rpruim.github.io/data/images/StLouisArchMultExpEV1.jpg"
urls = [url.replace('1', x) for x in ["1","2","3","4"]]
print(urls)

photos = [io.imread(u) for u in urls]
photo_stack = np.stack(photos)
print(p.shape for p in photos)
print(photo_stack.shape)
average_photo = np.rint(photo_stack.mean(axis = 0)).astype(int)
fig, ax = plt.subplots(1, 4)
print("four different exposures")
for i in range(4):
    ax[i].imshow(photos[i])
plt.show()
print("the average image")

plt.subplots(1, 1)

plt.imshow(average_photo)
plt.show()
</script></pre> <div class="para">More sophisticated algorithms can do an even better job of creating the final image from multiple exposures of the same scene.</div>
<div class="solutions"><a href="" class="solution-knowl original" data-knowl="./knowl/solution-14-hidden.html" title="Solution 1.5.4.1"><span class="type">Solution</span><span class="period">.</span></a></div></article><span class="incontext"><a href="sec-tensors.html#example-9" class="internal">in-context</a></span>
</body>
</html>
