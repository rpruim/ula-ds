<!DOCTYPE html>
<html lang="en-US" dir="ltr">
<!--********************************************-->
<!--*       Generated from PreTeXt source      *-->
<!--*                                          *-->
<!--*         https://pretextbook.org          *-->
<!--*                                          *-->
<!--********************************************-->
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta name="robots" content="noindex, nofollow">
</head>
<body class="ignore-math">
<h5 class="heading"><span class="type">Paragraph</span></h5>
<div class="para logical"><ol class="lower-alpha">
<li><div class="para">
<span class="process-math">\(\yvec\cdot\onevec\)</span> simply sums the components of <span class="process-math">\(\yvec\text{.}\)</span>
</div></li>
<li><div class="para">The examples weâ€™ve seen fit the data using functions that have a constant term such as <span class="process-math">\(y=\beta_0+\beta_1x\text{.}\)</span>  This means that <span class="process-math">\(\onevec\)</span> will be a column of the matrix <span class="process-math">\(X\)</span> and hence in <span class="process-math">\(\col(X)\text{.}\)</span>
</div></li>
<li><div class="para">Since <span class="process-math">\(\onevec\)</span> is in <span class="process-math">\(\col(X)\text{,}\)</span> any vector in <span class="process-math">\(\col(X)^\perp\text{,}\)</span> such as <span class="process-math">\(\yperp\text{,}\)</span> will be orthogonal to <span class="process-math">\(\onevec\text{.}\)</span>
</div></li>
<li><div class="para logical">
<div class="para">Notice that</div>
<div class="displaymath process-math">
\begin{equation*}
\yvec\cdot\onevec = \yhat\cdot\onevec +
\yperp\cdot\onevec = \yhat\cdot\onevec
\end{equation*}
</div>
<div class="para">which says that</div>
<div class="displaymath process-math">
\begin{equation*}
\widetilde{\yvec} = \widetilde{\yhat} + \yperp\text{.}
\end{equation*}
</div>
<div class="para">Since <span class="process-math">\(\yhat\)</span> and <span class="process-math">\(\yperp\)</span> are orthogonal, we have <span class="process-math">\(\widetilde{\yhat}\cdot\yperp = 0\text{.}\)</span>  This means that</div>
<div class="displaymath process-math">
\begin{equation*}
|\widetilde{\yvec}|^2 =
(\widetilde{\yhat}+\yperp)\cdot 
(\widetilde{\yhat}+\yperp)
= |\widetilde{\yhat}|^2 + |\yperp|^2
\end{equation*}
</div>
<div class="para">so that <span class="process-math">\(\var(\yvec) = \var(\yhat)+\var(\yperp)\text{.}\)</span>
</div>
</div></li>
<li><div class="para logical">
<div class="para">
<span class="process-math">\(|\yvec-X\betahat|^2 = |\yvec-\yhat|^2 = |\yperp|^2\text{,}\)</span> which explains why</div>
<div class="displaymath process-math">
\begin{equation*}
\frac{\len{\yvec - X\betahat}^2}{\len{\widetilde{\yvec}}^2}
= \frac{\var(\yvec^\perp)}{\var(\yvec)}\text{.}
\end{equation*}
</div>
<div class="para">Then</div>
<div class="displaymath process-math">
\begin{equation*}
R^2 = 1 - 
\frac{\len{\yvec - X\betahat}^2}{\len{\widetilde{\yvec}}^2}
= 1-\frac{\var(\yvec^\perp)}{\var(\yvec)} =
\frac{\var(\yvec) - \var(\yperp)}{\var(\yvec)} =
\frac{\var(\yhat)}{\var(\yvec)}\text{.}
\end{equation*}
</div>
</div></li>
<li><div class="para logical">
<div class="para">The variances are nonnegative so we have <span class="process-math">\(R^2 \geq
0\text{.}\)</span>  Also,</div>
<div class="displaymath process-math">
\begin{equation*}
1 = \frac{\var(\yvec)}{\var(\yvec)} =
\frac{\var(\yhat)+\var(\yperp)}{\var(\yvec)} \geq
\frac{\var(\yhat)}{\var(\yvec)}=R^2\text{.}
\end{equation*}
</div>
</div></li>
</ol></div>
<span class="incontext"><a href="sec-least-squares.html#p-7321" class="internal">in-context</a></span>
</body>
</html>
