<!DOCTYPE html>
<html lang="en-US" dir="ltr">
<!--********************************************-->
<!--*       Generated from PreTeXt source      *-->
<!--*                                          *-->
<!--*         https://pretextbook.org          *-->
<!--*                                          *-->
<!--********************************************-->
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta name="robots" content="noindex, nofollow">
</head>
<body class="ignore-math">
<h5 class="heading"><span class="type">Paragraph</span></h5>
<div class="para">Fitting the data with a function that is too flexible and fits the training data better than it can be expected to fit new data high is called <dfn class="terminology">overfitting</dfn>, a phenomenon that can appear in many machine learning applications. Generally speaking, we would like to choose <span class="process-math">\(k\)</span> large enough to capture the essential features of the data but not so large that we overfit and build the noise into the model.  What we really need is a method for selecting a good value for <span class="process-math">\(k\)</span> and a better way to measure how well we should expect the model to fit <em class="emphasis">new</em> data, not the data used to train the model. That discussion would take us too far afield for the moment, but it is an important discussion.</div>
<span class="incontext"><a href="sec-least-squares.html#p-7017" class="internal">in-context</a></span>
</body>
</html>
