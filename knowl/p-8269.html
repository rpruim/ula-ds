<!DOCTYPE html>
<html lang="en-US" dir="ltr">
<!--********************************************-->
<!--*       Generated from PreTeXt source      *-->
<!--*                                          *-->
<!--*         https://pretextbook.org          *-->
<!--*                                          *-->
<!--********************************************-->
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta name="robots" content="noindex, nofollow">
</head>
<body class="ignore-math">
<h5 class="heading"><span class="type">Paragraph</span></h5>
<div class="para">This dataset is a bit different from others that weâ€™ve looked at because the scale of the measurements is significantly different.  For instance, the measurements for the body mass are roughly 100 times as large as those for the culmen length. For this reason, first standardize the data by demeaning it, as usual, and then by also rescaling each measurement by the reciprocal of its standard deviation.  The result should be a <span class="process-math">\(333 \by 4\)</span> matrix <code class="code-inline tex2jax_ignore">penguinsXstd</code> with columns means of 0 and columns standard deviations of 1.</div>
<span class="incontext"><a href="sec-pca.html#p-8269" class="internal">in-context</a></span>
</body>
</html>
